{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from helpers.data_generator import process_data, DataGenerator\n",
    "from helpers.custom_losses import denorm_loss, hinge_mse_loss\n",
    "from helpers.custom_losses import percent_correct_sign, baseline_MAE\n",
    "from models.LSTMConv2D import get_model_lstm_conv2d, get_model_simple_lstm\n",
    "from models.LSTMConv2D import get_model_linear_systems, get_model_conv2d\n",
    "from utils.callbacks import CyclicLR, TensorBoardWrapper\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import strftime, localtime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from helpers.normalization import normalize, denormalize, renormalize\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "root = tk.Tk()\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 4\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                        inter_op_parallelism_threads=num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font={'family': 'Times New Roman',\n",
    "      'size': 10}\n",
    "plt.rc('font', **font)\n",
    "matplotlib.rcParams['figure.facecolor'] = (1,1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(delta_true, delta_pred):\n",
    "    \"\"\"Finds the percentage of the time the prediction has the right sign\n",
    "    \"\"\"\n",
    "    return np.sum(np.maximum(np.sign(delta_true*delta_pred),0))/delta_true.size\n",
    "\n",
    "def batch_hinge(model,generator,param_dict,sig):\n",
    "    \"\"\"Finds the percentage of the time the prediction has the right sign\n",
    "    \"\"\"    \n",
    "    nbatches = len(generator)\n",
    "    err = 0\n",
    "    for ind in range(nbatches):\n",
    "        inputs, targets = generator[ind]\n",
    "        predictions = model.predict_on_batch(inputs)\n",
    "        full_pred, full_true, delta_pred, delta_true, baseline = batch_denorm(inputs,targets,predictions,param_dict,sig)\n",
    "        err += hinge_loss(delta_true,delta_pred)\n",
    "    return err/nbatches    \n",
    "\n",
    "def batch_denorm(inputs,targets,predictions,param_dict,sig):\n",
    "    \"\"\"Denormalizes and calculates deltas, prep for plotting and analysis\n",
    "    \"\"\"\n",
    "    targets = targets['target_' + sig]\n",
    "    baseline = inputs['input_' + sig][:,-1]\n",
    "    if predict_deltas:\n",
    "        full_pred = predictions + baseline\n",
    "        full_true = targets + baseline\n",
    "    else:\n",
    "        full_pred = predictions\n",
    "        full_true = targets\n",
    "    denorm_baseline = denormalize(baseline, param_dict[sig])\n",
    "    denorm_full_pred = denormalize(full_pred, param_dict[sig])\n",
    "    denorm_full_true = denormalize(full_true, param_dict[sig])\n",
    "    denorm_delta_pred = denorm_full_pred - denorm_baseline\n",
    "    denorm_delta_true = denorm_full_true - denorm_baseline\n",
    "    return denorm_full_pred, denorm_full_true, denorm_delta_pred, denorm_delta_true, denorm_baseline\n",
    "\n",
    "def plot_batch(y_true, y_pred, baseline, psi, labels, axlabels,shots,times):\n",
    "    batch_size = y_true.shape[0]\n",
    "    ncols = 4\n",
    "    nrows = int(batch_size/ncols)\n",
    "    figsize = (20,10*batch_size/20)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ax = ax.flatten()\n",
    "    # Plot predictions and true deltas\n",
    "    for i in range(batch_size):\n",
    "        ax[i].plot(psi,y_true[i], label=labels[0])\n",
    "        ax[i].plot(psi,y_pred[i], label=labels[1])\n",
    "        ax[i].plot(psi,baseline[i], label=labels[2])\n",
    "        ax[i].title.set_text('Shot ' + str(int(shots[i])) + ', time ' + str(int(times[i])))\n",
    "        ax[i].set_xlabel(axlabels[0])\n",
    "        ax[i].set_ylabel(axlabels[1])\n",
    "        ax[i].legend(loc=0)\n",
    "    plt.tight_layout()\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model: model-conv2d_profiles-temp-dens-rotation-press-itemp-ffprime_act-pinj-curr-tinj-gasA_targ-temp_norm-StandardScaler_profLB-1_actLB-8_activ-relu_nshots-10000_29Jul19-21-10.h5\n"
     ]
    }
   ],
   "source": [
    "file_path = filedialog.askopenfilename(title='Saved Model File',filetypes = [(\"hdf5 files\",\"*.h5\"),(\"all files\",\"*.*\")])\n",
    "model = keras.models.load_model(file_path, compile=False)\n",
    "print('loaded model: ' + file_path.split('/')[-1])\n",
    "# file_path = filedialog.askopenfilename(title='Config Pickle',filetypes = [(\"pickle files\",\"*.pkl\"),(\"all files\",\"*.*\")])\n",
    "# with open(file_path, 'rb') as f:\n",
    "#      analysis_params = pickle.load(f, encoding='latin1')\n",
    "# print('loaded dict: ' + file_path.split('/')[-1])\n",
    "# print('with parameters: ' + str(analysis_params.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Signals: curr, dens, ffprime, gasA, itemp, pinj, press, rotation, temp, tinj, time, shotnum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering:   2%|1         | 16/1000 [00:00<00:06, 153.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of useable shots:  8683\n",
      "Number of shots used:  1000\n",
      "Total number of timesteps:  80431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering: 100%|##########| 1000/1000 [00:06<00:00, 151.52it/s]\n",
      "Stacking: 100%|##########| 12/12 [00:02<00:00,  4.28it/s]\n",
      "Normalizing: 100%|##########| 12/12 [00:01<00:00, 10.77it/s]\n",
      "Splitting: 100%|##########| 12/12 [00:00<00:00, 92.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  17746\n",
      "Number of training samples:  14196\n",
      "Number of validation samples:  3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = 'conv2d'\n",
    "input_profile_names = ['temp', 'dens', 'rotation', 'press', 'itemp', 'ffprime']\n",
    "target_profile_names = ['temp']\n",
    "actuator_names = ['pinj', 'curr', 'tinj', 'gasA']\n",
    "predict_deltas = False\n",
    "profile_lookback = 1\n",
    "actuator_lookback = 8\n",
    "lookahead = 3\n",
    "profile_length = 65\n",
    "std_activation = 'relu'\n",
    "rawdata_path = '/home/fouriest/SCHOOL/Princeton/PPPL/final_data.pkl'\n",
    "checkpt_dir = '/home/fouriest/SCHOOL/Princeton/PPPL/'\n",
    "sig_names = input_profile_names + target_profile_names + actuator_names\n",
    "normalization_method = 'StandardScaler'\n",
    "window_length = 1\n",
    "window_overlap = 0\n",
    "sample_step = 4\n",
    "uniform_normalization = True\n",
    "train_frac = 0.8\n",
    "val_frac = 0.2\n",
    "nshots = 1000\n",
    "mse_weight_vector = np.linspace(1, np.sqrt(10), profile_length)**2\n",
    "hinge_weight = 50\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "verbose = 1\n",
    "\n",
    "traindata, valdata, param_dict = process_data(rawdata_path, sig_names, normalization_method,\n",
    "                                              window_length, window_overlap, max(\n",
    "                                                  profile_lookback, actuator_lookback),\n",
    "                                              lookahead, sample_step, uniform_normalization,\n",
    "                                              train_frac, val_frac, nshots,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_generator = DataGenerator(traindata, batch_size, input_profile_names,\n",
    "                                actuator_names, target_profile_names,\n",
    "                                profile_lookback, actuator_lookback, lookahead,\n",
    "                                predict_deltas)\n",
    "val_generator = DataGenerator(valdata, batch_size, input_profile_names,\n",
    "                              actuator_names, target_profile_names,\n",
    "                              profile_lookback, actuator_lookback, lookahead,\n",
    "                              predict_deltas)\n",
    "steps_per_epoch = len(train_generator)\n",
    "val_steps = len(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ind = np.random.randint(len(train_generator))\n",
    "sig = 'temp'\n",
    "inputs, targets = train_generator[batch_ind]\n",
    "shotnums = train_generator.cur_shotnum[:,max(profile_lookback, actuator_lookback)]\n",
    "times = train_generator.cur_times[:,max(profile_lookback, actuator_lookback)]\n",
    "predictions = model.predict_on_batch(inputs)\n",
    "\n",
    "psi = np.linspace(0,1,profile_length)\n",
    "full_pred, full_true, delta_pred, delta_true, baseline = batch_denorm(inputs,targets,predictions,param_dict,sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_batch(delta_true,delta_pred,np.zeros_like(baseline),psi,['true','pred','baseline'],['psi','delta etemp'], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_batch(full_true,full_pred,baseline,psi,['true','pred','baseline'],['psi','etemp'], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "522.85px",
    "left": "1504px",
    "right": "20px",
    "top": "120px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
