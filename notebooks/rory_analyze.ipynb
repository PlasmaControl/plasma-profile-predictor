{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from helpers.data_generator import process_data, DataGenerator\n",
    "from helpers.custom_losses import denorm_loss, hinge_mse_loss\n",
    "from helpers.custom_losses import percent_correct_sign, baseline_MAE\n",
    "from models.LSTMConv2D import get_model_lstm_conv2d, get_model_simple_lstm\n",
    "from models.LSTMConv2D import get_model_linear_systems, get_model_conv2d\n",
    "from utils.callbacks import CyclicLR, TensorBoardWrapper\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import strftime, localtime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from helpers.normalization import normalize, denormalize, renormalize\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "root = tk.Tk()\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 4\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                        inter_op_parallelism_threads=num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font={'family': 'Times New Roman',\n",
    "      'size': 10}\n",
    "plt.rc('font', **font)\n",
    "matplotlib.rcParams['figure.facecolor'] = (1,1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(delta_true, delta_pred):\n",
    "    \"\"\"Finds the percentage of the time the prediction has the right sign\n",
    "    \"\"\"\n",
    "    return np.sum(np.maximum(np.sign(delta_true*delta_pred),0))/delta_true.size\n",
    "\n",
    "def batch_hinge(model,generator,param_dict,sig):\n",
    "    \"\"\"Finds the percentage of the time the prediction has the right sign\n",
    "    \"\"\"    \n",
    "    nbatches = len(generator)\n",
    "    err = 0\n",
    "    for ind in range(nbatches):\n",
    "        inputs, targets = generator[ind]\n",
    "        predictions = model.predict_on_batch(inputs)\n",
    "        full_pred, full_true, delta_pred, delta_true, baseline = batch_denorm(inputs,targets,predictions,param_dict,sig)\n",
    "        err += hinge_loss(delta_true,delta_pred)\n",
    "    return err/nbatches    \n",
    "\n",
    "def batch_denorm(inputs,targets,predictions,param_dict,sig):\n",
    "    \"\"\"Denormalizes and calculates deltas, prep for plotting and analysis\n",
    "    \"\"\"\n",
    "    targets = targets['target_' + sig]\n",
    "    baseline = inputs['input_' + sig][:,-1]\n",
    "    predictions = predictions[sig]\n",
    "    if predict_deltas:\n",
    "        full_pred = predictions + baseline\n",
    "        full_true = targets + baseline\n",
    "    else:\n",
    "        full_pred = predictions\n",
    "        full_true = targets\n",
    "    denorm_baseline = denormalize(baseline, param_dict[sig])\n",
    "    denorm_full_pred = denormalize(full_pred, param_dict[sig])\n",
    "    denorm_full_true = denormalize(full_true, param_dict[sig])\n",
    "    denorm_delta_pred = denorm_full_pred - denorm_baseline\n",
    "    denorm_delta_true = denorm_full_true - denorm_baseline\n",
    "    return denorm_full_pred, denorm_full_true, denorm_delta_pred, denorm_delta_true, denorm_baseline\n",
    "\n",
    "def plot_batch(y_true, y_pred, baseline, psi, labels, axlabels,shots,times):\n",
    "    batch_size = y_true.shape[0]\n",
    "    ncols = 4\n",
    "    nrows = int(batch_size/ncols)\n",
    "    figsize = (20,10*batch_size/10)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ax = ax.flatten()\n",
    "    # Plot predictions and true deltas\n",
    "    for i in range(batch_size):\n",
    "        ax[i].plot(psi,y_true[i], label=labels[0])\n",
    "        ax[i].plot(psi,y_pred[i], label=labels[1])\n",
    "        ax[i].plot(psi,baseline[i], label=labels[2])\n",
    "        ax[i].title.set_text('Shot ' + str(int(shots[i])) + ', time ' + str(int(times[i])))\n",
    "        ax[i].set_xlabel(axlabels[0])\n",
    "        ax[i].set_ylabel(axlabels[1])\n",
    "        ax[i].set_ylim(-2*normalization_params[sig]['std'],2*normalization_params[sig]['std'])\n",
    "        ax[i].legend(loc=0)\n",
    "    plt.tight_layout()\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model: model-conv2d_profiles-temp-dens-rotation-press-itemp-ffprime_act-pinj-curr-tinj-gasA_targ-temp_norm-StandardScaler_profLB-1_actLB-8_activ-relu_nshots-1000_31Jul19-14-05.h5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/fouriest/SCHOOL/Princeton/PPPL/model-conv2d_profiles-temp-dens-rotation-press-itemp-ffprime_act-pinj-curr-tinj-gasA_targ-temp_norm-StandardScaler_profLB-1_actLB-8_activ-relu_nshots-1000_31Jul19-14-05params.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b321dc8fcde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loaded model: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'params.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m      \u001b[0manalysis_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loaded dict: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/fouriest/SCHOOL/Princeton/PPPL/model-conv2d_profiles-temp-dens-rotation-press-itemp-ffprime_act-pinj-curr-tinj-gasA_targ-temp_norm-StandardScaler_profLB-1_actLB-8_activ-relu_nshots-1000_31Jul19-14-05params.pkl'"
     ]
    }
   ],
   "source": [
    "file_path = filedialog.askopenfilename(title='Saved Model File',filetypes = [(\"hdf5 files\",\"*.h5\"),(\"all files\",\"*.*\")])\n",
    "model = keras.models.load_model(file_path, compile=False)\n",
    "print('loaded model: ' + file_path.split('/')[-1])\n",
    "file_path = file_path[:-3] + 'params.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "     analysis_params = pickle.load(f, encoding='latin1')\n",
    "print('loaded dict: ' + file_path.split('/')[-1])\n",
    "print('with parameters: ' + str(analysis_params.keys()))\n",
    "locals().update(analysis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Signals: curr, dens, ffprime, gasA, itemp, pinj, press, rotation, temp, tinj\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b7e8aea5178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                   profile_lookback, actuator_lookback),\n\u001b[1;32m      7\u001b[0m                                               \u001b[0mlookahead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_normalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                               train_frac, val_frac, nshots,verbose=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SCHOOL/Princeton/PPPL/plasma-profile-predictor/helpers/data_generator.py\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(rawdata, sig_names, normalization_method, window_length, window_overlap, lookbacks, lookahead, sample_step, uniform_normalization, train_frac, val_frac, nshots, verbose)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# find which shots have all the signals needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mmax_lookback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_lookback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mmax_lookback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "train_frac = 1\n",
    "val_frac = 0\n",
    "nshots = 1000\n",
    "traindata, valdata, param_dict = process_data(rawdata, sig_names, normalization_method,\n",
    "                                              window_length, window_overlap, max(\n",
    "                                                  profile_lookback, actuator_lookback),\n",
    "                                              lookahead, sample_step, uniform_normalization,\n",
    "                                              train_frac, val_frac, nshots,verbose=1)\n",
    "traindata = denormalize(traindata, param_dict)\n",
    "traindata = renormalize(traindata, normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "train_generator = DataGenerator(traindata, batch_size, input_profile_names,\n",
    "                                actuator_names, target_profile_names,\n",
    "                                profile_lookback, actuator_lookback, lookahead,\n",
    "                                predict_deltas,2)\n",
    "steps_per_epoch = len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ind = np.random.randint(len(train_generator))\n",
    "inputs, targets = train_generator[batch_ind]\n",
    "shotnums = train_generator.cur_shotnum[:,max(profile_lookback, actuator_lookback)]\n",
    "times = train_generator.cur_times[:,max(profile_lookback, actuator_lookback)]\n",
    "pred = model.predict_on_batch(inputs)\n",
    "# add deltas to future actuators\n",
    "#predict on new actuators\n",
    "predictions = {}\n",
    "for i, sig in enumerate(target_profile_names):\n",
    "    predictions[sig] = pred[i]\n",
    "psi = np.linspace(0,1,profile_length)\n",
    "full_pred = {}\n",
    "full_true = {}\n",
    "delta_pred = {}\n",
    "delta_true = {}\n",
    "baseline = {}\n",
    "for sig in target_profile_names:\n",
    "    full_pred[sig], full_true[sig], delta_pred[sig], delta_true[sig], baseline[sig] = batch_denorm(inputs,targets,predictions,\n",
    "                                                                                                   normalization_params,sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sig = 'temp'\n",
    "fig, ax = plot_batch(delta_true[sig],delta_pred[sig],np.zeros_like(delta_true[sig]),\n",
    "                     psi,['true','pred','baseline'],['psi','delta ' + sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 'dens'\n",
    "fig, ax = plot_batch(delta_true[sig],delta_pred[sig],np.zeros_like(delta_true[sig]),\n",
    "                     psi,['true','pred','baseline'],['psi','delta ' + sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 'press'\n",
    "fig, ax = plot_batch(delta_true[sig],delta_pred[sig],np.zeros_like(delta_true[sig]),\n",
    "                     psi,['true','pred','baseline'],['psi','delta ' + sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sig = 'temp'\n",
    "fig, ax = plot_batch(full_true[sig],full_pred[sig],baseline[sig],\n",
    "                     psi,['true','pred','baseline'],['psi',sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 'dens'\n",
    "fig, ax = plot_batch(full_true[sig],full_pred[sig],baseline[sig],\n",
    "                     psi,['true','pred','baseline'],['psi',sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 'press'\n",
    "fig, ax = plot_batch(full_true[sig],full_pred[sig],baseline[sig],\n",
    "                     psi,['true','pred','baseline'],['psi',sig], shotnums,times)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(rawdata,'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 'rotation'\n",
    "zrat = []\n",
    "for shot in data.values():\n",
    "    if sig in shot.keys():\n",
    "        if shot[sig].size>0:\n",
    "            zrat.append(np.count_nonzero(shot[sig])/shot[sig].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[164334].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "522.85px",
    "left": "1504px",
    "right": "20px",
    "top": "120px",
    "width": "341px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
