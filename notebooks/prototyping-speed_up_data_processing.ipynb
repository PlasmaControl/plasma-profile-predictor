{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    efit_type = 'EFIT02'\n",
    "\n",
    "    scenario = {'actuator_names': ['pinj', 'curr', 'tinj'],\n",
    "                        'profile_names': ['thomson_temp_{}'.format(efit_type),\n",
    "                                          'thomson_dens_{}'.format(efit_type),\n",
    "                                          'ffprime_{}'.format(efit_type),\n",
    "                                          'press_{}'.format(efit_type),\n",
    "                                          'q_{}'.format(efit_type)],\n",
    "                        'scalar_names': [],\n",
    "                        'profile_downsample': 2,\n",
    "                        'state_encoder_type': 'dense',\n",
    "                        'state_decoder_type': 'dense',\n",
    "                        'control_encoder_type': 'dense',\n",
    "                        'control_decoder_type': 'dense',\n",
    "                        'state_encoder_kwargs': {'num_layers': 6,\n",
    "                                                 'layer_scale': 2,\n",
    "                                                 'std_activation':'relu'},\n",
    "                        'state_decoder_kwargs': {'num_layers': 6,\n",
    "                                                 'layer_scale': 2,\n",
    "                                                 'std_activation':'relu'},\n",
    "                        'control_encoder_kwargs': {'num_layers': 10,\n",
    "                                                   'layer_scale': 2,\n",
    "                                                   'std_activation':'relu'},\n",
    "                        'control_decoder_kwargs': {'num_layers': 10,\n",
    "                                                   'layer_scale': 2,\n",
    "                                                   'std_activation':'relu'},\n",
    "                        'state_latent_dim':50,\n",
    "                        'control_latent_dim':5,\n",
    "                        'x_weight':1,\n",
    "                        'u_weight':1,\n",
    "                        'discount_factor':1,\n",
    "                        'batch_size': 128,\n",
    "                        'epochs': 100,\n",
    "                        'flattop_only': True,\n",
    "                        'raw_data_path': '/scratch/gpfs/jabbate/mixed_data/final_data.pkl',\n",
    "                        'process_data': True,\n",
    "                        'processed_filename_base': '/scratch/gpfs/jabbate/data_60_ms_randomized_',\n",
    "                        'optimizer': 'adagrad',\n",
    "                        'optimizer_kwargs': {},\n",
    "                        'shuffle_generators': True,\n",
    "                        'pruning_functions': ['remove_nan', 'remove_dudtrip', 'remove_I_coil'],\n",
    "                        'normalization_method': 'RobustScaler',\n",
    "                        'window_length': 1,\n",
    "                        'window_overlap': 0,\n",
    "                        'lookback': 0,\n",
    "                        'lookahead': 3,\n",
    "                        'sample_step': 1,\n",
    "                        'uniform_normalization': True,\n",
    "                        'train_frac': 0.8,\n",
    "                        'val_frac': 0.2,\n",
    "                        'nshots': 12000,\n",
    "                        'excluded_shots': ['topology_TOP', 'topology_OUT', 'topology_MAR', 'topology_IN', 'topology_DN', 'topology_BOT']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wconlin/.conda/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "from helpers.normalization import normalize\n",
    "from helpers.pruning_functions import remove_dudtrip, remove_I_coil, remove_ECH, remove_gas, remove_nan\n",
    "from tqdm import tqdm\n",
    "from helpers import exclude_shots\n",
    "import numba\n",
    "\n",
    "def process_data(rawdata, sig_names, normalization_method, window_length=1,\n",
    "                 window_overlap=0, lookbacks={}, lookahead=3, sample_step=5,\n",
    "                 uniform_normalization=True, train_frac=0.7, val_frac=0.2,\n",
    "                 nshots=None,\n",
    "                 verbose=1, flattop_only=True, randomize=True, **kwargs):\n",
    "    \"\"\"Organize data into correct format for training\n",
    "\n",
    "    Gathers raw data into bins, group into training sequences, normalize,\n",
    "    and split into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        rawdata (dict): Nested dictionary of raw signal data, or path to pickle.\n",
    "            Should be of the form rawdata[shot][signal_name] = signal_data.\n",
    "        sig_names (list): List of signal names as strings.\n",
    "        normalization_method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
    "            `RobustScaler`, `PowerTransform`.\n",
    "        window_length (int): Number of samples to average over in each bin/window.\n",
    "        window_overlap (int): How many timesteps to overlap windows.\n",
    "        lookbacks (dict of int): How many window lengths for lookback for each sig.\n",
    "        lookahead (int): How many window lengths to predict into the future.\n",
    "        sample_step (int): How much to offset sequential training sequences.\n",
    "            Step of 1 means sample[i] and sample[i+1] will be offset by 1, with\n",
    "            the rest overlapping.\n",
    "        uniform_normalization (bool): 'True' uses the same normalization\n",
    "            parameters over a whole profile, 'False' normalizes each spatial\n",
    "            point separately.\n",
    "        val_frac (float): Fraction of samples to use for validation.\n",
    "        nshots (int): How many shots to use. If None, all available will be used.\n",
    "        verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 is abbreviated.\n",
    "        flattop_only (bool): Whether to only include data from flattop.\n",
    "\n",
    "    Returns:\n",
    "        traindata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
    "            Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
    "        valdata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
    "            Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
    "    \"\"\"\n",
    "    ##############################\n",
    "    # Load data\n",
    "    ##############################\n",
    "    if type(rawdata) is not dict:\n",
    "        if verbose:\n",
    "            print('Loading')\n",
    "        abs_path = Path(rawdata).resolve()\n",
    "        if abs_path.exists():\n",
    "            with open(abs_path, 'rb') as f:\n",
    "                rawdata = pickle.load(f, encoding='latin1')\n",
    "        else:\n",
    "            print(abs_path)\n",
    "            raise IOError(\"No such path to data file\")\n",
    "            \n",
    "    ##############################\n",
    "    # get pruning functions\n",
    "    ##############################\n",
    "    pruning_functions = kwargs.get('pruning_functions', [])\n",
    "    if 'ech' not in sig_names:\n",
    "        pruning_functions.append('remove_ECH')\n",
    "    if not {'gasB', 'gasC', 'gasD', 'gasE'}.issubset(set(sig_names)):\n",
    "        pruning_functions.append('remove_gas')\n",
    "    prun_dict = {'remove_nan': remove_nan,\n",
    "                 'remove_ECH': remove_ECH,\n",
    "                 'remove_I_coil': remove_I_coil,\n",
    "                 'remove_gas': remove_gas,\n",
    "                 'remove_dudtrip': remove_dudtrip}\n",
    "    for i, elem in enumerate(pruning_functions):\n",
    "        if isinstance(elem, str):\n",
    "            pruning_functions[i] = prun_dict[elem]\n",
    "\n",
    "    ##############################\n",
    "    # get excluded shots\n",
    "    ##############################\n",
    "    excluded_shots = kwargs.get('excluded_shots', [])\n",
    "    exclude_dict = {'topology_TOP': exclude_shots.topology_TOP,\n",
    "                    'topology_SNT': exclude_shots.topology_SNT,\n",
    "                    'topology_SNB': exclude_shots.topology_SNB,\n",
    "                    'topology_OUT': exclude_shots.topology_OUT,\n",
    "                    'topology_MAR': exclude_shots.topology_MAR,\n",
    "                    'topology_IN': exclude_shots.topology_IN,\n",
    "                    'topology_DN': exclude_shots.topology_DN,\n",
    "                    'topology_BOT': exclude_shots.topology_BOT}\n",
    "    for i, elem in enumerate(excluded_shots):\n",
    "        if isinstance(elem, str):\n",
    "            excluded_shots[i] = exclude_dict[elem]\n",
    "        if not isinstance(elem, list):\n",
    "            excluded_shots[i] = [elem]\n",
    "    excluded_shots = [item for sublist in excluded_shots for item in sublist]\n",
    "\n",
    "    ##############################\n",
    "    # get sig names\n",
    "    ##############################\n",
    "    extra_sigs = ['time', 'shotnum']\n",
    "    if remove_dudtrip in pruning_functions:\n",
    "        extra_sigs += ['dud_trip']\n",
    "    if remove_I_coil in pruning_functions:\n",
    "        extra_sigs += ['bt', 'curr', 'C_coil_method', 'I_coil_method']\n",
    "    if remove_gas in pruning_functions:\n",
    "        extra_sigs += ['gasB', 'gasC', 'gasD', 'gasE', 'pfx1', 'pfx2']\n",
    "    if remove_ECH in pruning_functions:\n",
    "        extra_sigs += ['ech']\n",
    "    sig_names = list(np.unique(sig_names))\n",
    "    sigsplustime = list(np.unique(sig_names + extra_sigs))\n",
    "    if verbose:\n",
    "        print('Signals: ' + ', '.join(sig_names))\n",
    "\n",
    "    ##############################\n",
    "    # figure out lookbacks\n",
    "    ##############################\n",
    "    if isinstance(lookbacks, int):\n",
    "        max_lookback = lookbacks\n",
    "        lookbacks = {sig: max_lookback for sig in sigsplustime}\n",
    "    else:\n",
    "        max_lookback = 0\n",
    "        for val in lookbacks.values():\n",
    "            if val > max_lookback:\n",
    "                max_lookback = val\n",
    "        for sig in sigsplustime:\n",
    "            if sig not in lookbacks.keys():\n",
    "                lookbacks[sig] = max_lookback\n",
    "            \n",
    "    ##############################\n",
    "    # find which shots have all the signals needed\n",
    "    ##############################\n",
    "    usabledata = []\n",
    "    all_shots = sorted(list(rawdata.keys()))\n",
    "    for shot in all_shots:\n",
    "        rawdata[shot]['shotnum'] = np.ones(rawdata[shot]['time'].shape[0])*shot\n",
    "        if set(sigsplustime).issubset(set(rawdata[shot].keys())) \\\n",
    "           and rawdata[shot]['time'].size > (max_lookback+lookahead) \\\n",
    "           and shot not in excluded_shots:\n",
    "            usabledata.append(rawdata[shot])\n",
    "    usabledata = np.array(usabledata)\n",
    "    del rawdata\n",
    "    gc.collect()\n",
    "    if nshots is not None:\n",
    "        nshots = np.minimum(nshots, len(usabledata))\n",
    "        usabledata = usabledata[:nshots]\n",
    "    else:\n",
    "        nshots = len(usabledata)\n",
    "    if verbose:\n",
    "        print('Number of useable shots: ', str(len(usabledata)))\n",
    "        print('Number of shots used: ', str(nshots))\n",
    "        sys.stdout.flush()\n",
    "    if verbose:\n",
    "        t = 0\n",
    "        for shot in usabledata:\n",
    "            t += shot['time'].size\n",
    "        print('Total number of timesteps: ', str(t))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    ##############################\n",
    "    # some helper functions\n",
    "    ##############################          \n",
    "    def moving_average(a, n):\n",
    "        \"\"\"moving average of array a with window size n\"\"\"\n",
    "        ret = np.nancumsum(a, axis=0)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "\n",
    "    def is_valid(shot):\n",
    "        \"\"\"checks if a shot is completely NaN or if it never reached flattop\"\"\"\n",
    "        for sig in sigsplustime:\n",
    "            if np.isnan(shot[sig]).all():  # or np.isinf(shot[sig]).any():\n",
    "                return False\n",
    "        if (flattop_only):\n",
    "            if (shot['t_ip_flat'] == None or shot['ip_flat_duration'] == None):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_non_nan_inds(arr):\n",
    "        \"\"\"gets indices of array where value is not NaN\"\"\"\n",
    "        if len(arr.shape) == 1:\n",
    "            return np.where(~np.isnan(arr))[0]\n",
    "        else:\n",
    "            return np.where(np.any(~np.isnan(arr), axis=1))[0]\n",
    "\n",
    "    def get_first_index(shot):\n",
    "        \"\"\"gets index of first valid timeslice for a shot\"\"\"\n",
    "        input_max = max([get_non_nan_inds(shot[sig])[0] +\n",
    "                         lookbacks[sig] for sig in sig_names])\n",
    "        output_max = max([get_non_nan_inds(shot[sig])[0] -\n",
    "                          lookahead for sig in sig_names])\n",
    "        if (flattop_only) and (shot['t_ip_flat'] != None):\n",
    "            current_max = np.searchsorted(\n",
    "                shot['time'], shot['t_ip_flat'], side='left')\n",
    "            return np.ceil(max(input_max, output_max, current_max)).astype(int)\n",
    "        else:\n",
    "            return np.ceil(max(input_max, output_max)).astype(int)\n",
    "\n",
    "    def get_last_index(shot):\n",
    "        \"\"\"gets index of last valid timeslice for a shot\"\"\"\n",
    "        partial_min = min([get_non_nan_inds(shot[sig])[-1]\n",
    "                           for sig in sig_names])\n",
    "        full_min = min([get_non_nan_inds(shot[sig])[-1] -\n",
    "                        lookahead for sig in sig_names])\n",
    "        if (flattop_only) and (shot['t_ip_flat'] != None) and (shot['ip_flat_duration'] != None):\n",
    "            current_min = np.searchsorted(\n",
    "                shot['time'], shot['t_ip_flat']+shot['ip_flat_duration'], side='right')\n",
    "            return np.floor(min(full_min, partial_min, current_min)).astype(int)\n",
    "        else:\n",
    "            return np.floor(min(full_min, partial_min)).astype(int)\n",
    "    \n",
    "    @numba.njit\n",
    "    def group_data(array,first,last,sample_step,lookback, lookahead):\n",
    "        \"\"\"groups shot data into i/o chunks\"\"\"\n",
    "        data = []\n",
    "        for i in range(first,last,sample_step):\n",
    "            data.append(array[i-lookback:i+lookahead+1])\n",
    "        return data\n",
    "    \n",
    "    ##############################\n",
    "    # loop through shots and do stuff\n",
    "    ##############################\n",
    "    alldata = {}\n",
    "    shots_with_complete_nan = []\n",
    "    for sig in sigsplustime:\n",
    "        alldata[sig] = []  # initalize empty lists\n",
    "    for shot in tqdm(usabledata, desc='Gathering', ascii=True, dynamic_ncols=True,\n",
    "                     disable=not verbose == 1):\n",
    "        ##############################\n",
    "        # take moving average of data and bin it\n",
    "        ##############################\n",
    "        binned_shot = {}\n",
    "        for sig in sigsplustime:\n",
    "            if np.any(np.isinf(shot[sig])):\n",
    "                shot[sig][np.isinf(shot[sig])] = np.nan            \n",
    "            binned_shot[sig] = moving_average(shot[sig],window_length)[::window_length-window_overlap]\n",
    "        binned_shot['t_ip_flat'] = shot['t_ip_flat']\n",
    "        binned_shot['ip_flat_duration'] = shot['ip_flat_duration']\n",
    "        if not is_valid(binned_shot):\n",
    "            shots_with_complete_nan.append(np.unique(shot[\"shotnum\"]))\n",
    "            continue\n",
    "\n",
    "        ##############################\n",
    "        # group into arrays of input/output pairs\n",
    "        ##############################\n",
    "        first = get_first_index(binned_shot)\n",
    "        last = get_last_index(binned_shot)\n",
    "        for sig in sigsplustime:\n",
    "            alldata[sig] += group_data(binned_shot[sig],first,last,sample_step,lookbacks[sig],lookahead)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Shots with Complete NaN: \" + ', '.join(str(e)\n",
    "                                                      for e in shots_with_complete_nan))\n",
    "    sys.stdout.flush()\n",
    "    del usabledata\n",
    "    gc.collect()\n",
    "    \n",
    "    ##############################\n",
    "    # stack data from all shots together\n",
    "    ##############################    \n",
    "    for sig in tqdm(sigsplustime, desc='Stacking', ascii=True, dynamic_ncols=True,\n",
    "                    disable=not verbose == 1):\n",
    "        alldata[sig] = np.stack(alldata[sig])\n",
    "    print(\"{} samples total\".format(len(alldata['time'])))\n",
    "    sys.stdout.flush()\n",
    "    ##############################\n",
    "    # apply pruning functions\n",
    "    ##############################\n",
    "    # call fns in the right order to speed things up\n",
    "    if remove_ECH in pruning_functions:\n",
    "        alldata = remove_ECH(alldata,verbose)\n",
    "    if remove_gas in pruning_functions:\n",
    "        alldata = remove_gas(alldata,verbose)\n",
    "    if remove_I_coil in pruning_functions:\n",
    "        alldata = remove_I_coil(alldata,verbose)\n",
    "    if remove_nan in pruning_functions:\n",
    "        alldata = remove_nan(alldata,verbose)\n",
    "    if remove_dudtrip in pruning_functions:\n",
    "        alldata = remove_dudtrip(alldata,verbose)\n",
    "\n",
    "    print(\"{} samples remaining after pruning\".format(len(alldata['time'])))\n",
    "    sys.stdout.flush()\n",
    "    ##############################\n",
    "    # normalize data\n",
    "    ##############################    \n",
    "    alldata, normalization_params = normalize(\n",
    "        alldata, normalization_method, uniform_normalization, verbose)\n",
    "    \n",
    "    ##############################\n",
    "    # split into train and validation sets\n",
    "    ##############################    \n",
    "    nsamples = alldata['time'].shape[0]\n",
    "    inds = np.random.permutation(nsamples) if randomize else np.arange(nsamples)\n",
    "    traininds = inds[:int(nsamples*train_frac)]\n",
    "    valinds = inds[int(nsamples*train_frac)\n",
    "                       :int(nsamples*(val_frac+train_frac))]\n",
    "    traindata = {}\n",
    "    valdata = {}\n",
    "    for sig in tqdm(sigsplustime, desc='Splitting', ascii=True, dynamic_ncols=True,\n",
    "                    disable=not verbose == 1):\n",
    "        traindata[sig] = alldata[sig][traininds]\n",
    "        valdata[sig] = alldata[sig][valinds]\n",
    "    time.sleep(0.1)\n",
    "    if verbose:\n",
    "        print('Total number of samples: ', str(nsamples))\n",
    "        print('Number of training samples: ', str(traininds.size))\n",
    "        print('Number of validation samples: ', str(valinds.size))\n",
    "    return traindata, valdata, normalization_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def prune_loop(inds,shotnumarr,timearr):\n",
    "    remove_inds = set()\n",
    "    for ind in inds:\n",
    "        shot = shotnumarr[ind]\n",
    "        time = timearr[ind]\n",
    "        i = ind\n",
    "        while np.any(shotnumarr[i] == shot) and np.any(timearr[i] >= time):\n",
    "            remove_inds.add(i)\n",
    "            i += 1\n",
    "            if i>=len(timearr):\n",
    "                break\n",
    "    return remove_inds\n",
    "\n",
    "\n",
    "def remove_dudtrip(data, verbose):\n",
    "    if verbose:\n",
    "        print('Removing dudtrip')\n",
    "    dud_trip_inds = np.nonzero(data['dud_trip'])[0]\n",
    "    if len(dud_trip_inds)==0:\n",
    "        return data\n",
    "    remove_inds = prune_loop(dud_trip_inds,data['shotnum'],data['time'])\n",
    "    if verbose:\n",
    "        print(\"Removed {} samples\".format(len(remove_inds)))\n",
    "    keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"{} samples remaining\".format(len(keep_inds)))\n",
    "    for sig in data.keys():\n",
    "        data[sig] = data[sig][list(keep_inds)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_I_coil(data, verbose):\n",
    "    if verbose:\n",
    "        print('Removing weird I-coils')\n",
    "    \n",
    "    @numba.njit\n",
    "    def find_Icoil_inds(n,bt,curr,C_coil_method,I_coil_method):\n",
    "        c_coil = list()\n",
    "        i_coil = list()\n",
    "        EFC = list()\n",
    "        for i in range(n):\n",
    "            if np.mean(bt[i]*curr[i]) < 0:\n",
    "                # left-handed\n",
    "                if not set(np.unique(C_coil_method[i])).issubset({5, 0, -1}):\n",
    "                    c_coil.append(i)\n",
    "                if not set(np.unique(I_coil_method[i])).issubset({5, 0, -1}):\n",
    "                    i_coil.append(i)\n",
    "                if not np.all(np.logical_xor(C_coil_method[i] == 5, I_coil_method[i] == 5)):\n",
    "                    EFC.append(i)\n",
    "            else:\n",
    "                # right-handed\n",
    "                if not set(np.unique(C_coil_method[i])).issubset({6, 0, -1}):\n",
    "                    c_coil.append(i)\n",
    "                if not set(np.unique(I_coil_method[i])).issubset({7, 0, -1}):\n",
    "                    i_coil.append(i)\n",
    "                if not np.any(np.logical_or(np.logical_and(C_coil_method[i] == 6, \n",
    "                                                           I_coil_method[i] != 7), \n",
    "                                            np.logical_and(C_coil_method[i] != 6, \n",
    "                                                           I_coil_method[i] == 7))):\n",
    "                    EFC.append(i)\n",
    "                    \n",
    "        coil_inds = c_coil + i_coil + EFC\n",
    "        return coil_inds\n",
    "\n",
    "    coil_inds = np.unique(find_Icoil_inds(len(data['time']),\n",
    "                                          data['bt'],\n",
    "                                          data['curr'],\n",
    "                                          data['C_coil_method'].astype(int),\n",
    "                                          data['I_coil_method'].astype(int)))\n",
    "    if len(coil_inds)==0:\n",
    "        return data\n",
    "    remove_inds = prune_loop(coil_inds,data['shotnum'],data['time'])\n",
    "    if verbose:\n",
    "        print(\"Removed {} samples\".format(len(remove_inds)))\n",
    "    keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"{} samples remaining\".format(len(keep_inds)))\n",
    "    for sig in data.keys():\n",
    "        data[sig] = data[sig][list(keep_inds)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_gas(data, verbose):\n",
    "    if verbose:\n",
    "        print('Removing weird gas')\n",
    "    from functools import reduce\n",
    "    threshold=2\n",
    "    gasB_inds = np.nonzero(np.any(data['gasB'] > threshold, axis=1))[0]\n",
    "    gasC_inds = np.nonzero(np.any(data['gasC'] > threshold, axis=1))[0]\n",
    "    gasD_inds = np.nonzero(np.any(data['gasD'] > threshold, axis=1))[0]\n",
    "    gasE_inds = np.nonzero(np.any(data['gasE'] > threshold, axis=1))[0]\n",
    "    pfx1_inds = np.nonzero(np.any(data['pfx1'] > threshold, axis=1))[0]\n",
    "    pfx2_inds = np.nonzero(np.any(data['pfx2'] > threshold, axis=1))[0]\n",
    "    gas_inds = reduce(np.union1d, (gasB_inds, gasC_inds,\n",
    "                                   gasD_inds, gasE_inds, pfx1_inds, pfx2_inds))\n",
    "    if len(gas_inds)==0:\n",
    "        return data\n",
    "    remove_inds = prune_loop(gas_inds,data['shotnum'],data['time'])\n",
    "    if verbose:\n",
    "        print(\"Removed {} samples\".format(len(remove_inds)))\n",
    "    keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"{} samples remaining\".format(len(keep_inds)))\n",
    "    for sig in data.keys():\n",
    "        data[sig] = data[sig][list(keep_inds)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_ECH(data, verbose):\n",
    "    if verbose:\n",
    "        print('Removing ECH')\n",
    "    ech_inds = np.nonzero(np.any(data['ech'] > .5, axis=1))[0]\n",
    "    if len(ech_inds)==0:\n",
    "        return data\n",
    "    remove_inds = prune_loop(ech_inds,data['shotnum'],data['time'])\n",
    "    if verbose:\n",
    "        print(\"Removed {} samples\".format(len(remove_inds)))\n",
    "    keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"{} samples remaining\".format(len(keep_inds)))\n",
    "    for sig in data.keys():\n",
    "        data[sig] = data[sig][list(keep_inds)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_nan(data, verbose):\n",
    "    if verbose:\n",
    "        print('Removing NaN')\n",
    "    remove_inds = []\n",
    "    for sig in data.keys():\n",
    "        if data[sig].ndim==1:\n",
    "            remove_inds += np.where(np.isnan(data[sig]))[0].tolist()\n",
    "        else:\n",
    "            ax = tuple(np.arange(1,data[sig].ndim).astype(int))\n",
    "            remove_inds += np.where(np.any(np.isnan(data[sig]),axis=ax))[0].tolist()\n",
    "    remove_inds = np.unique(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"Removed {} samples\".format(len(remove_inds)))\n",
    "    keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
    "    if verbose:\n",
    "        print(\"{} samples remaining\".format(len(keep_inds)))\n",
    "    for sig in data.keys():\n",
    "        data[sig] = data[sig][list(keep_inds)]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from tqdm import tqdm\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def normalize_arr(data, method, uniform_over_profile=True):\n",
    "    \"\"\"Normalizes data before training\n",
    "\n",
    "    Args:\n",
    "        data: Numpy array. Array.shape[0] = samples\n",
    "        method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
    "            `RobustScaler`, `PowerTransform`.\n",
    "        uniform_over_profile (bool): 'True' uses the same normalization\n",
    "            parameters over a whole profile, 'False' normalizes each spatial\n",
    "            point separately.\n",
    "\n",
    "    Returns:\n",
    "        data: Numpy array of normalized data.\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
    "    \"\"\"\n",
    "    param_dict = {}\n",
    "    # first replace all infs and nans with mean value\n",
    "    data[np.isinf(data)] = np.nan\n",
    "    nanmean = np.nanmean(data, axis=(0, 1))\n",
    "    param_dict['nanmean'] = nanmean\n",
    "    if data.ndim > 2:\n",
    "        for i in range(data.shape[2]):\n",
    "            data[np.isnan(data[:, :, i]), i] = nanmean[i]\n",
    "    else:\n",
    "        data[np.isnan(data)] = nanmean\n",
    "    # then normalize\n",
    "    if method == 'StandardScaler':\n",
    "        if uniform_over_profile or data.ndim < 3:\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "        else:\n",
    "            mean = np.mean(data, axis=(0, 1), keepdims=True)\n",
    "            std = np.std(data, axis=(0, 1), keepdims=True)\n",
    "        param_dict.update({'method': method,\n",
    "                           'mean': mean,\n",
    "                           'std': std})\n",
    "        return (data-mean)/np.maximum(std, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    elif method == 'MinMax':\n",
    "        if uniform_over_profile or data.ndim < 3:\n",
    "            armin = np.amin(data)\n",
    "            armax = np.amax(data)\n",
    "        else:\n",
    "            armin = np.amin(data, axis=(0, 1), keepdims=True)\n",
    "            armax = np.amax(data, axis=(0, 1), keepdims=True)\n",
    "        param_dict.update({'method': method,\n",
    "                           'armin': armin,\n",
    "                           'armax': armax})\n",
    "        return (data-armin)/np.maximum((armax-armin), np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    elif method == 'MaxAbs':\n",
    "        if uniform_over_profile or data.ndim < 3:\n",
    "            maxabs = np.amax(np.abs(data))\n",
    "        else:\n",
    "            maxabs = np.amax(np.abs(data), axis=(0, 1), keepdims=True)\n",
    "        param_dict.update({'method': method,\n",
    "                           'maxabs': maxabs})\n",
    "        return data/np.maximum(maxabs, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    elif method == 'RobustScaler':\n",
    "        if uniform_over_profile or data.ndim < 3:\n",
    "            median = np.median(data)\n",
    "            iqr = np.subtract(*np.percentile(data, [75, 25]))\n",
    "        else:\n",
    "            median = np.median(data, axis=0)\n",
    "            iqr = np.subtract(*np.percentile(data, [75, 25], axis=(0, 1)))\n",
    "        param_dict.update({'method': method,\n",
    "                           'median': median,\n",
    "                           'iqr': iqr})\n",
    "        return (data-median)/np.maximum(iqr, np.finfo(np.float32).eps), param_dict\n",
    "\n",
    "    elif method == 'PowerTransform':\n",
    "        def yeo_johnson_transform(x, lmbda):\n",
    "            \"\"\"Return transformed input x following Yeo-Johnson transform with\n",
    "            parameter lambda.\n",
    "            \"\"\"\n",
    "            out = np.zeros_like(x)\n",
    "            pos = x >= 0  # binary mask\n",
    "            # when x >= 0\n",
    "            if abs(lmbda) < np.finfo(np.float32).eps:\n",
    "                out[pos] = np.log1p(x[pos])\n",
    "            else:  # lmbda != 0\n",
    "                out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda\n",
    "            # when x < 0\n",
    "            if abs(lmbda - 2) > np.finfo(np.float32).eps:\n",
    "                out[~pos] = - \\\n",
    "                    (np.power(-x[~pos] + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
    "            else:  # lmbda == 2\n",
    "                out[~pos] = -np.log1p(-x[~pos])\n",
    "            return out\n",
    "\n",
    "        def yeo_johnson_optimize(x):\n",
    "            \"\"\"Find and return optimal lambda parameter of the Yeo-Johnson\n",
    "            transform by MLE, for observed data x.\n",
    "            Like for Box-Cox, MLE is done via the brent optimizer. From Scipy\n",
    "            \"\"\"\n",
    "            def _neg_log_likelihood(lmbda):\n",
    "                \"\"\"Return the negative log likelihood of the observed data x as a\n",
    "                function of lambda. From Scipy\"\"\"\n",
    "                x_trans = yeo_johnson_transform(x, lmbda)\n",
    "                n_samples = x.shape[0]\n",
    "                loglike = -n_samples / 2 * np.log(x_trans.var())\n",
    "                loglike += (lmbda - 1) * (np.sign(x) *\n",
    "                                          np.log1p(np.abs(x))).sum()\n",
    "                return -loglike\n",
    "            # choosing bracket -2, 2 like for boxcox\n",
    "            return optimize.brent(_neg_log_likelihood, brack=(-2, 2))\n",
    "        if uniform_over_profile or data.ndim < 3:\n",
    "            lmbda = yeo_johnson_optimize(data.flatten())\n",
    "            y = yeo_johnson_transform(\n",
    "                data.flatten(), lmbda).reshape(data.shape)\n",
    "            mean = np.mean(y)\n",
    "            std = np.std(y)\n",
    "        else:\n",
    "            y = np.zeros_like(data)\n",
    "            lmbda = np.array([yeo_johnson_optimize(data[:, :, i])\n",
    "                              for i in range(data.shape[2])])\n",
    "            for i, l in enumerate(lmbda):\n",
    "                y[:, :, i] = yeo_johnson_transform(data[:, :, i], l)\n",
    "            mean = np.mean(y, axis=(0, 1))\n",
    "            std = np.std(y, axis=(0, 1))\n",
    "        param_dict.update({'method': method,\n",
    "                           'lambda': lmbda,\n",
    "                           'mean': mean,\n",
    "                           'std': std})\n",
    "        return (y-mean)/np.maximum(std, np.finfo(np.float32).eps), param_dict\n",
    "    elif method is None or method == 'None':\n",
    "        param_dict.update({'method': method})\n",
    "        return data, param_dict\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization method\")\n",
    "\n",
    "\n",
    "def normalize(data, method, uniform_over_profile=True, verbose=1):\n",
    "    \"\"\"Normalizes data before training\n",
    "\n",
    "    Args:\n",
    "        data: Numpy array or dictionary of numpy arrays. If a dictionary, all\n",
    "            arrays are normalized using the same method, but each array with\n",
    "            respect to itself. Array.shape[0] = batches\n",
    "        method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
    "            `RobustScaler`, `PowerTransform`.\n",
    "        uniform_over_profile (bool): 'True' uses the same normalization\n",
    "            parameters over a whole profile, 'False' normalizes each spatial\n",
    "            point separately.\n",
    "        verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 abbreviates.\n",
    "\n",
    "    Returns:\n",
    "        data: Numpy array or dictionary of numpy arrays. Normalized data.\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
    "    \"\"\"\n",
    "    if type(data) is dict:\n",
    "        param_dict = {}\n",
    "        for key in tqdm(data.keys(), desc='Normalizing', ascii=True, dynamic_ncols=True,\n",
    "                        disable=not verbose==1):\n",
    "            if key not in ['time', 'shotnum']:\n",
    "                data[key], p = normalize_arr(\n",
    "                    data[key], method, uniform_over_profile)\n",
    "                param_dict[key] = p\n",
    "        return data, param_dict\n",
    "    else:\n",
    "        return normalize_arr(data, method, uniform_over_profile)\n",
    "\n",
    "\n",
    "def denormalize_arr(data, param_dict):\n",
    "    \"\"\"Denormalizes data after training\n",
    "\n",
    "    Args:\n",
    "        data: Numpy array of data to denorm.\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            to be used for denormalizing. Eg, mean, stddev, method, etc.\n",
    "\n",
    "    Returns:\n",
    "        data: Numpy array of denormalized data.\n",
    "    \"\"\"\n",
    "    eps = np.finfo('float32').eps\n",
    "    #for key, val in param_dict.items():\n",
    "    #    if K.is_tensor(val):\n",
    "    #        val = np.array(K.eval(val))\n",
    "    if param_dict['method'] == 'StandardScaler':\n",
    "        return data*np.maximum(param_dict['std'], eps) + param_dict['mean']\n",
    "    elif param_dict['method'] == 'MinMax':\n",
    "        return data*np.maximum((param_dict['armax']-param_dict['armin']), eps)\n",
    "        + param_dict['armin']\n",
    "    elif param_dict['method'] == 'MaxAbs':\n",
    "        return data*np.maximum(param_dict['maxabs'], eps)\n",
    "    elif param_dict['method'] == 'RobustScaler':\n",
    "        return data*np.maximum(param_dict['iqr'], eps) + param_dict['median']\n",
    "    elif param_dict['method'] == 'PowerTransform':\n",
    "        y = data*np.maximum(param_dict['std'], eps) + param_dict['mean']\n",
    "\n",
    "        def np_yeo_johnson_inverse_transform(x, lmbda):\n",
    "            \"\"\"Return inverse-transformed input x following Yeo-Johnson inverse\n",
    "            transform with parameter lambda. From Scipy\n",
    "            \"\"\"\n",
    "            x_inv = np.zeros_like(x)\n",
    "            pos = x >= 0\n",
    "            # when x >= 0\n",
    "            if np.abs(lmbda) < np.finfo(np.float32).eps:\n",
    "                x_inv[pos] = np.exp(x[pos]) - 1\n",
    "            else:  # lmbda != 0\n",
    "                x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1\n",
    "            # when x < 0\n",
    "            if np.abs(lmbda - 2) > np.finfo(np.float32).eps:\n",
    "                x_inv[~pos] = 1 - np.power(-(2 - lmbda) * x[~pos] + 1,\n",
    "                                           1 / (2 - lmbda))\n",
    "            else:  # lmbda == 2\n",
    "                x_inv[~pos] = 1 - np.exp(-x[~pos])\n",
    "            return x_inv\n",
    "        if param_dict['lambda'].size > 1:\n",
    "            for i, l in enumerate(param_dict['lambda']):\n",
    "                y[:, i] = np_yeo_johnson_inverse_transform(y[:, i], l)\n",
    "        else:\n",
    "            y = np_yeo_johnson_inverse_transform(\n",
    "                y.flatten(), param_dict['lambda']).reshape(y.shape)\n",
    "        return y\n",
    "    elif param_dict['method'] is None or param_dict['method'] == 'None':\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization method\")\n",
    "\n",
    "\n",
    "def denormalize(data, param_dict, verbose=1):\n",
    "    \"\"\"Denormalizes data after training\n",
    "\n",
    "    Args:\n",
    "        data: Numpy array or dictionary of numpy arrays.\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            to be used for denormalizing. Eg, mean, stddev, method, etc.\n",
    "        verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 abbreviates.\n",
    "\n",
    "    Returns:\n",
    "        data: Numpy array or dictionary of numpy arrays. Denormalized data.\n",
    "    \"\"\"\n",
    "    if type(data) is dict:\n",
    "        data=data.copy() # don't make changes in place\n",
    "        for key in tqdm(data.keys(), desc='Denormalizing', ascii=True, dynamic_ncols=True,\n",
    "                        disable=not verbose==1):\n",
    "            if key not in ['time', 'shotnum']:\n",
    "                data[key] = denormalize_arr(data[key], param_dict[key])\n",
    "        return data\n",
    "    else:\n",
    "        return denormalize_arr(data, param_dict)\n",
    "\n",
    "\n",
    "def renormalize(data, param_dict, verbose=1):\n",
    "    \"\"\"Normalizes data using already determined parameters\n",
    "\n",
    "    Args:\n",
    "        data: Numpy array or dictionary of numpy arrays of raw data.\n",
    "        param_dict (dict): Dictionary of parameters used during normalization,\n",
    "            Eg, mean, stddev, method, etc.\n",
    "        verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 abbreviates\n",
    "\n",
    "    Returns:\n",
    "        data: Numpy array or dictionary of numpy arrays. Normalized data.\n",
    "    \"\"\"\n",
    "    if type(data) is dict:\n",
    "        for key in tqdm(data.keys(), desc='Normalizing', ascii=True, dynamic_ncols=True,\n",
    "                        disable=not verbose==1):\n",
    "            if key not in ['time', 'shotnum']:\n",
    "                data[key] = renormalize(data[key], param_dict[key])\n",
    "        return data\n",
    "    else:\n",
    "        # first remove all inf/nan\n",
    "        data[np.isinf(data)] = np.nan\n",
    "        if data.ndim > 2:\n",
    "            for i in range(data.shape[2]):\n",
    "                data[np.isnan(data[:, :, i]), i] = param_dict['nanmean'][i]\n",
    "        else:\n",
    "            data[np.isnan(data)] = param_dict['nanmean']\n",
    "        # then normalize\n",
    "        if param_dict['method'] == 'StandardScaler':\n",
    "            return (data - param_dict['mean'])/np.maximum(\n",
    "                param_dict['std'], np.finfo(np.float32).eps)\n",
    "        elif param_dict['method'] == 'MinMax':\n",
    "            return (data - param_dict['armin'])/np.maximum(\n",
    "                (param_dict['armax']-param_dict['armin']), np.finfo(np.float32).eps)\n",
    "        elif param_dict['method'] == 'MaxAbs':\n",
    "            return data/np.maximum(param_dict['maxabs'], np.finfo(np.float32).eps)\n",
    "        elif param_dict['method'] == 'RobustScaler':\n",
    "            return (data - param_dict['median'])/np.maximum(\n",
    "                param_dict['iqr'], np.finfo(np.float32).eps)\n",
    "        elif param_dict['method'] == 'PowerTransform':\n",
    "            def yeo_johnson_transform(x, lmbda):\n",
    "                \"\"\"Return transformed input x following Yeo-Johnson transform with\n",
    "                parameter lambda.\n",
    "                \"\"\"\n",
    "                out = np.zeros_like(x)\n",
    "                pos = x >= 0  # binary mask\n",
    "                # when x >= 0\n",
    "                if abs(lmbda) < np.finfo(np.float32).eps:\n",
    "                    out[pos] = np.log1p(x[pos])\n",
    "                else:  # lmbda != 0\n",
    "                    out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda\n",
    "                # when x < 0\n",
    "                if abs(lmbda - 2) > np.finfo(np.float32).eps:\n",
    "                    out[~pos] = - \\\n",
    "                        (np.power(-x[~pos] + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
    "                else:  # lmbda == 2\n",
    "                    out[~pos] = -np.log1p(-x[~pos])\n",
    "                return out\n",
    "            y = data\n",
    "            if param_dict['lambda'].size > 1:\n",
    "                for i, l in enumerate(param_dict['lambda']):\n",
    "                    y[:, i] = yeo_johnson_transform(y[:, i], l)\n",
    "            else:\n",
    "                y = yeo_johnson_transform(\n",
    "                    y.flatten(), param_dict['lambda']).reshape(y.shape)\n",
    "            y = (y - param_dict['mean'])/np.maximum(\n",
    "                param_dict['std'], np.finfo(np.float32).eps)\n",
    "            return y\n",
    "        elif param_dict['method'] is None or param_dict['method'] == 'None':\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(\"Unknown normalization method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "scenario['sig_names'] = scenario['profile_names'] + scenario['scalar_names'] + scenario['actuator_names']\n",
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Signals: curr, ffprime_EFIT02, pinj, press_EFIT02, q_EFIT02, thomson_dens_EFIT02, thomson_temp_EFIT02, tinj\n",
      "Number of useable shots:  5740\n",
      "Number of shots used:  5740\n",
      "Total number of timesteps:  1517720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering: 100%|##########| 5740/5740 [00:51<00:00, 111.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shots with Complete NaN: [156351.], [156352.], [156403.], [156478.], [156481.], [156793.], [156796.], [157744.], [157747.], [158007.], [158008.], [159579.], [161179.], [164471.], [164473.], [164474.], [165187.], [165343.], [165714.], [165864.], [165885.], [165891.], [166428.], [167599.], [171541.], [172008.], [172051.], [172052.], [172053.], [172055.], [172065.], [172066.], [172067.], [172068.], [172069.], [172083.], [172084.], [172085.], [172090.], [172292.], [172293.], [172294.], [172295.], [172296.], [172297.], [172302.], [173989.], [174750.], [174755.], [174762.], [175708.], [175710.], [175711.], [176905.], [176997.], [177001.], [177002.], [177011.], [177020.], [178718.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking: 100%|##########| 21/21 [01:15<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052920 samples total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing ECH\n",
      "Removed 395616 samples\n",
      "657304 samples remaining\n",
      "Removing weird gas\n",
      "Removed 35929 samples\n",
      "621375 samples remaining\n",
      "Removing weird I-coils\n",
      "Removed 118826 samples\n",
      "502549 samples remaining\n",
      "Removing NaN\n",
      "Removed 0 samples\n",
      "502549 samples remaining\n",
      "Removing dudtrip\n",
      "Removed 16273 samples\n",
      "486276 samples remaining\n",
      "486276 samples remaining after pruning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing: 100%|##########| 21/21 [00:30<00:00,  1.44s/it]\n",
      "Splitting: 100%|##########| 21/21 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  486276\n",
      "Number of training samples:  389020\n",
      "Number of validation samples:  97256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 254.833 s\n",
       "File: <ipython-input-2-529bb85e402a>\n",
       "Function: process_data at line 15\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    15                                           def process_data(rawdata, sig_names, normalization_method, window_length=1,\n",
       "    16                                                            window_overlap=0, lookbacks={}, lookahead=3, sample_step=5,\n",
       "    17                                                            uniform_normalization=True, train_frac=0.7, val_frac=0.2,\n",
       "    18                                                            nshots=None,\n",
       "    19                                                            verbose=1, flattop_only=True, randomize=True, **kwargs):\n",
       "    20                                               \"\"\"Organize data into correct format for training\n",
       "    21                                           \n",
       "    22                                               Gathers raw data into bins, group into training sequences, normalize,\n",
       "    23                                               and split into training and validation sets.\n",
       "    24                                           \n",
       "    25                                               Args:\n",
       "    26                                                   rawdata (dict): Nested dictionary of raw signal data, or path to pickle.\n",
       "    27                                                       Should be of the form rawdata[shot][signal_name] = signal_data.\n",
       "    28                                                   sig_names (list): List of signal names as strings.\n",
       "    29                                                   normalization_method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
       "    30                                                       `RobustScaler`, `PowerTransform`.\n",
       "    31                                                   window_length (int): Number of samples to average over in each bin/window.\n",
       "    32                                                   window_overlap (int): How many timesteps to overlap windows.\n",
       "    33                                                   lookbacks (dict of int): How many window lengths for lookback for each sig.\n",
       "    34                                                   lookahead (int): How many window lengths to predict into the future.\n",
       "    35                                                   sample_step (int): How much to offset sequential training sequences.\n",
       "    36                                                       Step of 1 means sample[i] and sample[i+1] will be offset by 1, with\n",
       "    37                                                       the rest overlapping.\n",
       "    38                                                   uniform_normalization (bool): 'True' uses the same normalization\n",
       "    39                                                       parameters over a whole profile, 'False' normalizes each spatial\n",
       "    40                                                       point separately.\n",
       "    41                                                   val_frac (float): Fraction of samples to use for validation.\n",
       "    42                                                   nshots (int): How many shots to use. If None, all available will be used.\n",
       "    43                                                   verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 is abbreviated.\n",
       "    44                                                   flattop_only (bool): Whether to only include data from flattop.\n",
       "    45                                           \n",
       "    46                                               Returns:\n",
       "    47                                                   traindata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    48                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    49                                                   valdata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    50                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    51                                                   param_dict (dict): Dictionary of parameters used during normalization,\n",
       "    52                                                       to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
       "    53                                               \"\"\"\n",
       "    54                                               ##############################\n",
       "    55                                               # Load data\n",
       "    56                                               ##############################\n",
       "    57         1         18.0     18.0      0.0      if type(rawdata) is not dict:\n",
       "    58         1         15.0     15.0      0.0          if verbose:\n",
       "    59         1        149.0    149.0      0.0              print('Loading')\n",
       "    60         1        645.0    645.0      0.0          abs_path = Path(rawdata).resolve()\n",
       "    61         1         51.0     51.0      0.0          if abs_path.exists():\n",
       "    62         1        130.0    130.0      0.0              with open(abs_path, 'rb') as f:\n",
       "    63         1   32385816.0 32385816.0     12.7                  rawdata = pickle.load(f, encoding='latin1')\n",
       "    64                                                   else:\n",
       "    65                                                       print(abs_path)\n",
       "    66                                                       raise IOError(\"No such path to data file\")\n",
       "    67                                                       \n",
       "    68                                               ##############################\n",
       "    69                                               # get pruning functions\n",
       "    70                                               ##############################\n",
       "    71         1         14.0     14.0      0.0      pruning_functions = kwargs.get('pruning_functions', [])\n",
       "    72         1         12.0     12.0      0.0      if 'ech' not in sig_names:\n",
       "    73         1         11.0     11.0      0.0          pruning_functions.append('remove_ECH')\n",
       "    74         1         17.0     17.0      0.0      if not {'gasB', 'gasC', 'gasD', 'gasE'}.issubset(set(sig_names)):\n",
       "    75         1         13.0     13.0      0.0          pruning_functions.append('remove_gas')\n",
       "    76         1         10.0     10.0      0.0      prun_dict = {'remove_nan': remove_nan,\n",
       "    77         1         10.0     10.0      0.0                   'remove_ECH': remove_ECH,\n",
       "    78         1         10.0     10.0      0.0                   'remove_I_coil': remove_I_coil,\n",
       "    79         1         10.0     10.0      0.0                   'remove_gas': remove_gas,\n",
       "    80         1         11.0     11.0      0.0                   'remove_dudtrip': remove_dudtrip}\n",
       "    81         6         65.0     10.8      0.0      for i, elem in enumerate(pruning_functions):\n",
       "    82         5         59.0     11.8      0.0          if isinstance(elem, str):\n",
       "    83         5         54.0     10.8      0.0              pruning_functions[i] = prun_dict[elem]\n",
       "    84                                           \n",
       "    85                                               ##############################\n",
       "    86                                               # get excluded shots\n",
       "    87                                               ##############################\n",
       "    88         1         11.0     11.0      0.0      excluded_shots = kwargs.get('excluded_shots', [])\n",
       "    89         1         11.0     11.0      0.0      exclude_dict = {'topology_TOP': exclude_shots.topology_TOP,\n",
       "    90         1         13.0     13.0      0.0                      'topology_SNT': exclude_shots.topology_SNT,\n",
       "    91         1         11.0     11.0      0.0                      'topology_SNB': exclude_shots.topology_SNB,\n",
       "    92         1         11.0     11.0      0.0                      'topology_OUT': exclude_shots.topology_OUT,\n",
       "    93         1         11.0     11.0      0.0                      'topology_MAR': exclude_shots.topology_MAR,\n",
       "    94         1         11.0     11.0      0.0                      'topology_IN': exclude_shots.topology_IN,\n",
       "    95         1         10.0     10.0      0.0                      'topology_DN': exclude_shots.topology_DN,\n",
       "    96         1         12.0     12.0      0.0                      'topology_BOT': exclude_shots.topology_BOT}\n",
       "    97         7         72.0     10.3      0.0      for i, elem in enumerate(excluded_shots):\n",
       "    98         6         61.0     10.2      0.0          if isinstance(elem, str):\n",
       "    99         6         61.0     10.2      0.0              excluded_shots[i] = exclude_dict[elem]\n",
       "   100         6         63.0     10.5      0.0          if not isinstance(elem, list):\n",
       "   101         6         63.0     10.5      0.0              excluded_shots[i] = [elem]\n",
       "   102         1         19.0     19.0      0.0      excluded_shots = [item for sublist in excluded_shots for item in sublist]\n",
       "   103                                           \n",
       "   104                                               ##############################\n",
       "   105                                               # get sig names\n",
       "   106                                               ##############################\n",
       "   107         1         11.0     11.0      0.0      extra_sigs = ['time', 'shotnum']\n",
       "   108         1         11.0     11.0      0.0      if remove_dudtrip in pruning_functions:\n",
       "   109         1         11.0     11.0      0.0          extra_sigs += ['dud_trip']\n",
       "   110         1         10.0     10.0      0.0      if remove_I_coil in pruning_functions:\n",
       "   111         1         11.0     11.0      0.0          extra_sigs += ['bt', 'curr', 'C_coil_method', 'I_coil_method']\n",
       "   112         1         11.0     11.0      0.0      if remove_gas in pruning_functions:\n",
       "   113         1         11.0     11.0      0.0          extra_sigs += ['gasB', 'gasC', 'gasD', 'gasE', 'pfx1', 'pfx2']\n",
       "   114         1         10.0     10.0      0.0      if remove_ECH in pruning_functions:\n",
       "   115         1         13.0     13.0      0.0          extra_sigs += ['ech']\n",
       "   116         1       4501.0   4501.0      0.0      sig_names = list(np.unique(sig_names))\n",
       "   117         1         84.0     84.0      0.0      sigsplustime = list(np.unique(sig_names + extra_sigs))\n",
       "   118         1         11.0     11.0      0.0      if verbose:\n",
       "   119         1        127.0    127.0      0.0          print('Signals: ' + ', '.join(sig_names))\n",
       "   120                                           \n",
       "   121                                               ##############################\n",
       "   122                                               # figure out lookbacks\n",
       "   123                                               ##############################\n",
       "   124         1         11.0     11.0      0.0      if isinstance(lookbacks, int):\n",
       "   125         1         10.0     10.0      0.0          max_lookback = lookbacks\n",
       "   126         1         18.0     18.0      0.0          lookbacks = {sig: max_lookback for sig in sigsplustime}\n",
       "   127                                               else:\n",
       "   128                                                   max_lookback = 0\n",
       "   129                                                   for val in lookbacks.values():\n",
       "   130                                                       if val > max_lookback:\n",
       "   131                                                           max_lookback = val\n",
       "   132                                                   for sig in sigsplustime:\n",
       "   133                                                       if sig not in lookbacks.keys():\n",
       "   134                                                           lookbacks[sig] = max_lookback\n",
       "   135                                                       \n",
       "   136                                               ##############################\n",
       "   137                                               # find which shots have all the signals needed\n",
       "   138                                               ##############################\n",
       "   139         1         10.0     10.0      0.0      usabledata = []\n",
       "   140         1       1582.0   1582.0      0.0      all_shots = sorted(list(rawdata.keys()))\n",
       "   141     11062     114361.0     10.3      0.0      for shot in all_shots:\n",
       "   142     11061     283463.0     25.6      0.1          rawdata[shot]['shotnum'] = np.ones(rawdata[shot]['time'].shape[0])*shot\n",
       "   143     11061     246709.0     22.3      0.1          if set(sigsplustime).issubset(set(rawdata[shot].keys())) \\\n",
       "   144      5740      62383.0     10.9      0.0             and rawdata[shot]['time'].size > (max_lookback+lookahead) \\\n",
       "   145      5740      59598.0     10.4      0.0             and shot not in excluded_shots:\n",
       "   146      5740      60182.0     10.5      0.0              usabledata.append(rawdata[shot])\n",
       "   147         1        935.0    935.0      0.0      usabledata = np.array(usabledata)\n",
       "   148         1     541108.0 541108.0      0.2      del rawdata\n",
       "   149         1      34908.0  34908.0      0.0      gc.collect()\n",
       "   150         1         12.0     12.0      0.0      if nshots is not None:\n",
       "   151         1         37.0     37.0      0.0          nshots = np.minimum(nshots, len(usabledata))\n",
       "   152         1         15.0     15.0      0.0          usabledata = usabledata[:nshots]\n",
       "   153                                               else:\n",
       "   154                                                   nshots = len(usabledata)\n",
       "   155         1         10.0     10.0      0.0      if verbose:\n",
       "   156         1        176.0    176.0      0.0          print('Number of useable shots: ', str(len(usabledata)))\n",
       "   157         1        122.0    122.0      0.0          print('Number of shots used: ', str(nshots))\n",
       "   158         1        493.0    493.0      0.0          sys.stdout.flush()\n",
       "   159         1         11.0     11.0      0.0      if verbose:\n",
       "   160         1         10.0     10.0      0.0          t = 0\n",
       "   161      5741      60628.0     10.6      0.0          for shot in usabledata:\n",
       "   162      5740      67834.0     11.8      0.0              t += shot['time'].size\n",
       "   163         1        464.0    464.0      0.0          print('Total number of timesteps: ', str(t))\n",
       "   164         1        440.0    440.0      0.0          sys.stdout.flush()\n",
       "   165                                                   \n",
       "   166                                               ##############################\n",
       "   167                                               # some helper functions\n",
       "   168                                               ##############################          \n",
       "   169         1         11.0     11.0      0.0      def moving_average(a, n):\n",
       "   170                                                   \"\"\"moving average of array a with window size n\"\"\"\n",
       "   171                                                   ret = np.nancumsum(a, axis=0)\n",
       "   172                                                   ret[n:] = ret[n:] - ret[:-n]\n",
       "   173                                                   return ret[n - 1:] / n\n",
       "   174                                           \n",
       "   175         1         10.0     10.0      0.0      def is_valid(shot):\n",
       "   176                                                   \"\"\"checks if a shot is completely NaN or if it never reached flattop\"\"\"\n",
       "   177                                                   for sig in sigsplustime:\n",
       "   178                                                       if np.isnan(shot[sig]).all():  # or np.isinf(shot[sig]).any():\n",
       "   179                                                           return False\n",
       "   180                                                   if (flattop_only):\n",
       "   181                                                       if (shot['t_ip_flat'] == None or shot['ip_flat_duration'] == None):\n",
       "   182                                                           return False\n",
       "   183                                                   return True\n",
       "   184                                           \n",
       "   185         1         10.0     10.0      0.0      def get_non_nan_inds(arr):\n",
       "   186                                                   \"\"\"gets indices of array where value is not NaN\"\"\"\n",
       "   187                                                   if len(arr.shape) == 1:\n",
       "   188                                                       return np.where(~np.isnan(arr))[0]\n",
       "   189                                                   else:\n",
       "   190                                                       return np.where(np.any(~np.isnan(arr), axis=1))[0]\n",
       "   191                                           \n",
       "   192         1         11.0     11.0      0.0      def get_first_index(shot):\n",
       "   193                                                   \"\"\"gets index of first valid timeslice for a shot\"\"\"\n",
       "   194                                                   input_max = max([get_non_nan_inds(shot[sig])[0] +\n",
       "   195                                                                    lookbacks[sig] for sig in sig_names])\n",
       "   196                                                   output_max = max([get_non_nan_inds(shot[sig])[0] -\n",
       "   197                                                                     lookahead for sig in sig_names])\n",
       "   198                                                   if (flattop_only) and (shot['t_ip_flat'] != None):\n",
       "   199                                                       current_max = np.searchsorted(\n",
       "   200                                                           shot['time'], shot['t_ip_flat'], side='left')\n",
       "   201                                                       return np.ceil(max(input_max, output_max, current_max)).astype(int)\n",
       "   202                                                   else:\n",
       "   203                                                       return np.ceil(max(input_max, output_max)).astype(int)\n",
       "   204                                           \n",
       "   205         1         10.0     10.0      0.0      def get_last_index(shot):\n",
       "   206                                                   \"\"\"gets index of last valid timeslice for a shot\"\"\"\n",
       "   207                                                   partial_min = min([get_non_nan_inds(shot[sig])[-1]\n",
       "   208                                                                      for sig in sig_names])\n",
       "   209                                                   full_min = min([get_non_nan_inds(shot[sig])[-1] -\n",
       "   210                                                                   lookahead for sig in sig_names])\n",
       "   211                                                   if (flattop_only) and (shot['t_ip_flat'] != None) and (shot['ip_flat_duration'] != None):\n",
       "   212                                                       current_min = np.searchsorted(\n",
       "   213                                                           shot['time'], shot['t_ip_flat']+shot['ip_flat_duration'], side='right')\n",
       "   214                                                       return np.floor(min(full_min, partial_min, current_min)).astype(int)\n",
       "   215                                                   else:\n",
       "   216                                                       return np.floor(min(full_min, partial_min)).astype(int)\n",
       "   217                                               \n",
       "   218         1       1867.0   1867.0      0.0      @numba.njit\n",
       "   219                                               def group_data(array,first,last,sample_step,lookback, lookahead):\n",
       "   220                                                   \"\"\"groups shot data into i/o chunks\"\"\"\n",
       "   221                                                   data = []\n",
       "   222                                                   for i in range(first,last,sample_step):\n",
       "   223                                                       data.append(array[i-lookback:i+lookahead+1])\n",
       "   224                                                   return data\n",
       "   225                                               \n",
       "   226                                               ##############################\n",
       "   227                                               # loop through shots and do stuff\n",
       "   228                                               ##############################\n",
       "   229         1         11.0     11.0      0.0      alldata = {}\n",
       "   230         1         11.0     11.0      0.0      shots_with_complete_nan = []\n",
       "   231        22        231.0     10.5      0.0      for sig in sigsplustime:\n",
       "   232        21        223.0     10.6      0.0          alldata[sig] = []  # initalize empty lists\n",
       "   233         1         10.0     10.0      0.0      for shot in tqdm(usabledata, desc='Gathering', ascii=True, dynamic_ncols=True,\n",
       "   234      5741     496190.0     86.4      0.2                       disable=not verbose == 1):\n",
       "   235                                                   ##############################\n",
       "   236                                                   # take moving average of data and bin it\n",
       "   237                                                   ##############################\n",
       "   238      5740      64037.0     11.2      0.0          binned_shot = {}\n",
       "   239    126280    1355209.0     10.7      0.5          for sig in sigsplustime:\n",
       "   240    120540    4507650.0     37.4      1.8              if np.any(np.isinf(shot[sig])):\n",
       "   241                                                           shot[sig][np.isinf(shot[sig])] = np.nan            \n",
       "   242    120540   12697417.0    105.3      5.0              binned_shot[sig] = moving_average(shot[sig],window_length)[::window_length-window_overlap]\n",
       "   243      5740      68908.0     12.0      0.0          binned_shot['t_ip_flat'] = shot['t_ip_flat']\n",
       "   244      5740      62686.0     10.9      0.0          binned_shot['ip_flat_duration'] = shot['ip_flat_duration']\n",
       "   245      5740    1487941.0    259.2      0.6          if not is_valid(binned_shot):\n",
       "   246        60       3255.0     54.2      0.0              shots_with_complete_nan.append(np.unique(shot[\"shotnum\"]))\n",
       "   247        60        632.0     10.5      0.0              continue\n",
       "   248                                           \n",
       "   249                                                   ##############################\n",
       "   250                                                   # group into arrays of input/output pairs\n",
       "   251                                                   ##############################\n",
       "   252      5680    4338084.0    763.7      1.7          first = get_first_index(binned_shot)\n",
       "   253      5680    4314071.0    759.5      1.7          last = get_last_index(binned_shot)\n",
       "   254    124960    1323667.0     10.6      0.5          for sig in sigsplustime:\n",
       "   255    119280   11087000.0     92.9      4.4              alldata[sig] += group_data(binned_shot[sig],first,last,sample_step,lookbacks[sig],lookahead)\n",
       "   256                                           \n",
       "   257         1         11.0     11.0      0.0      if verbose:\n",
       "   258         1         16.0     16.0      0.0          print(\"Shots with Complete NaN: \" + ', '.join(str(e)\n",
       "   259         1      24902.0  24902.0      0.0                                                        for e in shots_with_complete_nan))\n",
       "   260         1        444.0    444.0      0.0      sys.stdout.flush()\n",
       "   261         1     904660.0 904660.0      0.4      del usabledata\n",
       "   262         1     783463.0 783463.0      0.3      gc.collect()\n",
       "   263                                               \n",
       "   264                                               ##############################\n",
       "   265                                               # stack data from all shots together\n",
       "   266                                               ##############################    \n",
       "   267         1         21.0     21.0      0.0      for sig in tqdm(sigsplustime, desc='Stacking', ascii=True, dynamic_ncols=True,\n",
       "   268        22     489392.0  22245.1      0.2                      disable=not verbose == 1):\n",
       "   269        21   74940588.0 3568599.4     29.4          alldata[sig] = np.stack(alldata[sig])\n",
       "   270         1         93.0     93.0      0.0      print(\"{} samples total\".format(len(alldata['time'])))\n",
       "   271         1        622.0    622.0      0.0      sys.stdout.flush()\n",
       "   272                                               ##############################\n",
       "   273                                               # apply pruning functions\n",
       "   274                                               ##############################\n",
       "   275                                               # call fns in the right order to speed things up\n",
       "   276         1         13.0     13.0      0.0      if remove_ECH in pruning_functions:\n",
       "   277         1   31096849.0 31096849.0     12.2          alldata = remove_ECH(alldata,verbose)\n",
       "   278         1         18.0     18.0      0.0      if remove_gas in pruning_functions:\n",
       "   279         1    4510252.0 4510252.0      1.8          alldata = remove_gas(alldata,verbose)\n",
       "   280         1         15.0     15.0      0.0      if remove_I_coil in pruning_functions:\n",
       "   281         1   24754978.0 24754978.0      9.7          alldata = remove_I_coil(alldata,verbose)\n",
       "   282         1         12.0     12.0      0.0      if remove_nan in pruning_functions:\n",
       "   283         1    3428652.0 3428652.0      1.3          alldata = remove_nan(alldata,verbose)\n",
       "   284         1         18.0     18.0      0.0      if remove_dudtrip in pruning_functions:\n",
       "   285         1    6144434.0 6144434.0      2.4          alldata = remove_dudtrip(alldata,verbose)\n",
       "   286                                           \n",
       "   287         1       1248.0   1248.0      0.0      print(\"{} samples remaining after pruning\".format(len(alldata['time'])))\n",
       "   288         1        955.0    955.0      0.0      sys.stdout.flush()\n",
       "   289                                               ##############################\n",
       "   290                                               # normalize data\n",
       "   291                                               ##############################    \n",
       "   292         1         11.0     11.0      0.0      alldata, normalization_params = normalize(\n",
       "   293         1   30311184.0 30311184.0     11.9          alldata, normalization_method, uniform_normalization, verbose)\n",
       "   294                                               \n",
       "   295                                               ##############################\n",
       "   296                                               # split into train and validation sets\n",
       "   297                                               ##############################    \n",
       "   298         1         14.0     14.0      0.0      nsamples = alldata['time'].shape[0]\n",
       "   299         1      11398.0  11398.0      0.0      inds = np.random.permutation(nsamples) if randomize else np.arange(nsamples)\n",
       "   300         1         14.0     14.0      0.0      traininds = inds[:int(nsamples*train_frac)]\n",
       "   301         1         11.0     11.0      0.0      valinds = inds[int(nsamples*train_frac)\n",
       "   302         1         13.0     13.0      0.0                         :int(nsamples*(val_frac+train_frac))]\n",
       "   303         1         10.0     10.0      0.0      traindata = {}\n",
       "   304         1         10.0     10.0      0.0      valdata = {}\n",
       "   305         1         35.0     35.0      0.0      for sig in tqdm(sigsplustime, desc='Splitting', ascii=True, dynamic_ncols=True,\n",
       "   306        22      16671.0    757.8      0.0                      disable=not verbose == 1):\n",
       "   307        21    1291389.0  61494.7      0.5          traindata[sig] = alldata[sig][traininds]\n",
       "   308        21     283114.0  13481.6      0.1          valdata[sig] = alldata[sig][valinds]\n",
       "   309         1     100125.0 100125.0      0.0      time.sleep(0.1)\n",
       "   310         1         11.0     11.0      0.0      if verbose:\n",
       "   311         1        172.0    172.0      0.0          print('Total number of samples: ', str(nsamples))\n",
       "   312         1        134.0    134.0      0.0          print('Number of training samples: ', str(traininds.size))\n",
       "   313         1        127.0    127.0      0.0          print('Number of validation samples: ', str(valinds.size))\n",
       "   314         1         10.0     10.0      0.0      return traindata, valdata, normalization_params\n",
       "\n",
       "Total time: 6.13958 s\n",
       "File: <ipython-input-3-3f2a7c9cc4af>\n",
       "Function: remove_dudtrip at line 20\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    20                                           def remove_dudtrip(data, verbose):\n",
       "    21         1          4.0      4.0      0.0      if verbose:\n",
       "    22         1        217.0    217.0      0.0          print('Removing dudtrip')\n",
       "    23         1      31437.0  31437.0      0.5      dud_trip_inds = np.nonzero(data['dud_trip'])[0]\n",
       "    24         1          6.0      6.0      0.0      if len(dud_trip_inds)==0:\n",
       "    25                                                   return data\n",
       "    26         1    4030495.0 4030495.0     65.6      remove_inds = prune_loop(dud_trip_inds,data['shotnum'],data['time'])\n",
       "    27         1          3.0      3.0      0.0      if verbose:\n",
       "    28         1        183.0    183.0      0.0          print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    29         1      23397.0  23397.0      0.4      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    30         1          3.0      3.0      0.0      if verbose:\n",
       "    31         1        168.0    168.0      0.0          print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    32        22        141.0      6.4      0.0      for sig in data.keys():\n",
       "    33        21    2053524.0  97786.9     33.4          data[sig] = data[sig][list(keep_inds)]\n",
       "    34         1          1.0      1.0      0.0      return data\n",
       "\n",
       "Total time: 24.7477 s\n",
       "File: <ipython-input-3-3f2a7c9cc4af>\n",
       "Function: remove_I_coil at line 37\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    37                                           def remove_I_coil(data, verbose):\n",
       "    38         1          2.0      2.0      0.0      if verbose:\n",
       "    39         1        181.0    181.0      0.0          print('Removing weird I-coils')\n",
       "    40                                               \n",
       "    41         1       2179.0   2179.0      0.0      @numba.njit\n",
       "    42                                               def find_Icoil_inds(n,bt,curr,C_coil_method,I_coil_method):\n",
       "    43                                                   c_coil = list()\n",
       "    44                                                   i_coil = list()\n",
       "    45                                                   EFC = list()\n",
       "    46                                                   for i in range(n):\n",
       "    47                                                       if np.mean(bt[i]*curr[i]) < 0:\n",
       "    48                                                           # left-handed\n",
       "    49                                                           if not set(np.unique(C_coil_method[i])).issubset({5, 0, -1}):\n",
       "    50                                                               c_coil.append(i)\n",
       "    51                                                           if not set(np.unique(I_coil_method[i])).issubset({5, 0, -1}):\n",
       "    52                                                               i_coil.append(i)\n",
       "    53                                                           if not np.all(np.logical_xor(C_coil_method[i] == 5, I_coil_method[i] == 5)):\n",
       "    54                                                               EFC.append(i)\n",
       "    55                                                       else:\n",
       "    56                                                           # right-handed\n",
       "    57                                                           if not set(np.unique(C_coil_method[i])).issubset({6, 0, -1}):\n",
       "    58                                                               c_coil.append(i)\n",
       "    59                                                           if not set(np.unique(I_coil_method[i])).issubset({7, 0, -1}):\n",
       "    60                                                               i_coil.append(i)\n",
       "    61                                                           if not np.any(np.logical_or(np.logical_and(C_coil_method[i] == 6, \n",
       "    62                                                                                                      I_coil_method[i] != 7), \n",
       "    63                                                                                       np.logical_and(C_coil_method[i] != 6, \n",
       "    64                                                                                                      I_coil_method[i] == 7))):\n",
       "    65                                                               EFC.append(i)\n",
       "    66                                                               \n",
       "    67                                                   coil_inds = c_coil + i_coil + EFC\n",
       "    68                                                   return coil_inds\n",
       "    69                                           \n",
       "    70         1          8.0      8.0      0.0      coil_inds = np.unique(find_Icoil_inds(len(data['time']),\n",
       "    71         1          3.0      3.0      0.0                                            data['bt'],\n",
       "    72         1          2.0      2.0      0.0                                            data['curr'],\n",
       "    73         1       1674.0   1674.0      0.0                                            data['C_coil_method'].astype(int),\n",
       "    74         1   14865613.0 14865613.0     60.1                                            data['I_coil_method'].astype(int)))\n",
       "    75         1          7.0      7.0      0.0      if len(coil_inds)==0:\n",
       "    76                                                   return data\n",
       "    77         1    7701478.0 7701478.0     31.1      remove_inds = prune_loop(coil_inds,data['shotnum'],data['time'])\n",
       "    78         1          4.0      4.0      0.0      if verbose:\n",
       "    79         1        210.0    210.0      0.0          print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    80         1      32493.0  32493.0      0.1      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    81         1          3.0      3.0      0.0      if verbose:\n",
       "    82         1        171.0    171.0      0.0          print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    83        22        148.0      6.7      0.0      for sig in data.keys():\n",
       "    84        21    2143505.0 102071.7      8.7          data[sig] = data[sig][list(keep_inds)]\n",
       "    85         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 4.5029 s\n",
       "File: <ipython-input-3-3f2a7c9cc4af>\n",
       "Function: remove_gas at line 88\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    88                                           def remove_gas(data, verbose):\n",
       "    89         1          2.0      2.0      0.0      if verbose:\n",
       "    90         1        196.0    196.0      0.0          print('Removing weird gas')\n",
       "    91         1         26.0     26.0      0.0      from functools import reduce\n",
       "    92         1          1.0      1.0      0.0      threshold=2\n",
       "    93         1      14792.0  14792.0      0.3      gasB_inds = np.nonzero(np.any(data['gasB'] > threshold, axis=1))[0]\n",
       "    94         1      15971.0  15971.0      0.4      gasC_inds = np.nonzero(np.any(data['gasC'] > threshold, axis=1))[0]\n",
       "    95         1      15917.0  15917.0      0.4      gasD_inds = np.nonzero(np.any(data['gasD'] > threshold, axis=1))[0]\n",
       "    96         1      13818.0  13818.0      0.3      gasE_inds = np.nonzero(np.any(data['gasE'] > threshold, axis=1))[0]\n",
       "    97         1      13327.0  13327.0      0.3      pfx1_inds = np.nonzero(np.any(data['pfx1'] > threshold, axis=1))[0]\n",
       "    98         1      13846.0  13846.0      0.3      pfx2_inds = np.nonzero(np.any(data['pfx2'] > threshold, axis=1))[0]\n",
       "    99         1          8.0      8.0      0.0      gas_inds = reduce(np.union1d, (gasB_inds, gasC_inds,\n",
       "   100         1       2714.0   2714.0      0.1                                     gasD_inds, gasE_inds, pfx1_inds, pfx2_inds))\n",
       "   101         1          3.0      3.0      0.0      if len(gas_inds)==0:\n",
       "   102                                                   return data\n",
       "   103         1    1407489.0 1407489.0     31.3      remove_inds = prune_loop(gas_inds,data['shotnum'],data['time'])\n",
       "   104         1          4.0      4.0      0.0      if verbose:\n",
       "   105         1        462.0    462.0      0.0          print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   106         1      38116.0  38116.0      0.8      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   107         1          4.0      4.0      0.0      if verbose:\n",
       "   108         1        204.0    204.0      0.0          print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   109        22        148.0      6.7      0.0      for sig in data.keys():\n",
       "   110        21    2965852.0 141231.0     65.9          data[sig] = data[sig][list(keep_inds)]\n",
       "   111         1          1.0      1.0      0.0      return data\n",
       "\n",
       "Total time: 31.0835 s\n",
       "File: <ipython-input-3-3f2a7c9cc4af>\n",
       "Function: remove_ECH at line 114\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   114                                           def remove_ECH(data, verbose):\n",
       "   115         1          2.0      2.0      0.0      if verbose:\n",
       "   116         1         86.0     86.0      0.0          print('Removing ECH')\n",
       "   117         1      35690.0  35690.0      0.1      ech_inds = np.nonzero(np.any(data['ech'] > .5, axis=1))[0]\n",
       "   118         1          3.0      3.0      0.0      if len(ech_inds)==0:\n",
       "   119                                                   return data\n",
       "   120         1   26516817.0 26516817.0     85.3      remove_inds = prune_loop(ech_inds,data['shotnum'],data['time'])\n",
       "   121         1          3.0      3.0      0.0      if verbose:\n",
       "   122         1       1029.0   1029.0      0.0          print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   123         1      71881.0  71881.0      0.2      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   124         1          3.0      3.0      0.0      if verbose:\n",
       "   125         1        193.0    193.0      0.0          print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   126        22        152.0      6.9      0.0      for sig in data.keys():\n",
       "   127        21    4457643.0 212268.7     14.3          data[sig] = data[sig][list(keep_inds)]\n",
       "   128         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 3.42298 s\n",
       "File: <ipython-input-3-3f2a7c9cc4af>\n",
       "Function: remove_nan at line 131\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   131                                           def remove_nan(data, verbose):\n",
       "   132         1          2.0      2.0      0.0      if verbose:\n",
       "   133         1        162.0    162.0      0.0          print('Removing NaN')\n",
       "   134         1          2.0      2.0      0.0      remove_inds = []\n",
       "   135        22         61.0      2.8      0.0      for sig in data.keys():\n",
       "   136        21         60.0      2.9      0.0          if data[sig].ndim==1:\n",
       "   137                                                       remove_inds += np.where(np.isnan(data[sig]))[0].tolist()\n",
       "   138                                                   else:\n",
       "   139        21        518.0     24.7      0.0              ax = tuple(np.arange(1,data[sig].ndim).astype(int))\n",
       "   140        21    1067035.0  50811.2     31.2              remove_inds += np.where(np.any(np.isnan(data[sig]),axis=ax))[0].tolist()\n",
       "   141         1        102.0    102.0      0.0      remove_inds = np.unique(remove_inds)\n",
       "   142         1          2.0      2.0      0.0      if verbose:\n",
       "   143         1        171.0    171.0      0.0          print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   144         1      24700.0  24700.0      0.7      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   145         1          4.0      4.0      0.0      if verbose:\n",
       "   146         1        167.0    167.0      0.0          print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   147        22        156.0      7.1      0.0      for sig in data.keys():\n",
       "   148        21    2329838.0 110944.7     68.1          data[sig] = data[sig][list(keep_inds)]\n",
       "   149         1          2.0      2.0      0.0      return data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f process_data -f remove_dudtrip -f remove_I_coil -f remove_gas -f remove_ECH -f remove_nan process_data(scenario['raw_data_path'],scenario['sig_names'],scenario['normalization_method'],scenario['window_length'],scenario['window_overlap'],scenario['lookback'],scenario['lookahead'],scenario['sample_step'],scenario['uniform_normalization'],scenario['train_frac'],scenario['val_frac'],scenario['nshots'],verbose,scenario['flattop_only'],pruning_functions=scenario['pruning_functions'],excluded_shots=scenario['excluded_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052920 samples total\n",
      "486276 samples remaining after pruning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 251.249 s\n",
       "File: <ipython-input-261-9ed60b859aca>\n",
       "Function: process_data at line 13\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    13                                           def process_data(rawdata, sig_names, normalization_method, window_length=1,\n",
       "    14                                                            window_overlap=0, lookbacks={}, lookahead=3, sample_step=5,\n",
       "    15                                                            uniform_normalization=True, train_frac=0.7, val_frac=0.2,\n",
       "    16                                                            nshots=None,\n",
       "    17                                                            verbose=1, flattop_only=True, randomize=True, **kwargs):\n",
       "    18                                               \"\"\"Organize data into correct format for training\n",
       "    19                                           \n",
       "    20                                               Gathers raw data into bins, group into training sequences, normalize,\n",
       "    21                                               and split into training and validation sets.\n",
       "    22                                           \n",
       "    23                                               Args:\n",
       "    24                                                   rawdata (dict): Nested dictionary of raw signal data, or path to pickle.\n",
       "    25                                                       Should be of the form rawdata[shot][signal_name] = signal_data.\n",
       "    26                                                   sig_names (list): List of signal names as strings.\n",
       "    27                                                   normalization_method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
       "    28                                                       `RobustScaler`, `PowerTransform`.\n",
       "    29                                                   window_length (int): Number of samples to average over in each bin/window.\n",
       "    30                                                   window_overlap (int): How many timesteps to overlap windows.\n",
       "    31                                                   lookbacks (dict of int): How many window lengths for lookback for each sig.\n",
       "    32                                                   lookahead (int): How many window lengths to predict into the future.\n",
       "    33                                                   sample_step (int): How much to offset sequential training sequences.\n",
       "    34                                                       Step of 1 means sample[i] and sample[i+1] will be offset by 1, with\n",
       "    35                                                       the rest overlapping.\n",
       "    36                                                   uniform_normalization (bool): 'True' uses the same normalization\n",
       "    37                                                       parameters over a whole profile, 'False' normalizes each spatial\n",
       "    38                                                       point separately.\n",
       "    39                                                   val_frac (float): Fraction of samples to use for validation.\n",
       "    40                                                   nshots (int): How many shots to use. If None, all available will be used.\n",
       "    41                                                   verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 is abbreviated.\n",
       "    42                                                   flattop_only (bool): Whether to only include data from flattop.\n",
       "    43                                           \n",
       "    44                                               Returns:\n",
       "    45                                                   traindata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    46                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    47                                                   valdata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    48                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    49                                                   param_dict (dict): Dictionary of parameters used during normalization,\n",
       "    50                                                       to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
       "    51                                               \"\"\"\n",
       "    52                                               ##############################\n",
       "    53                                               # Load data\n",
       "    54                                               ##############################\n",
       "    55         1         12.0     12.0      0.0      if type(rawdata) is not dict:\n",
       "    56         1         11.0     11.0      0.0          if verbose:\n",
       "    57                                                       print('Loading')\n",
       "    58         1       2133.0   2133.0      0.0          abs_path = Path(rawdata).resolve()\n",
       "    59         1         46.0     46.0      0.0          if abs_path.exists():\n",
       "    60         1        250.0    250.0      0.0              with open(abs_path, 'rb') as f:\n",
       "    61         1   28384003.0 28384003.0     11.3                  rawdata = pickle.load(f, encoding='latin1')\n",
       "    62                                                   else:\n",
       "    63                                                       print(abs_path)\n",
       "    64                                                       raise IOError(\"No such path to data file\")\n",
       "    65                                                       \n",
       "    66                                               ##############################\n",
       "    67                                               # get pruning functions\n",
       "    68                                               ##############################\n",
       "    69         1         15.0     15.0      0.0      pruning_functions = kwargs.get('pruning_functions', [])\n",
       "    70         1         14.0     14.0      0.0      if 'ech' not in sig_names:\n",
       "    71         1         12.0     12.0      0.0          pruning_functions.append('remove_ECH')\n",
       "    72         1         25.0     25.0      0.0      if not {'gasB', 'gasC', 'gasD', 'gasE'}.issubset(set(sig_names)):\n",
       "    73         1         11.0     11.0      0.0          pruning_functions.append('remove_gas')\n",
       "    74         1         13.0     13.0      0.0      prun_dict = {'remove_nan': remove_nan,\n",
       "    75         1         10.0     10.0      0.0                   'remove_ECH': remove_ECH,\n",
       "    76         1         11.0     11.0      0.0                   'remove_I_coil': remove_I_coil,\n",
       "    77         1         11.0     11.0      0.0                   'remove_gas': remove_gas,\n",
       "    78         1         12.0     12.0      0.0                   'remove_dudtrip': remove_dudtrip}\n",
       "    79         6         69.0     11.5      0.0      for i, elem in enumerate(pruning_functions):\n",
       "    80         5         54.0     10.8      0.0          if isinstance(elem, str):\n",
       "    81         5         56.0     11.2      0.0              pruning_functions[i] = prun_dict[elem]\n",
       "    82                                           \n",
       "    83                                               ##############################\n",
       "    84                                               # get excluded shots\n",
       "    85                                               ##############################\n",
       "    86         1         11.0     11.0      0.0      excluded_shots = kwargs.get('excluded_shots', [])\n",
       "    87         1         14.0     14.0      0.0      exclude_dict = {'topology_TOP': exclude_shots.topology_TOP,\n",
       "    88         1         11.0     11.0      0.0                      'topology_SNT': exclude_shots.topology_SNT,\n",
       "    89         1         13.0     13.0      0.0                      'topology_SNB': exclude_shots.topology_SNB,\n",
       "    90         1         11.0     11.0      0.0                      'topology_OUT': exclude_shots.topology_OUT,\n",
       "    91         1         12.0     12.0      0.0                      'topology_MAR': exclude_shots.topology_MAR,\n",
       "    92         1         13.0     13.0      0.0                      'topology_IN': exclude_shots.topology_IN,\n",
       "    93         1         12.0     12.0      0.0                      'topology_DN': exclude_shots.topology_DN,\n",
       "    94         1         13.0     13.0      0.0                      'topology_BOT': exclude_shots.topology_BOT}\n",
       "    95         7         72.0     10.3      0.0      for i, elem in enumerate(excluded_shots):\n",
       "    96         6         61.0     10.2      0.0          if isinstance(elem, str):\n",
       "    97         6         65.0     10.8      0.0              excluded_shots[i] = exclude_dict[elem]\n",
       "    98         6         65.0     10.8      0.0          if not isinstance(elem, list):\n",
       "    99         6         63.0     10.5      0.0              excluded_shots[i] = [elem]\n",
       "   100         1         24.0     24.0      0.0      excluded_shots = [item for sublist in excluded_shots for item in sublist]\n",
       "   101                                           \n",
       "   102                                               ##############################\n",
       "   103                                               # get sig names\n",
       "   104                                               ##############################\n",
       "   105         1         11.0     11.0      0.0      extra_sigs = ['time', 'shotnum']\n",
       "   106         1         11.0     11.0      0.0      if remove_dudtrip in pruning_functions:\n",
       "   107         1         13.0     13.0      0.0          extra_sigs += ['dud_trip']\n",
       "   108         1         10.0     10.0      0.0      if remove_I_coil in pruning_functions:\n",
       "   109         1         11.0     11.0      0.0          extra_sigs += ['bt', 'curr', 'C_coil_method', 'I_coil_method']\n",
       "   110         1         10.0     10.0      0.0      if remove_gas in pruning_functions:\n",
       "   111         1         10.0     10.0      0.0          extra_sigs += ['gasB', 'gasC', 'gasD', 'gasE', 'pfx1', 'pfx2']\n",
       "   112         1         11.0     11.0      0.0      if remove_ECH in pruning_functions:\n",
       "   113         1         10.0     10.0      0.0          extra_sigs += ['ech']\n",
       "   114         1       3503.0   3503.0      0.0      sig_names = list(np.unique(sig_names))\n",
       "   115         1         91.0     91.0      0.0      sigsplustime = list(np.unique(sig_names + extra_sigs))\n",
       "   116         1         11.0     11.0      0.0      if verbose:\n",
       "   117                                                   print('Signals: ' + ', '.join(sig_names))\n",
       "   118                                           \n",
       "   119                                               ##############################\n",
       "   120                                               # figure out lookbacks\n",
       "   121                                               ##############################\n",
       "   122         1         11.0     11.0      0.0      if isinstance(lookbacks, int):\n",
       "   123         1         10.0     10.0      0.0          max_lookback = lookbacks\n",
       "   124         1         21.0     21.0      0.0          lookbacks = {sig: max_lookback for sig in sigsplustime}\n",
       "   125                                               else:\n",
       "   126                                                   max_lookback = 0\n",
       "   127                                                   for val in lookbacks.values():\n",
       "   128                                                       if val > max_lookback:\n",
       "   129                                                           max_lookback = val\n",
       "   130                                                   for sig in sigsplustime:\n",
       "   131                                                       if sig not in lookbacks.keys():\n",
       "   132                                                           lookbacks[sig] = max_lookback\n",
       "   133                                                       \n",
       "   134                                               ##############################\n",
       "   135                                               # find which shots have all the signals needed\n",
       "   136                                               ##############################\n",
       "   137         1         11.0     11.0      0.0      usabledata = []\n",
       "   138         1       1195.0   1195.0      0.0      all_shots = sorted(list(rawdata.keys()))\n",
       "   139     11062     115927.0     10.5      0.0      for shot in all_shots:\n",
       "   140     11061     288925.0     26.1      0.1          rawdata[shot]['shotnum'] = np.ones(rawdata[shot]['time'].shape[0])*shot\n",
       "   141     11061     239062.0     21.6      0.1          if set(sigsplustime).issubset(set(rawdata[shot].keys())) \\\n",
       "   142      5740      63580.0     11.1      0.0             and rawdata[shot]['time'].size > (max_lookback+lookahead) \\\n",
       "   143      5740      61263.0     10.7      0.0             and shot not in excluded_shots:\n",
       "   144      5740      61437.0     10.7      0.0              usabledata.append(rawdata[shot])\n",
       "   145         1        775.0    775.0      0.0      usabledata = np.array(usabledata)\n",
       "   146         1     477074.0 477074.0      0.2      del rawdata\n",
       "   147         1      95060.0  95060.0      0.0      gc.collect()\n",
       "   148         1         13.0     13.0      0.0      if nshots is not None:\n",
       "   149         1         58.0     58.0      0.0          nshots = np.minimum(nshots, len(usabledata))\n",
       "   150         1         21.0     21.0      0.0          usabledata = usabledata[:nshots]\n",
       "   151                                               else:\n",
       "   152                                                   nshots = len(usabledata)\n",
       "   153         1         11.0     11.0      0.0      if verbose:\n",
       "   154                                                   print('Number of useable shots: ', str(len(usabledata)))\n",
       "   155                                                   print('Number of shots used: ', str(nshots))\n",
       "   156         1         11.0     11.0      0.0      if verbose:\n",
       "   157                                                   t = 0\n",
       "   158                                                   for shot in usabledata:\n",
       "   159                                                       t += shot['time'].size\n",
       "   160                                                   print('Total number of timesteps: ', str(t))\n",
       "   161                                                   \n",
       "   162                                               ##############################\n",
       "   163                                               # some helper functions\n",
       "   164                                               ##############################          \n",
       "   165         1         11.0     11.0      0.0      def moving_average(a, n):\n",
       "   166                                                   \"\"\"moving average of array a with window size n\"\"\"\n",
       "   167                                                   ret = np.nancumsum(a, axis=0)\n",
       "   168                                                   ret[n:] = ret[n:] - ret[:-n]\n",
       "   169                                                   return ret[n - 1:] / n\n",
       "   170                                           \n",
       "   171         1         11.0     11.0      0.0      def is_valid(shot):\n",
       "   172                                                   \"\"\"checks if a shot is completely NaN or if it never reached flattop\"\"\"\n",
       "   173                                                   for sig in sigsplustime:\n",
       "   174                                                       if np.isnan(shot[sig]).all():  # or np.isinf(shot[sig]).any():\n",
       "   175                                                           return False\n",
       "   176                                                   if (flattop_only):\n",
       "   177                                                       if (shot['t_ip_flat'] == None or shot['ip_flat_duration'] == None):\n",
       "   178                                                           return False\n",
       "   179                                                   return True\n",
       "   180                                           \n",
       "   181         1         11.0     11.0      0.0      def get_non_nan_inds(arr):\n",
       "   182                                                   \"\"\"gets indices of array where value is not NaN\"\"\"\n",
       "   183                                                   if len(arr.shape) == 1:\n",
       "   184                                                       return np.where(~np.isnan(arr))[0]\n",
       "   185                                                   else:\n",
       "   186                                                       return np.where(np.any(~np.isnan(arr), axis=1))[0]\n",
       "   187                                           \n",
       "   188         1         10.0     10.0      0.0      def get_first_index(shot):\n",
       "   189                                                   \"\"\"gets index of first valid timeslice for a shot\"\"\"\n",
       "   190                                                   input_max = max([get_non_nan_inds(shot[sig])[0] +\n",
       "   191                                                                    lookbacks[sig] for sig in sig_names])\n",
       "   192                                                   output_max = max([get_non_nan_inds(shot[sig])[0] -\n",
       "   193                                                                     lookahead for sig in sig_names])\n",
       "   194                                                   if (flattop_only) and (shot['t_ip_flat'] != None):\n",
       "   195                                                       current_max = np.searchsorted(\n",
       "   196                                                           shot['time'], shot['t_ip_flat'], side='left')\n",
       "   197                                                       return np.ceil(max(input_max, output_max, current_max)).astype(int)\n",
       "   198                                                   else:\n",
       "   199                                                       return np.ceil(max(input_max, output_max)).astype(int)\n",
       "   200                                           \n",
       "   201         1         11.0     11.0      0.0      def get_last_index(shot):\n",
       "   202                                                   \"\"\"gets index of last valid timeslice for a shot\"\"\"\n",
       "   203                                                   partial_min = min([get_non_nan_inds(shot[sig])[-1]\n",
       "   204                                                                      for sig in sig_names])\n",
       "   205                                                   full_min = min([get_non_nan_inds(shot[sig])[-1] -\n",
       "   206                                                                   lookahead for sig in sig_names])\n",
       "   207                                                   if (flattop_only) and (shot['t_ip_flat'] != None) and (shot['ip_flat_duration'] != None):\n",
       "   208                                                       current_min = np.searchsorted(\n",
       "   209                                                           shot['time'], shot['t_ip_flat']+shot['ip_flat_duration'], side='right')\n",
       "   210                                                       return np.floor(min(full_min, partial_min, current_min)).astype(int)\n",
       "   211                                                   else:\n",
       "   212                                                       return np.floor(min(full_min, partial_min)).astype(int)\n",
       "   213                                               \n",
       "   214         1        915.0    915.0      0.0      @numba.njit\n",
       "   215                                               def group_data(array,first,last,sample_step,lookback, lookahead):\n",
       "   216                                                   \"\"\"groups shot data into i/o chunks\"\"\"\n",
       "   217                                                   data = []\n",
       "   218                                                   for i in range(first,last,sample_step):\n",
       "   219                                                       data.append(array[i-lookback:i+lookahead+1])\n",
       "   220                                                   return data\n",
       "   221                                               \n",
       "   222                                               ##############################\n",
       "   223                                               # loop through shots and do stuff\n",
       "   224                                               ##############################\n",
       "   225         1         11.0     11.0      0.0      alldata = {}\n",
       "   226         1         11.0     11.0      0.0      shots_with_complete_nan = []\n",
       "   227        22        232.0     10.5      0.0      for sig in sigsplustime:\n",
       "   228        21        219.0     10.4      0.0          alldata[sig] = []  # initalize empty lists\n",
       "   229         1         11.0     11.0      0.0      for shot in tqdm(usabledata, desc='Gathering', ascii=True, dynamic_ncols=True,\n",
       "   230      5741      82444.0     14.4      0.0                       disable=not verbose == 1):\n",
       "   231                                                   ##############################\n",
       "   232                                                   # take moving average of data and bin it\n",
       "   233                                                   ##############################\n",
       "   234      5740      65321.0     11.4      0.0          binned_shot = {}\n",
       "   235    126280    1392622.0     11.0      0.6          for sig in sigsplustime:\n",
       "   236    120540    4357832.0     36.2      1.7              if np.any(np.isinf(shot[sig])):\n",
       "   237                                                           shot[sig][np.isinf(shot[sig])] = np.nan            \n",
       "   238    120540   12642820.0    104.9      5.0              binned_shot[sig] = moving_average(shot[sig],window_length)[::window_length-window_overlap]\n",
       "   239      5740      68513.0     11.9      0.0          binned_shot['t_ip_flat'] = shot['t_ip_flat']\n",
       "   240      5740      63966.0     11.1      0.0          binned_shot['ip_flat_duration'] = shot['ip_flat_duration']\n",
       "   241      5740    1543860.0    269.0      0.6          if not is_valid(binned_shot):\n",
       "   242        60       3471.0     57.9      0.0              shots_with_complete_nan.append(np.unique(shot[\"shotnum\"]))\n",
       "   243        60        644.0     10.7      0.0              continue\n",
       "   244                                           \n",
       "   245                                                   ##############################\n",
       "   246                                                   # group into arrays of input/output pairs\n",
       "   247                                                   ##############################\n",
       "   248      5680    4495925.0    791.5      1.8          first = get_first_index(binned_shot)\n",
       "   249      5680    4446896.0    782.9      1.8          last = get_last_index(binned_shot)\n",
       "   250    124960    1380070.0     11.0      0.5          for sig in sigsplustime:\n",
       "   251    119280   11065703.0     92.8      4.4              alldata[sig] += group_data(binned_shot[sig],first,last,sample_step,lookbacks[sig],lookahead)\n",
       "   252                                           \n",
       "   253         1         11.0     11.0      0.0      if verbose:\n",
       "   254                                                   print(\"Shots with Complete NaN: \" + ', '.join(str(e)\n",
       "   255                                                                                                 for e in shots_with_complete_nan))\n",
       "   256         1     728903.0 728903.0      0.3      del usabledata\n",
       "   257         1     349189.0 349189.0      0.1      gc.collect()\n",
       "   258                                               \n",
       "   259                                               ##############################\n",
       "   260                                               # stack data from all shots together\n",
       "   261                                               ##############################    \n",
       "   262         1         16.0     16.0      0.0      for sig in tqdm(sigsplustime, desc='Stacking', ascii=True, dynamic_ncols=True,\n",
       "   263        22        861.0     39.1      0.0                      disable=not verbose == 1):\n",
       "   264        21   69796567.0 3323646.0     27.8          alldata[sig] = np.stack(alldata[sig])\n",
       "   265         1        276.0    276.0      0.0      print(\"{} samples total\".format(len(alldata['time'])))\n",
       "   266                                           \n",
       "   267                                               ##############################\n",
       "   268                                               # apply pruning functions\n",
       "   269                                               ##############################\n",
       "   270         1         11.0     11.0      0.0      prun_funs = []\n",
       "   271         1         11.0     11.0      0.0      prun_dict = {'remove_nan': remove_nan,\n",
       "   272         1         10.0     10.0      0.0                   'remove_ECH': remove_ECH,\n",
       "   273         1         13.0     13.0      0.0                   'remove_I_coil': remove_I_coil,\n",
       "   274         1         10.0     10.0      0.0                   'remove_gas': remove_gas,\n",
       "   275         1         13.0     13.0      0.0                   'remove_dudtrip': remove_dudtrip}\n",
       "   276                                               \n",
       "   277         1         12.0     12.0      0.0      if remove_gas in pruning_functions:\n",
       "   278         1         11.0     11.0      0.0          prun_funs.append(remove_gas)\n",
       "   279         1         11.0     11.0      0.0      if remove_nan in pruning_functions:\n",
       "   280         1         10.0     10.0      0.0          prun_funs.append(remove_nan)\n",
       "   281         1         11.0     11.0      0.0      if remove_dudtrip in pruning_functions:\n",
       "   282         1         11.0     11.0      0.0          prun_funs.append(remove_dudtrip)\n",
       "   283         1         10.0     10.0      0.0      if remove_ECH in pruning_functions:\n",
       "   284         1         11.0     11.0      0.0          prun_funs.append(remove_ECH)\n",
       "   285         1         10.0     10.0      0.0      if remove_I_coil in pruning_functions:\n",
       "   286         1         11.0     11.0      0.0          prun_funs.append(remove_I_coil)\n",
       "   287                                                   \n",
       "   288         6         86.0     14.3      0.0      for fun in prun_funs:\n",
       "   289         5   74089056.0 14817811.2     29.5          alldata = fun(alldata, verbose)\n",
       "   290         1        305.0    305.0      0.0      print(\"{} samples remaining after pruning\".format(len(alldata['time'])))\n",
       "   291                                           \n",
       "   292                                               ##############################\n",
       "   293                                               # normalize data\n",
       "   294                                               ##############################    \n",
       "   295         1         13.0     13.0      0.0      alldata, normalization_params = normalize(\n",
       "   296         1   32810827.0 32810827.0     13.1          alldata, normalization_method, uniform_normalization, verbose)\n",
       "   297                                               \n",
       "   298                                               ##############################\n",
       "   299                                               # split into train and validation sets\n",
       "   300                                               ##############################    \n",
       "   301         1         15.0     15.0      0.0      nsamples = alldata['time'].shape[0]\n",
       "   302         1      11182.0  11182.0      0.0      inds = np.random.permutation(nsamples) if randomize else np.arange(nsamples)\n",
       "   303         1         18.0     18.0      0.0      traininds = inds[:int(nsamples*train_frac)]\n",
       "   304         1         11.0     11.0      0.0      valinds = inds[int(nsamples*train_frac)\n",
       "   305         1         14.0     14.0      0.0                         :int(nsamples*(val_frac+train_frac))]\n",
       "   306         1         11.0     11.0      0.0      traindata = {}\n",
       "   307         1         11.0     11.0      0.0      valdata = {}\n",
       "   308         1         11.0     11.0      0.0      for sig in tqdm(sigsplustime, desc='Splitting', ascii=True, dynamic_ncols=True,\n",
       "   309        22        743.0     33.8      0.0                      disable=not verbose == 1):\n",
       "   310        21    1698540.0  80882.9      0.7          traindata[sig] = alldata[sig][traininds]\n",
       "   311        21     355040.0  16906.7      0.1          valdata[sig] = alldata[sig][valinds]\n",
       "   312         1         12.0     12.0      0.0      if verbose:\n",
       "   313                                                   print('Total number of samples: ', str(nsamples))\n",
       "   314                                                   print('Number of training samples: ', str(traininds.size))\n",
       "   315                                                   print('Number of validation samples: ', str(valinds.size))\n",
       "   316         1         12.0     12.0      0.0      return traindata, valdata, normalization_params\n",
       "\n",
       "Total time: 13.9026 s\n",
       "File: <ipython-input-262-12b28576f9d8>\n",
       "Function: remove_dudtrip at line 21\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    21                                           def remove_dudtrip(data, verbose):\n",
       "    22         1          2.0      2.0      0.0      if verbose:\n",
       "    23                                                   print('Removing dudtrip')\n",
       "    24         1      49567.0  49567.0      0.4      dud_trip_inds = np.nonzero(data['dud_trip'])[0]\n",
       "    25         1          7.0      7.0      0.0      if len(dud_trip_inds)==0:\n",
       "    26                                                   return data\n",
       "    27         1    8985328.0 8985328.0     64.6      remove_inds = prune_loop(dud_trip_inds,data['shotnum'],data['time'])\n",
       "    28         1          3.0      3.0      0.0      if verbose:\n",
       "    29                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    30         1      47232.0  47232.0      0.3      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    31         1          3.0      3.0      0.0      if verbose:\n",
       "    32                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    33        22        157.0      7.1      0.0      for sig in data.keys():\n",
       "    34        21    4820299.0 229538.0     34.7          data[sig] = data[sig][list(keep_inds)]\n",
       "    35         1          1.0      1.0      0.0      return data\n",
       "\n",
       "Total time: 20.278 s\n",
       "File: <ipython-input-262-12b28576f9d8>\n",
       "Function: remove_I_coil at line 38\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    38                                           def remove_I_coil(data, verbose):\n",
       "    39         1          5.0      5.0      0.0      if verbose:\n",
       "    40                                                   print('Removing weird I-coils')\n",
       "    41                                               \n",
       "    42         1       1512.0   1512.0      0.0      @numba.njit\n",
       "    43                                               def find_Icoil_inds(n,bt,curr,C_coil_method,I_coil_method):\n",
       "    44                                                   c_coil = list()\n",
       "    45                                                   i_coil = list()\n",
       "    46                                                   EFC = list()\n",
       "    47                                                   for i in range(n):\n",
       "    48                                                       if np.mean(bt[i]*curr[i]) < 0:\n",
       "    49                                                           # left-handed\n",
       "    50                                                           if not set(np.unique(C_coil_method[i])).issubset({5, 0, -1}):\n",
       "    51                                                               c_coil.append(i)\n",
       "    52                                                           if not set(np.unique(I_coil_method[i])).issubset({5, 0, -1}):\n",
       "    53                                                               i_coil.append(i)\n",
       "    54                                                           if not np.all(np.logical_xor(C_coil_method[i] == 5, I_coil_method[i] == 5)):\n",
       "    55                                                               EFC.append(i)\n",
       "    56                                                       else:\n",
       "    57                                                           # right-handed\n",
       "    58                                                           if not set(np.unique(C_coil_method[i])).issubset({6, 0, -1}):\n",
       "    59                                                               c_coil.append(i)\n",
       "    60                                                           if not set(np.unique(I_coil_method[i])).issubset({7, 0, -1}):\n",
       "    61                                                               i_coil.append(i)\n",
       "    62                                                           if not np.any(np.logical_or(np.logical_and(C_coil_method[i] == 6, I_coil_method[i] != 7), np.logical_and(C_coil_method[i] != 6, I_coil_method[i] == 7))):\n",
       "    63                                                               EFC.append(i)\n",
       "    64                                                               \n",
       "    65                                                   coil_inds = c_coil + i_coil + EFC\n",
       "    66                                                   return coil_inds\n",
       "    67                                           \n",
       "    68         1   10176483.0 10176483.0     50.2      coil_inds = np.unique(find_Icoil_inds(len(data['time']),data['bt'],data['curr'],data['C_coil_method'].astype(int),data['I_coil_method'].astype(int)))\n",
       "    69         1          5.0      5.0      0.0      if len(coil_inds)==0:\n",
       "    70                                                   return data\n",
       "    71         1    7270756.0 7270756.0     35.9      remove_inds = prune_loop(coil_inds,data['shotnum'],data['time'])\n",
       "    72         1          6.0      6.0      0.0      if verbose:\n",
       "    73                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    74         1      35089.0  35089.0      0.2      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    75         1          5.0      5.0      0.0      if verbose:\n",
       "    76                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    77        22        183.0      8.3      0.0      for sig in data.keys():\n",
       "    78        21    2793937.0 133044.6     13.8          data[sig] = data[sig][list(keep_inds)]\n",
       "    79         1          3.0      3.0      0.0      return data\n",
       "\n",
       "Total time: 8.47466 s\n",
       "File: <ipython-input-262-12b28576f9d8>\n",
       "Function: remove_gas at line 82\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    82                                           def remove_gas(data, verbose):\n",
       "    83         1          2.0      2.0      0.0      if verbose:\n",
       "    84                                                   print('Removing weird gas')\n",
       "    85         1         24.0     24.0      0.0      from functools import reduce\n",
       "    86         1          1.0      1.0      0.0      threshold=2\n",
       "    87         1      49477.0  49477.0      0.6      gasB_inds = np.nonzero(np.any(data['gasB'] > threshold, axis=1))[0]\n",
       "    88         1      23900.0  23900.0      0.3      gasC_inds = np.nonzero(np.any(data['gasC'] > threshold, axis=1))[0]\n",
       "    89         1      22638.0  22638.0      0.3      gasD_inds = np.nonzero(np.any(data['gasD'] > threshold, axis=1))[0]\n",
       "    90         1      22102.0  22102.0      0.3      gasE_inds = np.nonzero(np.any(data['gasE'] > threshold, axis=1))[0]\n",
       "    91         1      24419.0  24419.0      0.3      pfx1_inds = np.nonzero(np.any(data['pfx1'] > threshold, axis=1))[0]\n",
       "    92         1      24062.0  24062.0      0.3      pfx2_inds = np.nonzero(np.any(data['pfx2'] > threshold, axis=1))[0]\n",
       "    93         1         16.0     16.0      0.0      gas_inds = reduce(np.union1d, (gasB_inds, gasC_inds,\n",
       "    94         1       4142.0   4142.0      0.0                                     gasD_inds, gasE_inds, pfx1_inds, pfx2_inds))\n",
       "    95         1          3.0      3.0      0.0      if len(gas_inds)==0:\n",
       "    96                                                   return data\n",
       "    97         1    2919132.0 2919132.0     34.4      remove_inds = prune_loop(gas_inds,data['shotnum'],data['time'])\n",
       "    98         1          3.0      3.0      0.0      if verbose:\n",
       "    99                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   100         1      57203.0  57203.0      0.7      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   101         1          4.0      4.0      0.0      if verbose:\n",
       "   102                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   103        22        145.0      6.6      0.0      for sig in data.keys():\n",
       "   104        21    5327384.0 253685.0     62.9          data[sig] = data[sig][list(keep_inds)]\n",
       "   105         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 23.9616 s\n",
       "File: <ipython-input-262-12b28576f9d8>\n",
       "Function: remove_ECH at line 108\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   108                                           def remove_ECH(data, verbose):\n",
       "   109         1          2.0      2.0      0.0      if verbose:\n",
       "   110                                                   print('Removing ECH')\n",
       "   111         1      22240.0  22240.0      0.1      ech_inds = np.nonzero(np.any(data['ech'] > .5, axis=1))[0]\n",
       "   112         1          6.0      6.0      0.0      if len(ech_inds)==0:\n",
       "   113                                                   return data\n",
       "   114         1   20918319.0 20918319.0     87.3      remove_inds = prune_loop(ech_inds,data['shotnum'],data['time'])\n",
       "   115         1          4.0      4.0      0.0      if verbose:\n",
       "   116                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   117         1      58364.0  58364.0      0.2      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   118         1          4.0      4.0      0.0      if verbose:\n",
       "   119                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   120        22        143.0      6.5      0.0      for sig in data.keys():\n",
       "   121        21    2962486.0 141070.8     12.4          data[sig] = data[sig][list(keep_inds)]\n",
       "   122         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 7.42224 s\n",
       "File: <ipython-input-262-12b28576f9d8>\n",
       "Function: remove_nan at line 125\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   125                                           def remove_nan(data, verbose):\n",
       "   126         1          2.0      2.0      0.0      if verbose:\n",
       "   127                                                   print('Removing NaN')\n",
       "   128         1          7.0      7.0      0.0      remove_inds = set()\n",
       "   129        22         68.0      3.1      0.0      for sig in data.keys():\n",
       "   130        21         58.0      2.8      0.0          if data[sig].ndim==1:\n",
       "   131                                                       remove_inds = remove_inds.union(set(np.where(np.isnan(data[sig]))[0].tolist()))\n",
       "   132                                                   else:\n",
       "   133        21    2413008.0 114905.1     32.5              remove_inds = remove_inds.union(set(np.where(np.any(np.isnan(data[sig]),axis=tuple(np.arange(1,data[sig].ndim).astype(int))))[0].tolist()))\n",
       "   134         1          2.0      2.0      0.0      if verbose:\n",
       "   135                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   136         1      44738.0  44738.0      0.6      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   137         1          4.0      4.0      0.0      if verbose:\n",
       "   138                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   139        22        150.0      6.8      0.0      for sig in data.keys():\n",
       "   140        21    4964197.0 236390.3     66.9          data[sig] = data[sig][list(keep_inds)]\n",
       "   141         1          2.0      2.0      0.0      return data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f process_data -f remove_dudtrip -f remove_I_coil -f remove_gas -f remove_ECH -f remove_nan process_data(scenario['raw_data_path'],scenario['sig_names'],scenario['normalization_method'],scenario['window_length'],scenario['window_overlap'],scenario['lookback'],scenario['lookahead'],scenario['sample_step'],scenario['uniform_normalization'],scenario['train_frac'],scenario['val_frac'],scenario['nshots'],verbose,scenario['flattop_only'],pruning_functions=scenario['pruning_functions'],excluded_shots=scenario['excluded_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052920 samples total\n",
      "486276 samples remaining after pruning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 252.923 s\n",
       "File: <ipython-input-249-9c984d9629d5>\n",
       "Function: process_data at line 13\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    13                                           def process_data(rawdata, sig_names, normalization_method, window_length=1,\n",
       "    14                                                            window_overlap=0, lookbacks={}, lookahead=3, sample_step=5,\n",
       "    15                                                            uniform_normalization=True, train_frac=0.7, val_frac=0.2,\n",
       "    16                                                            nshots=None,\n",
       "    17                                                            verbose=1, flattop_only=True, randomize=True, **kwargs):\n",
       "    18                                               \"\"\"Organize data into correct format for training\n",
       "    19                                           \n",
       "    20                                               Gathers raw data into bins, group into training sequences, normalize,\n",
       "    21                                               and split into training and validation sets.\n",
       "    22                                           \n",
       "    23                                               Args:\n",
       "    24                                                   rawdata (dict): Nested dictionary of raw signal data, or path to pickle.\n",
       "    25                                                       Should be of the form rawdata[shot][signal_name] = signal_data.\n",
       "    26                                                   sig_names (list): List of signal names as strings.\n",
       "    27                                                   normalization_method (str): One of `StandardScaler`, `MinMax`, `MaxAbs`,\n",
       "    28                                                       `RobustScaler`, `PowerTransform`.\n",
       "    29                                                   window_length (int): Number of samples to average over in each bin/window.\n",
       "    30                                                   window_overlap (int): How many timesteps to overlap windows.\n",
       "    31                                                   lookbacks (dict of int): How many window lengths for lookback for each sig.\n",
       "    32                                                   lookahead (int): How many window lengths to predict into the future.\n",
       "    33                                                   sample_step (int): How much to offset sequential training sequences.\n",
       "    34                                                       Step of 1 means sample[i] and sample[i+1] will be offset by 1, with\n",
       "    35                                                       the rest overlapping.\n",
       "    36                                                   uniform_normalization (bool): 'True' uses the same normalization\n",
       "    37                                                       parameters over a whole profile, 'False' normalizes each spatial\n",
       "    38                                                       point separately.\n",
       "    39                                                   val_frac (float): Fraction of samples to use for validation.\n",
       "    40                                                   nshots (int): How many shots to use. If None, all available will be used.\n",
       "    41                                                   verbose (int): verbosity level. 0 is no CL output, 1 shows progress, 2 is abbreviated.\n",
       "    42                                                   flattop_only (bool): Whether to only include data from flattop.\n",
       "    43                                           \n",
       "    44                                               Returns:\n",
       "    45                                                   traindata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    46                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    47                                                   valdata (dict): Dictionary of numpy arrays, one entry for each signal.\n",
       "    48                                                       Each array has shape [nsamples,lookback+lookahead,signal_shape]\n",
       "    49                                                   param_dict (dict): Dictionary of parameters used during normalization,\n",
       "    50                                                       to be used for denormalizing later. Eg, mean, stddev, method, etc.\n",
       "    51                                               \"\"\"\n",
       "    52                                               ##############################\n",
       "    53                                               # Load data\n",
       "    54                                               ##############################\n",
       "    55         1         13.0     13.0      0.0      if type(rawdata) is not dict:\n",
       "    56         1         12.0     12.0      0.0          if verbose:\n",
       "    57                                                       print('Loading')\n",
       "    58         1      24193.0  24193.0      0.0          abs_path = Path(rawdata).resolve()\n",
       "    59         1         47.0     47.0      0.0          if abs_path.exists():\n",
       "    60         1        301.0    301.0      0.0              with open(abs_path, 'rb') as f:\n",
       "    61         1   29608602.0 29608602.0     11.7                  rawdata = pickle.load(f, encoding='latin1')\n",
       "    62                                                   else:\n",
       "    63                                                       print(abs_path)\n",
       "    64                                                       raise IOError(\"No such path to data file\")\n",
       "    65                                                       \n",
       "    66                                               ##############################\n",
       "    67                                               # get pruning functions\n",
       "    68                                               ##############################\n",
       "    69         1         16.0     16.0      0.0      pruning_functions = kwargs.get('pruning_functions', [])\n",
       "    70         1         14.0     14.0      0.0      if 'ech' not in sig_names:\n",
       "    71         1         12.0     12.0      0.0          pruning_functions.append('remove_ECH')\n",
       "    72         1         22.0     22.0      0.0      if not {'gasB', 'gasC', 'gasD', 'gasE'}.issubset(set(sig_names)):\n",
       "    73         1         10.0     10.0      0.0          pruning_functions.append('remove_gas')\n",
       "    74         1         13.0     13.0      0.0      prun_dict = {'remove_nan': remove_nan,\n",
       "    75         1         10.0     10.0      0.0                   'remove_ECH': remove_ECH,\n",
       "    76         1         10.0     10.0      0.0                   'remove_I_coil': remove_I_coil,\n",
       "    77         1         10.0     10.0      0.0                   'remove_gas': remove_gas,\n",
       "    78         1         13.0     13.0      0.0                   'remove_dudtrip': remove_dudtrip}\n",
       "    79         6         66.0     11.0      0.0      for i, elem in enumerate(pruning_functions):\n",
       "    80         5         53.0     10.6      0.0          if isinstance(elem, str):\n",
       "    81         5         53.0     10.6      0.0              pruning_functions[i] = prun_dict[elem]\n",
       "    82                                           \n",
       "    83                                               ##############################\n",
       "    84                                               # get excluded shots\n",
       "    85                                               ##############################\n",
       "    86         1         11.0     11.0      0.0      excluded_shots = kwargs.get('excluded_shots', [])\n",
       "    87         1         15.0     15.0      0.0      exclude_dict = {'topology_TOP': exclude_shots.topology_TOP,\n",
       "    88         1         10.0     10.0      0.0                      'topology_SNT': exclude_shots.topology_SNT,\n",
       "    89         1         13.0     13.0      0.0                      'topology_SNB': exclude_shots.topology_SNB,\n",
       "    90         1         11.0     11.0      0.0                      'topology_OUT': exclude_shots.topology_OUT,\n",
       "    91         1         10.0     10.0      0.0                      'topology_MAR': exclude_shots.topology_MAR,\n",
       "    92         1         11.0     11.0      0.0                      'topology_IN': exclude_shots.topology_IN,\n",
       "    93         1         11.0     11.0      0.0                      'topology_DN': exclude_shots.topology_DN,\n",
       "    94         1         11.0     11.0      0.0                      'topology_BOT': exclude_shots.topology_BOT}\n",
       "    95         7         72.0     10.3      0.0      for i, elem in enumerate(excluded_shots):\n",
       "    96         6         62.0     10.3      0.0          if isinstance(elem, str):\n",
       "    97         6         62.0     10.3      0.0              excluded_shots[i] = exclude_dict[elem]\n",
       "    98         6         64.0     10.7      0.0          if not isinstance(elem, list):\n",
       "    99         6         62.0     10.3      0.0              excluded_shots[i] = [elem]\n",
       "   100         1         22.0     22.0      0.0      excluded_shots = [item for sublist in excluded_shots for item in sublist]\n",
       "   101                                           \n",
       "   102                                               ##############################\n",
       "   103                                               # get sig names\n",
       "   104                                               ##############################\n",
       "   105         1         10.0     10.0      0.0      extra_sigs = ['time', 'shotnum']\n",
       "   106         1         11.0     11.0      0.0      if remove_dudtrip in pruning_functions:\n",
       "   107         1         12.0     12.0      0.0          extra_sigs += ['dud_trip']\n",
       "   108         1         10.0     10.0      0.0      if remove_I_coil in pruning_functions:\n",
       "   109         1         10.0     10.0      0.0          extra_sigs += ['bt', 'curr', 'C_coil_method', 'I_coil_method']\n",
       "   110         1         10.0     10.0      0.0      if remove_gas in pruning_functions:\n",
       "   111         1         10.0     10.0      0.0          extra_sigs += ['gasB', 'gasC', 'gasD', 'gasE', 'pfx1', 'pfx2']\n",
       "   112         1         11.0     11.0      0.0      if remove_ECH in pruning_functions:\n",
       "   113         1         10.0     10.0      0.0          extra_sigs += ['ech']\n",
       "   114         1       3564.0   3564.0      0.0      sig_names = list(np.unique(sig_names))\n",
       "   115         1         88.0     88.0      0.0      sigsplustime = list(np.unique(sig_names + extra_sigs))\n",
       "   116         1         11.0     11.0      0.0      if verbose:\n",
       "   117                                                   print('Signals: ' + ', '.join(sig_names))\n",
       "   118                                           \n",
       "   119                                               ##############################\n",
       "   120                                               # figure out lookbacks\n",
       "   121                                               ##############################\n",
       "   122         1         11.0     11.0      0.0      if isinstance(lookbacks, int):\n",
       "   123         1         10.0     10.0      0.0          max_lookback = lookbacks\n",
       "   124         1         18.0     18.0      0.0          lookbacks = {sig: max_lookback for sig in sigsplustime}\n",
       "   125                                               else:\n",
       "   126                                                   max_lookback = 0\n",
       "   127                                                   for val in lookbacks.values():\n",
       "   128                                                       if val > max_lookback:\n",
       "   129                                                           max_lookback = val\n",
       "   130                                                   for sig in sigsplustime:\n",
       "   131                                                       if sig not in lookbacks.keys():\n",
       "   132                                                           lookbacks[sig] = max_lookback\n",
       "   133                                                       \n",
       "   134                                               ##############################\n",
       "   135                                               # find which shots have all the signals needed\n",
       "   136                                               ##############################\n",
       "   137         1         11.0     11.0      0.0      usabledata = []\n",
       "   138         1       1174.0   1174.0      0.0      all_shots = sorted(list(rawdata.keys()))\n",
       "   139     11062     113965.0     10.3      0.0      for shot in all_shots:\n",
       "   140     11061     276160.0     25.0      0.1          rawdata[shot]['shotnum'] = np.ones(rawdata[shot]['time'].shape[0])*shot\n",
       "   141     11061     235340.0     21.3      0.1          if set(sigsplustime).issubset(set(rawdata[shot].keys())) \\\n",
       "   142      5740      62198.0     10.8      0.0             and rawdata[shot]['time'].size > (max_lookback+lookahead) \\\n",
       "   143      5740      60361.0     10.5      0.0             and shot not in excluded_shots:\n",
       "   144      5740      60468.0     10.5      0.0              usabledata.append(rawdata[shot])\n",
       "   145         1        791.0    791.0      0.0      usabledata = np.array(usabledata)\n",
       "   146         1     460250.0 460250.0      0.2      del rawdata\n",
       "   147         1      84526.0  84526.0      0.0      gc.collect()\n",
       "   148         1         13.0     13.0      0.0      if nshots is not None:\n",
       "   149         1         56.0     56.0      0.0          nshots = np.minimum(nshots, len(usabledata))\n",
       "   150         1         19.0     19.0      0.0          usabledata = usabledata[:nshots]\n",
       "   151                                               else:\n",
       "   152                                                   nshots = len(usabledata)\n",
       "   153         1         11.0     11.0      0.0      if verbose:\n",
       "   154                                                   print('Number of useable shots: ', str(len(usabledata)))\n",
       "   155                                                   print('Number of shots used: ', str(nshots))\n",
       "   156         1         10.0     10.0      0.0      if verbose:\n",
       "   157                                                   t = 0\n",
       "   158                                                   for shot in usabledata:\n",
       "   159                                                       t += shot['time'].size\n",
       "   160                                                   print('Total number of timesteps: ', str(t))\n",
       "   161                                                   \n",
       "   162                                               ##############################\n",
       "   163                                               # some helper functions\n",
       "   164                                               ##############################          \n",
       "   165         1         12.0     12.0      0.0      def moving_average(a, n):\n",
       "   166                                                   \"\"\"moving average of array a with window size n\"\"\"\n",
       "   167                                                   ret = np.nancumsum(a, axis=0)\n",
       "   168                                                   ret[n:] = ret[n:] - ret[:-n]\n",
       "   169                                                   return ret[n - 1:] / n\n",
       "   170                                           \n",
       "   171         1         12.0     12.0      0.0      def is_valid(shot):\n",
       "   172                                                   \"\"\"checks if a shot is completely NaN or if it never reached flattop\"\"\"\n",
       "   173                                                   for sig in sigsplustime:\n",
       "   174                                                       if np.isnan(shot[sig]).all():  # or np.isinf(shot[sig]).any():\n",
       "   175                                                           return False\n",
       "   176                                                   if (flattop_only):\n",
       "   177                                                       if (shot['t_ip_flat'] == None or shot['ip_flat_duration'] == None):\n",
       "   178                                                           return False\n",
       "   179                                                   return True\n",
       "   180                                           \n",
       "   181         1         10.0     10.0      0.0      def get_non_nan_inds(arr):\n",
       "   182                                                   \"\"\"gets indices of array where value is not NaN\"\"\"\n",
       "   183                                                   if len(arr.shape) == 1:\n",
       "   184                                                       return np.where(~np.isnan(arr))[0]\n",
       "   185                                                   else:\n",
       "   186                                                       return np.where(np.any(~np.isnan(arr), axis=1))[0]\n",
       "   187                                           \n",
       "   188         1         11.0     11.0      0.0      def get_first_index(shot):\n",
       "   189                                                   \"\"\"gets index of first valid timeslice for a shot\"\"\"\n",
       "   190                                                   input_max = max([get_non_nan_inds(shot[sig])[0] +\n",
       "   191                                                                    lookbacks[sig] for sig in sig_names])\n",
       "   192                                                   output_max = max([get_non_nan_inds(shot[sig])[0] -\n",
       "   193                                                                     lookahead for sig in sig_names])\n",
       "   194                                                   if (flattop_only) and (shot['t_ip_flat'] != None):\n",
       "   195                                                       current_max = np.searchsorted(\n",
       "   196                                                           shot['time'], shot['t_ip_flat'], side='left')\n",
       "   197                                                       return np.ceil(max(input_max, output_max, current_max)).astype(int)\n",
       "   198                                                   else:\n",
       "   199                                                       return np.ceil(max(input_max, output_max)).astype(int)\n",
       "   200                                           \n",
       "   201         1         10.0     10.0      0.0      def get_last_index(shot):\n",
       "   202                                                   \"\"\"gets index of last valid timeslice for a shot\"\"\"\n",
       "   203                                                   partial_min = min([get_non_nan_inds(shot[sig])[-1]\n",
       "   204                                                                      for sig in sig_names])\n",
       "   205                                                   full_min = min([get_non_nan_inds(shot[sig])[-1] -\n",
       "   206                                                                   lookahead for sig in sig_names])\n",
       "   207                                                   if (flattop_only) and (shot['t_ip_flat'] != None) and (shot['ip_flat_duration'] != None):\n",
       "   208                                                       current_min = np.searchsorted(\n",
       "   209                                                           shot['time'], shot['t_ip_flat']+shot['ip_flat_duration'], side='right')\n",
       "   210                                                       return np.floor(min(full_min, partial_min, current_min)).astype(int)\n",
       "   211                                                   else:\n",
       "   212                                                       return np.floor(min(full_min, partial_min)).astype(int)\n",
       "   213                                               \n",
       "   214         1        877.0    877.0      0.0      @numba.njit\n",
       "   215                                               def group_data(array,first,last,sample_step,lookback, lookahead):\n",
       "   216                                                   \"\"\"groups shot data into i/o chunks\"\"\"\n",
       "   217                                                   data = []\n",
       "   218                                                   for i in range(first,last,sample_step):\n",
       "   219                                                       data.append(array[i-lookback:i+lookahead+1])\n",
       "   220                                                   return data\n",
       "   221                                               \n",
       "   222                                               ##############################\n",
       "   223                                               # loop through shots and do stuff\n",
       "   224                                               ##############################\n",
       "   225         1         11.0     11.0      0.0      alldata = {}\n",
       "   226         1         10.0     10.0      0.0      shots_with_complete_nan = []\n",
       "   227        22        224.0     10.2      0.0      for sig in sigsplustime:\n",
       "   228        21        216.0     10.3      0.0          alldata[sig] = []  # initalize empty lists\n",
       "   229         1         11.0     11.0      0.0      for shot in tqdm(usabledata, desc='Gathering', ascii=True, dynamic_ncols=True,\n",
       "   230      5741      79388.0     13.8      0.0                       disable=not verbose == 1):\n",
       "   231                                                   ##############################\n",
       "   232                                                   # take moving average of data and bin it\n",
       "   233                                                   ##############################\n",
       "   234      5740      62981.0     11.0      0.0          binned_shot = {}\n",
       "   235    126280    1343652.0     10.6      0.5          for sig in sigsplustime:\n",
       "   236    120540    4141327.0     34.4      1.6              if np.any(np.isinf(shot[sig])):\n",
       "   237                                                           shot[sig][np.isinf(shot[sig])] = np.nan            \n",
       "   238    120540   12213522.0    101.3      4.8              binned_shot[sig] = moving_average(shot[sig],window_length)[::window_length-window_overlap]\n",
       "   239      5740      66229.0     11.5      0.0          binned_shot['t_ip_flat'] = shot['t_ip_flat']\n",
       "   240      5740      61800.0     10.8      0.0          binned_shot['ip_flat_duration'] = shot['ip_flat_duration']\n",
       "   241      5740    1475361.0    257.0      0.6          if not is_valid(binned_shot):\n",
       "   242        60       3469.0     57.8      0.0              shots_with_complete_nan.append(np.unique(shot[\"shotnum\"]))\n",
       "   243        60        641.0     10.7      0.0              continue\n",
       "   244                                           \n",
       "   245                                                   ##############################\n",
       "   246                                                   # group into arrays of input/output pairs\n",
       "   247                                                   ##############################\n",
       "   248      5680    4259404.0    749.9      1.7          first = get_first_index(binned_shot)\n",
       "   249      5680    4167680.0    733.7      1.6          last = get_last_index(binned_shot)\n",
       "   250    124960    1331351.0     10.7      0.5          for sig in sigsplustime:\n",
       "   251    119280   10377942.0     87.0      4.1              alldata[sig] += group_data(binned_shot[sig],first,last,sample_step,lookbacks[sig],lookahead)\n",
       "   252                                           \n",
       "   253         1         11.0     11.0      0.0      if verbose:\n",
       "   254                                                   print(\"Shots with Complete NaN: \" + ', '.join(str(e)\n",
       "   255                                                                                                 for e in shots_with_complete_nan))\n",
       "   256         1     725598.0 725598.0      0.3      del usabledata\n",
       "   257         1     366096.0 366096.0      0.1      gc.collect()\n",
       "   258                                               \n",
       "   259                                               ##############################\n",
       "   260                                               # stack data from all shots together\n",
       "   261                                               ##############################    \n",
       "   262         1         16.0     16.0      0.0      for sig in tqdm(sigsplustime, desc='Stacking', ascii=True, dynamic_ncols=True,\n",
       "   263        22        819.0     37.2      0.0                      disable=not verbose == 1):\n",
       "   264        21   68142555.0 3244883.6     26.9          alldata[sig] = np.stack(alldata[sig])\n",
       "   265         1        273.0    273.0      0.0      print(\"{} samples total\".format(len(alldata['time'])))\n",
       "   266                                           \n",
       "   267                                               ##############################\n",
       "   268                                               # apply pruning functions\n",
       "   269                                               ##############################\n",
       "   270         6         80.0     13.3      0.0      for fun in pruning_functions:\n",
       "   271         5   79546035.0 15909207.0     31.5          alldata = fun(alldata, verbose)\n",
       "   272         1        287.0    287.0      0.0      print(\"{} samples remaining after pruning\".format(len(alldata['time'])))\n",
       "   273                                           \n",
       "   274                                               ##############################\n",
       "   275                                               # normalize data\n",
       "   276                                               ##############################    \n",
       "   277         1         11.0     11.0      0.0      alldata, normalization_params = normalize(\n",
       "   278         1   31468270.0 31468270.0     12.4          alldata, normalization_method, uniform_normalization, verbose)\n",
       "   279                                               \n",
       "   280                                               ##############################\n",
       "   281                                               # split into train and validation sets\n",
       "   282                                               ##############################    \n",
       "   283         1         15.0     15.0      0.0      nsamples = alldata['time'].shape[0]\n",
       "   284         1      10573.0  10573.0      0.0      inds = np.random.permutation(nsamples) if randomize else np.arange(nsamples)\n",
       "   285         1         18.0     18.0      0.0      traininds = inds[:int(nsamples*train_frac)]\n",
       "   286         1         11.0     11.0      0.0      valinds = inds[int(nsamples*train_frac)\n",
       "   287         1         12.0     12.0      0.0                         :int(nsamples*(val_frac+train_frac))]\n",
       "   288         1         11.0     11.0      0.0      traindata = {}\n",
       "   289         1         11.0     11.0      0.0      valdata = {}\n",
       "   290         1         11.0     11.0      0.0      for sig in tqdm(sigsplustime, desc='Splitting', ascii=True, dynamic_ncols=True,\n",
       "   291        22        738.0     33.5      0.0                      disable=not verbose == 1):\n",
       "   292        21    1729124.0  82339.2      0.7          traindata[sig] = alldata[sig][traininds]\n",
       "   293        21     353000.0  16809.5      0.1          valdata[sig] = alldata[sig][valinds]\n",
       "   294         1         11.0     11.0      0.0      if verbose:\n",
       "   295                                                   print('Total number of samples: ', str(nsamples))\n",
       "   296                                                   print('Number of training samples: ', str(traininds.size))\n",
       "   297                                                   print('Number of validation samples: ', str(valinds.size))\n",
       "   298         1         10.0     10.0      0.0      return traindata, valdata, normalization_params\n",
       "\n",
       "Total time: 14.2479 s\n",
       "File: <ipython-input-250-12b28576f9d8>\n",
       "Function: remove_dudtrip at line 21\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    21                                           def remove_dudtrip(data, verbose):\n",
       "    22         1          2.0      2.0      0.0      if verbose:\n",
       "    23                                                   print('Removing dudtrip')\n",
       "    24         1      51220.0  51220.0      0.4      dud_trip_inds = np.nonzero(data['dud_trip'])[0]\n",
       "    25         1          5.0      5.0      0.0      if len(dud_trip_inds)==0:\n",
       "    26                                                   return data\n",
       "    27         1    9183573.0 9183573.0     64.5      remove_inds = prune_loop(dud_trip_inds,data['shotnum'],data['time'])\n",
       "    28         1          3.0      3.0      0.0      if verbose:\n",
       "    29                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    30         1      48455.0  48455.0      0.3      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    31         1          2.0      2.0      0.0      if verbose:\n",
       "    32                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    33        22        133.0      6.0      0.0      for sig in data.keys():\n",
       "    34        21    4964497.0 236404.6     34.8          data[sig] = data[sig][list(keep_inds)]\n",
       "    35         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 32.562 s\n",
       "File: <ipython-input-250-12b28576f9d8>\n",
       "Function: remove_I_coil at line 38\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    38                                           def remove_I_coil(data, verbose):\n",
       "    39         1          3.0      3.0      0.0      if verbose:\n",
       "    40                                                   print('Removing weird I-coils')\n",
       "    41                                               \n",
       "    42         1       1196.0   1196.0      0.0      @numba.njit\n",
       "    43                                               def find_Icoil_inds(n,bt,curr,C_coil_method,I_coil_method):\n",
       "    44                                                   c_coil = list()\n",
       "    45                                                   i_coil = list()\n",
       "    46                                                   EFC = list()\n",
       "    47                                                   for i in range(n):\n",
       "    48                                                       if np.mean(bt[i]*curr[i]) < 0:\n",
       "    49                                                           # left-handed\n",
       "    50                                                           if not set(np.unique(C_coil_method[i])).issubset({5, 0, -1}):\n",
       "    51                                                               c_coil.append(i)\n",
       "    52                                                           if not set(np.unique(I_coil_method[i])).issubset({5, 0, -1}):\n",
       "    53                                                               i_coil.append(i)\n",
       "    54                                                           if not np.all(np.logical_xor(C_coil_method[i] == 5, I_coil_method[i] == 5)):\n",
       "    55                                                               EFC.append(i)\n",
       "    56                                                       else:\n",
       "    57                                                           # right-handed\n",
       "    58                                                           if not set(np.unique(C_coil_method[i])).issubset({6, 0, -1}):\n",
       "    59                                                               c_coil.append(i)\n",
       "    60                                                           if not set(np.unique(I_coil_method[i])).issubset({7, 0, -1}):\n",
       "    61                                                               i_coil.append(i)\n",
       "    62                                                           if not np.any(np.logical_or(np.logical_and(C_coil_method[i] == 6, I_coil_method[i] != 7), np.logical_and(C_coil_method[i] != 6, I_coil_method[i] == 7))):\n",
       "    63                                                               EFC.append(i)\n",
       "    64                                                               \n",
       "    65                                                   coil_inds = c_coil + i_coil + EFC\n",
       "    66                                                   return coil_inds\n",
       "    67                                           \n",
       "    68         1   14533690.0 14533690.0     44.6      coil_inds = np.unique(find_Icoil_inds(len(data['time']),data['bt'],data['curr'],data['C_coil_method'].astype(int),data['I_coil_method'].astype(int)))\n",
       "    69         1          7.0      7.0      0.0      if len(coil_inds)==0:\n",
       "    70                                                   return data\n",
       "    71         1   13728380.0 13728380.0     42.2      remove_inds = prune_loop(coil_inds,data['shotnum'],data['time'])\n",
       "    72         1          4.0      4.0      0.0      if verbose:\n",
       "    73                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "    74         1      56523.0  56523.0      0.2      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "    75         1          3.0      3.0      0.0      if verbose:\n",
       "    76                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "    77        22        154.0      7.0      0.0      for sig in data.keys():\n",
       "    78        21    4242056.0 202002.7     13.0          data[sig] = data[sig][list(keep_inds)]\n",
       "    79         1          3.0      3.0      0.0      return data\n",
       "\n",
       "Total time: 3.71745 s\n",
       "File: <ipython-input-250-12b28576f9d8>\n",
       "Function: remove_gas at line 82\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    82                                           def remove_gas(data, verbose):\n",
       "    83         1          4.0      4.0      0.0      if verbose:\n",
       "    84                                                   print('Removing weird gas')\n",
       "    85         1         46.0     46.0      0.0      from functools import reduce\n",
       "    86         1          1.0      1.0      0.0      threshold=2\n",
       "    87         1      14823.0  14823.0      0.4      gasB_inds = np.nonzero(np.any(data['gasB'] > threshold, axis=1))[0]\n",
       "    88         1      14048.0  14048.0      0.4      gasC_inds = np.nonzero(np.any(data['gasC'] > threshold, axis=1))[0]\n",
       "    89         1      14251.0  14251.0      0.4      gasD_inds = np.nonzero(np.any(data['gasD'] > threshold, axis=1))[0]\n",
       "    90         1      15462.0  15462.0      0.4      gasE_inds = np.nonzero(np.any(data['gasE'] > threshold, axis=1))[0]\n",
       "    91         1      13520.0  13520.0      0.4      pfx1_inds = np.nonzero(np.any(data['pfx1'] > threshold, axis=1))[0]\n",
       "    92         1      14160.0  14160.0      0.4      pfx2_inds = np.nonzero(np.any(data['pfx2'] > threshold, axis=1))[0]\n",
       "    93         1          5.0      5.0      0.0      gas_inds = reduce(np.union1d, (gasB_inds, gasC_inds,\n",
       "    94         1       2605.0   2605.0      0.1                                     gasD_inds, gasE_inds, pfx1_inds, pfx2_inds))\n",
       "    95         1          3.0      3.0      0.0      if len(gas_inds)==0:\n",
       "    96                                                   return data\n",
       "    97         1    1212918.0 1212918.0     32.6      remove_inds = prune_loop(gas_inds,data['shotnum'],data['time'])\n",
       "    98         1          4.0      4.0      0.0      if verbose:\n",
       "    99                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   100         1      24141.0  24141.0      0.6      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   101         1          3.0      3.0      0.0      if verbose:\n",
       "   102                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   103        22        134.0      6.1      0.0      for sig in data.keys():\n",
       "   104        21    2391319.0 113872.3     64.3          data[sig] = data[sig][list(keep_inds)]\n",
       "   105         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 20.7652 s\n",
       "File: <ipython-input-250-12b28576f9d8>\n",
       "Function: remove_ECH at line 108\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   108                                           def remove_ECH(data, verbose):\n",
       "   109         1          1.0      1.0      0.0      if verbose:\n",
       "   110                                                   print('Removing ECH')\n",
       "   111         1      18612.0  18612.0      0.1      ech_inds = np.nonzero(np.any(data['ech'] > .5, axis=1))[0]\n",
       "   112         1          4.0      4.0      0.0      if len(ech_inds)==0:\n",
       "   113                                                   return data\n",
       "   114         1   18140591.0 18140591.0     87.4      remove_inds = prune_loop(ech_inds,data['shotnum'],data['time'])\n",
       "   115         1          9.0      9.0      0.0      if verbose:\n",
       "   116                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   117         1      59361.0  59361.0      0.3      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   118         1          4.0      4.0      0.0      if verbose:\n",
       "   119                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   120        22        136.0      6.2      0.0      for sig in data.keys():\n",
       "   121        21    2546472.0 121260.6     12.3          data[sig] = data[sig][list(keep_inds)]\n",
       "   122         1          2.0      2.0      0.0      return data\n",
       "\n",
       "Total time: 8.20771 s\n",
       "File: <ipython-input-250-12b28576f9d8>\n",
       "Function: remove_nan at line 125\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   125                                           def remove_nan(data, verbose):\n",
       "   126         1          2.0      2.0      0.0      if verbose:\n",
       "   127                                                   print('Removing NaN')\n",
       "   128         1          3.0      3.0      0.0      remove_inds = set()\n",
       "   129        22         60.0      2.7      0.0      for sig in data.keys():\n",
       "   130        21         59.0      2.8      0.0          if data[sig].ndim==1:\n",
       "   131                                                       remove_inds = remove_inds.union(set(np.where(np.isnan(data[sig]))[0].tolist()))\n",
       "   132                                                   else:\n",
       "   133        21    2720247.0 129535.6     33.1              remove_inds = remove_inds.union(set(np.where(np.any(np.isnan(data[sig]),axis=tuple(np.arange(1,data[sig].ndim).astype(int))))[0].tolist()))\n",
       "   134         1          2.0      2.0      0.0      if verbose:\n",
       "   135                                                   print(\"Removed {} samples\".format(len(remove_inds)))\n",
       "   136         1      50755.0  50755.0      0.6      keep_inds = set(range(len(data['time']))).difference(remove_inds)\n",
       "   137         1          3.0      3.0      0.0      if verbose:\n",
       "   138                                                   print(\"{} samples remaining\".format(len(keep_inds)))\n",
       "   139        22        156.0      7.1      0.0      for sig in data.keys():\n",
       "   140        21    5436418.0 258877.0     66.2          data[sig] = data[sig][list(keep_inds)]\n",
       "   141         1          2.0      2.0      0.0      return data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f process_data -f remove_dudtrip -f remove_I_coil -f remove_gas -f remove_ECH -f remove_nan process_data(scenario['raw_data_path'],scenario['sig_names'],scenario['normalization_method'],scenario['window_length'],scenario['window_overlap'],scenario['lookback'],scenario['lookahead'],scenario['sample_step'],scenario['uniform_normalization'],scenario['train_frac'],scenario['val_frac'],scenario['nshots'],verbose,scenario['flattop_only'],pruning_functions=scenario['pruning_functions'],excluded_shots=scenario['excluded_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Execute a statement under the line-by-line profiler from the\n",
       "line_profiler module.\n",
       "\n",
       "Usage:\n",
       "  %lprun -f func1 -f func2 <statement>\n",
       "\n",
       "The given statement (which doesn't require quote marks) is run via the\n",
       "LineProfiler. Profiling is enabled for the functions specified by the -f\n",
       "options. The statistics will be shown side-by-side with the code through the\n",
       "pager once the statement has completed.\n",
       "\n",
       "Options:\n",
       "\n",
       "-f <function>: LineProfiler only profiles functions and methods it is told\n",
       "to profile.  This option tells the profiler about these functions. Multiple\n",
       "-f options may be used. The argument may be any expression that gives\n",
       "a Python function or method object. However, one must be careful to avoid\n",
       "spaces that may confuse the option parser.\n",
       "\n",
       "-m <module>: Get all the functions/methods in a module\n",
       "\n",
       "One or more -f or -m options are required to get any useful results.\n",
       "\n",
       "-D <filename>: dump the raw statistics out to a pickle file on disk. The\n",
       "usual extension for this is \".lprof\". These statistics may be viewed later\n",
       "by running line_profiler.py as a script.\n",
       "\n",
       "-T <filename>: dump the text-formatted statistics with the code side-by-side\n",
       "out to a text file.\n",
       "\n",
       "-r: return the LineProfiler object after it has completed profiling.\n",
       "\n",
       "-s: strip out all entries from the print-out that have zeros.\n",
       "\n",
       "-u: specify time unit for the print-out in seconds.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/tfgpu/lib/python3.6/site-packages/line_profiler.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "b = [False,True,True,False,False]\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  1.,  2., nan])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [np.inf,1,2,np.nan]\n",
    "a = np.array(a)\n",
    "a[np.isinf(a)] = np.nan\n",
    "a[np.isinf(a)] = np.nan\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.random.random((5,6,7))>.5,axis=tuple(np.arange(1,3).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.arange(1,2).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
