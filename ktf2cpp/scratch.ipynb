{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import numpy as np\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5043300182898677e-08"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### average pooling test\n",
    "\n",
    "def arravg(array,numels,offset):\n",
    "    avg=0\n",
    "    ct = 0\n",
    "    for i in range(numels):\n",
    "        if array[i*offset] > -np.inf:\n",
    "            avg += array[i*offset]\n",
    "            ct += 1\n",
    "    avg = avg/ct\n",
    "    return avg\n",
    "\n",
    "def avgpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arravg(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = avgpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.17117913332441e-08"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### max pooling test\n",
    "def arrmax(array,numels,offset):\n",
    "    maxval=array[0];\n",
    "    for i in range(numels):\n",
    "        if array[i*offset]>maxval:\n",
    "            maxval = array[i*offset]\n",
    "    return maxval  \n",
    "\n",
    "def maxpool1d(inputs,pool_size,stride,out_height,in_width):\n",
    "    k=0\n",
    "    outputs = np.zeros(out_height*in_width)\n",
    "    inputs = inputs.flatten(order='C')\n",
    "    for i in range(out_height):\n",
    "        inrowidx = k*in_width;\n",
    "        outrowidx = i*in_width;\n",
    "        for j in range(in_width):\n",
    "            outputs[outrowidx+j] = arrmax(inputs[inrowidx+j:],pool_size,in_width)\n",
    "        k += stride\n",
    "    return outputs\n",
    "\n",
    "inshape = (8,23)\n",
    "pool_size=2\n",
    "stride=1\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.MaxPooling1D(pool_size=pool_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "y1 = np.concatenate((-np.inf*np.ones((pad_top,in_width)),x,-np.inf*np.ones((pad_bottom,in_width))),0)\n",
    "y2 = maxpool1d(y1,pool_size,stride,out_height,in_width)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "code_folding": [
     0,
     38,
     42,
     47
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3243318054802334e-08"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### conv1d test\n",
    "\n",
    "def conv1d(x,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation):\n",
    "    x = x.flatten(order='C')\n",
    "    kernel = kernel.flatten(order='C')\n",
    "    out_size = out_height*out_width\n",
    "    output = np.zeros(out_size)\n",
    "   \n",
    "    for p in range(out_height):\n",
    "        outrowidx = p*out_width\n",
    "        for k in range(out_width):\n",
    "            for z in range(kernel_size):\n",
    "                kernelidx = z*in_width*out_width\n",
    "                for q in range(in_width):\n",
    "                    inheightidx = q*out_width\n",
    "                    output[outrowidx+k] += kernel[kernelidx+ inheightidx+ k]*x[(p*stride+ z*dilation)*in_width+q];\n",
    "            output[outrowidx+k] += bias[k]\n",
    "    \n",
    "    return output\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation = 1\n",
    "kernel_size = 3\n",
    "num_filters = 12\n",
    "pad = 'same'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Conv1D(filters=num_filters, dilation_rate=dilation, kernel_size=kernel_size, strides=stride, padding=pad)(a)\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "(in_height,in_width) = model.layers[1].input_shape[1:]\n",
    "(out_height, out_width) = model.layers[1].output_shape[1:]\n",
    "\n",
    "if pad is 'causal':\n",
    "    pad_along_height = dilation*(kernel_size-1)\n",
    "    pad_top = pad_along_height\n",
    "    pad_bottom = 0\n",
    "elif pad is 'same':\n",
    "    pad_along_height = max((out_height - 1) * stride +\n",
    "                        pool_size - in_height, 0)\n",
    "    pad_top = int(pad_along_height // 2)\n",
    "    pad_bottom = int(pad_along_height - pad_top)\n",
    "elif pad is 'valid':\n",
    "    pad_top=0\n",
    "    pad_bottom=0\n",
    "padded_in_height = in_height + pad_top + pad_bottom\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "bias = model.layers[1].get_weights()[1]\n",
    "y1 = np.concatenate((np.zeros((pad_top,in_width)),x,np.zeros((pad_bottom,in_width))),0)\n",
    "y2 = conv1d(y1,kernel,bias,out_height,out_width,kernel_size,in_width,padded_in_height,stride,dilation)\n",
    "np.mean(np.abs(y.flatten(order='C')-y2.flatten(order='C')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5031581013236206e-07"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### simple RNN test\n",
    "def rnn(inputs,weights,recurrent_weights,bias):\n",
    "    state = np.zeros(bias.shape[0])\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = rnncell(inputs[i,:],state,weights,recurrent_weights,bias)\n",
    "    return state\n",
    "   \n",
    "def rnncell(inputs,state,weights,recurrent_weights,bias):\n",
    "    prev = state\n",
    "    h = inputs@weights+bias\n",
    "    output = h + prev@recurrent_weights\n",
    "    output = np.tanh(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.SimpleRNN(12, dropout=.5, recurrent_dropout=.5)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "model.layers[1].output_shape\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "recurrent_weights = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "a = rnn(x,weights,recurrent_weights,bias)\n",
    "np.max(np.abs(a-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "code_folding": [
     0,
     2,
     10
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.875467575857442e-07"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRU test\n",
    "\n",
    "def gru(inputs, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    \n",
    "    state = np.zeros(units)\n",
    "    for i in range(inputs.shape[0]):\n",
    "        state = grucell(inputs[i,:], state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "    return state\n",
    "    \n",
    "\n",
    "def grucell(inputs, state, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units):\n",
    "    kernel_z = kernel[:, :units]\n",
    "    recurrent_kernel_z = recurrent_kernel[:, :units]\n",
    "    # reset gate\n",
    "    kernel_r = kernel[:, units: units * 2]\n",
    "    recurrent_kernel_r = recurrent_kernel[:,units:units * 2]\n",
    "    # new gate\n",
    "    kernel_h = kernel[:, units * 2:]\n",
    "    recurrent_kernel_h = recurrent_kernel[:, units * 2:]\n",
    "    \n",
    "    input_bias_z = input_bias[:units]\n",
    "    input_bias_r = input_bias[units: units * 2]\n",
    "    input_bias_h = input_bias[units * 2:]\n",
    "        \n",
    "    recurrent_bias_z = recurrent_bias[:units]\n",
    "    recurrent_bias_r = recurrent_bias[units: units * 2]\n",
    "    recurrent_bias_h = recurrent_bias[units * 2:]\n",
    "    \n",
    "    \n",
    "    x_z = inputs@kernel_z + input_bias_z\n",
    "    x_r = inputs@kernel_r + input_bias_r\n",
    "    x_h = inputs@kernel_h + input_bias_h\n",
    "    \n",
    "    h_tm1 = state\n",
    "\n",
    "            \n",
    "    recurrent_z = h_tm1@recurrent_kernel_z\n",
    "    recurrent_r = h_tm1@recurrent_kernel_r\n",
    "#     if reset_after: \n",
    "    recurrent_z = recurrent_z + recurrent_bias_z\n",
    "    recurrent_r = recurrent_r + recurrent_bias_r\n",
    "\n",
    "    z = np.tanh(x_z + recurrent_z)\n",
    "    r = np.tanh(x_r + recurrent_r)\n",
    "\n",
    "    # reset gate applied after/before matrix multiplication\n",
    "    if reset_after:\n",
    "        recurrent_h = h_tm1@recurrent_kernel_h + recurrent_bias_h\n",
    "        recurrent_h = r * recurrent_h\n",
    "    else:\n",
    "        recurrent_h = (r * h_tm1)@recurrent_kernel_h\n",
    "    hh = np.tanh(x_h + recurrent_h)\n",
    "    h = z * h_tm1 + (1 - z) * hh\n",
    "    return h\n",
    "\n",
    "reset_after = True\n",
    "units=12\n",
    "insize = (10,33)\n",
    "a = keras.layers.Input(insize)\n",
    "b = keras.layers.GRU(units, reset_after=reset_after, activation='tanh', recurrent_activation='tanh',\\\n",
    "                    bias_initializer='glorot_uniform',dropout=.76, recurrent_dropout=.25)(a)\n",
    "\n",
    "model = keras.models.Model(inputs=[a], outputs=[b])\n",
    "x = np.random.random(insize)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "kernel = model.layers[1].get_weights()[0]\n",
    "recurrent_kernel = model.layers[1].get_weights()[1]\n",
    "bias = model.layers[1].get_weights()[2]\n",
    "if reset_after:\n",
    "    input_bias = bias[0,:]\n",
    "    recurrent_bias = bias[1,:]\n",
    "else:\n",
    "    recurrent_bias = np.zeros(3*units)\n",
    "    input_bias = bias\n",
    "\n",
    "a = gru(x, kernel, recurrent_kernel, input_bias, recurrent_bias, reset_after, units)\n",
    "np.max(np.abs(a-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6064534425506167e-07"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dropout test\n",
    "inshape = (10,20)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(40, use_bias=False)(a)\n",
    "c = keras.layers.Dropout(.9)(b)\n",
    "d = keras.layers.Dense(40, use_bias=False)(c)\n",
    "model = keras.models.Model(inputs=a, outputs=d)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "y2 = (x@model.layers[1].get_weights()[0])@model.layers[3].get_weights()[0]\n",
    "\n",
    "np.max(np.abs(y2-y)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### flatten / reshape test\n",
    "x = np.array(range(12)).reshape((3,4))\n",
    "x1 = np.reshape(x, (1, -1))\n",
    "np.max(np.abs(x1.flatten() - x.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9774109622238143e-08"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reshape test\n",
    "inshape = (20,16)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Reshape((8,2,2,10))(a)\n",
    "\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "\n",
    "np.max(np.abs(x.flatten()-y.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     1,
     13,
     24
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9799230083504824e-08"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### transpose testing\n",
    "def transp(a,ndim,olddim,permute):\n",
    "    a = a.flatten()\n",
    "    b = np.zeros(a.shape)\n",
    "    oldidx2d = np.array([0,0])\n",
    "    oldidx3d = np.array([0,0,0])\n",
    "    newidx2d = np.array([0,0])\n",
    "    newidx3d = np.array([0,0,0])\n",
    "\n",
    "#    b[i,j,k] = a[i * (dim2 * dim3) + (j * dim3) + k]\n",
    "#    b[i,j] = a[i*dim2 + j]\n",
    "    if ndim==1:\n",
    "        return a # no need to transpose a 1d array\n",
    "    if ndim==2:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                oldidx2d = [i,j]\n",
    "                newidx2d = [oldidx2d[permute[0]],oldidx2d[permute[1]]]\n",
    "                b[newidx2d[0]*newcols + newidx2d[1]] = a[oldidx2d[0]*oldcols + oldidx2d[1]]\n",
    "        return b\n",
    "    if ndim==3:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    oldidx3d = [i,j,k]\n",
    "                    newidx3d = [oldidx3d[permute[0]],oldidx3d[permute[1]],oldidx3d[permute[2]]]\n",
    "                    b[newidx3d[0]*newcols*newchan + newidx3d[1]*newchan + newidx3d[2]] =\\\n",
    "                        a[oldidx3d[0]*oldcols*oldchan + oldidx3d[1]*oldchan + oldidx3d[2]]\n",
    "        return b\n",
    "    if ndim==4:\n",
    "        oldrows = olddim[0]\n",
    "        oldcols = olddim[1]\n",
    "        oldchan = olddim[2]\n",
    "        oldtime = olddim[3]\n",
    "        newrows = olddim[permute[0]]\n",
    "        newcols = olddim[permute[1]]\n",
    "        newchan = olddim[permute[2]]\n",
    "        newtime = olddim[permute[3]]\n",
    "        for i in range(oldrows):\n",
    "            for j in range(oldcols):\n",
    "                for k in range(oldchan):\n",
    "                    for l in range(oldtime):\n",
    "                        oldidx4d = [i,j,k,l]\n",
    "                        newidx4d = [oldidx4d[permute[0]],oldidx4d[permute[1]],oldidx4d[permute[2]],oldidx4d[permute[3]]]\n",
    "                        b[newidx4d[0]*newcols*newchan*newtime + newidx4d[1]*newchan*newtime + newidx4d[2]*newtime + newidx4d[3]] =\\\n",
    "                            a[oldidx4d[0]*oldcols*oldchan*oldtime + oldidx4d[1]*oldchan*oldtime + oldidx4d[2]*oldtime + oldidx4d[3]]\n",
    "        return b\n",
    "\n",
    "inshape = (5,7,8,12)\n",
    "permute = np.array((3,2,1,4))\n",
    "ndim = 4\n",
    "l1 = keras.layers.Input(inshape)\n",
    "l2 = keras.layers.Permute(permute)(l1)\n",
    "model = keras.models.Model(inputs=l1, outputs=l2)\n",
    "\n",
    "x = np.random.random(inshape)\n",
    "x1 = x[np.newaxis,...]\n",
    "y = model.predict(x1)\n",
    "\n",
    "xt = transp(x,ndim,inshape,permute-1)\n",
    "\n",
    "np.max(np.abs(xt-y.flatten()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape = (4,5)\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "model = keras.models.Model(inputs=a, outputs=b)\n",
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc testing and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### indexing testing\n",
    "kernel_size=9\n",
    "in_width=48\n",
    "filters=19\n",
    "b = np.random.random((kernel_size,in_width,filters))\n",
    "a = b.flatten(order='C')\n",
    "idx = (4,17,2)\n",
    "b[idx] - a[idx[0] * (in_width * filters) + (idx[1] * filters) + idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### input/output sizing with filters/padding\n",
    "#out_height = ceil(float(in_height) / float(strides[1]))\n",
    "#out_width  = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "#pad_along_height = max((out_height - 1) * strides[1] +\n",
    "#                    filter_height - in_height, 0)\n",
    "#pad_along_width = max((out_width - 1) * strides[2] +\n",
    "#                   filter_width - in_width, 0)\n",
    "#pad_top = pad_along_height // 2\n",
    "#pad_bottom = pad_along_height - pad_top\n",
    "#pad_left = pad_along_width // 2\n",
    "#pad_right = pad_along_width - pad_left\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### pydot graph testing\n",
    "#graph = pydot.graph_from_dot_data(str())\n",
    "graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "nodes = graph.get_nodes()\n",
    "edges = graph.get_edges()\n",
    "# for edge in edges:\n",
    "#     print(edge)\n",
    "# for node in nodes:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "code_folding": [
     0,
     2,
     19,
     25,
     26,
     68,
     82
    ]
   },
   "outputs": [],
   "source": [
    "### kgraph stuff\n",
    "\n",
    "class keras_node():\n",
    "    def __init__(self, pydot_node):\n",
    "        self.pydot_node = pydot_node\n",
    "        self.ID = pydot_node.to_string().split()[0]\n",
    "        self.type = pydot_node.to_string().split()[2][:-3]\n",
    "        self.name = pydot_node.to_string().split()[1][8:-1]\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "    \n",
    "    def find_layer_idx(self,model):\n",
    "        \"\"\"finds the index into model.layers corresponding to the node\"\"\"\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if layer.name == self.name:\n",
    "                self.layer_idx = i\n",
    "                return\n",
    "        self.layer_idx = None\n",
    "            \n",
    "class keras_edge():\n",
    "    def __init__(self, pydot_edge):\n",
    "        self.pydot_edge = pydot_edge\n",
    "        self.start_id = pydot_edge.to_string().split()[0]\n",
    "        self.end_id = pydot_edge.to_string().split()[2][:-1]\n",
    "\n",
    "class keras_graph():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.pydot_graph = keras.utils.vis_utils.model_to_dot(model)\n",
    "        self.edges = self.parse_edges(self.pydot_graph)\n",
    "        self.nodes = self.parse_nodes(self.pydot_graph)\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        \n",
    "    def parse_edges(self,pydot_graph):\n",
    "        \"\"\"converts pydot edges to keras_graph edges\"\"\"\n",
    "        edges = []\n",
    "        for edge in pydot_graph.get_edges():\n",
    "            edges += [keras_edge(edge)]\n",
    "        return edges\n",
    "    \n",
    "    def parse_nodes(self,pydot_graph):\n",
    "        \"\"\"converts pydot nodes to keras_graph nodes\"\"\"\n",
    "        nodes = []\n",
    "        for i, node in enumerate(pydot_graph.get_nodes()[1:]):\n",
    "            nodes += [keras_node(node)]\n",
    "            nodes[i].find_layer_idx(self.model)\n",
    "        return nodes\n",
    "    \n",
    "    def parse_connections(self):\n",
    "        for edge in self.edges:\n",
    "            self.find_node_from_id(edge.start_id).outputs += [self.find_node_from_id(edge.end_id)]\n",
    "            self.find_node_from_id(edge.end_id).inputs += [self.find_node_from_id(edge.start_id)]\n",
    "\n",
    "    def find_node_from_id(self,ID):\n",
    "        \"\"\"finds the node associated with a given ID\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.ID == ID:\n",
    "                return node\n",
    "        return None\n",
    "    \n",
    "    def find_io_nodes(self):\n",
    "        for node in self.nodes:\n",
    "            if len(node.inputs) == 0:\n",
    "                self.input_nodes += [node]\n",
    "            if len(node.outputs) == 0:\n",
    "                self.output_nodes += [node]\n",
    "            \n",
    "def write_model(model):\n",
    "    kgraph = keras_graph(model)\n",
    "    kgraph.parse_connections()\n",
    "    kgraph.find_io_nodes()\n",
    "\n",
    "    written_nodes = []\n",
    "    unwritten_nodes = copy.deepcopy(kgraph.nodes)\n",
    "    while len(unwritten_nodes)>0:\n",
    "        for node in unwritten_nodes:\n",
    "            if set(node.inputs).issubset(written_nodes):\n",
    "                write_layer(model.layers[node.layer_idx],node)\n",
    "                written_nodes.append(node)\n",
    "                unwritten_nodes.remove(node)\n",
    "        \n",
    "def write_layer(layer,node):\n",
    "    print(layer.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     2,
     3,
     12,
     61,
     70,
     74,
     76,
     84
    ]
   },
   "outputs": [],
   "source": [
    "### check and io functions\n",
    "\n",
    "def get_all_io_names(model):\n",
    "    def flatten(x):\n",
    "        if isinstance(x, list) or isinstance(x, tuple):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]\n",
    "    \n",
    "    a = [get_layer_io_names(layer) for layer in model.layers]\n",
    "    return list(set(flatten(a)))\n",
    "\n",
    "def get_layer_io_names(layer):\n",
    "    inputs = []\n",
    "    num_inputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_input_at(num_inputs)\n",
    "            num_inputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    \n",
    "    outputs = []\n",
    "    num_outputs = 0\n",
    "    error = False\n",
    "    while not error:\n",
    "        try:\n",
    "            layer.get_output_at(num_outputs)\n",
    "            num_outputs +=1\n",
    "        except:\n",
    "            error = True\n",
    "    # num_inputs>1 -> shared layer\n",
    "    for i in range(num_inputs):\n",
    "        # is the input a list?\n",
    "        if isinstance(layer.get_input_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_input_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_input_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            inputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_input_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            inputs.insert(i,name)\n",
    "            \n",
    "    for i in range(num_outputs):\n",
    "        # is the output a list?\n",
    "        if isinstance(layer.get_output_at(i), list):\n",
    "            temp_list = []\n",
    "            list_length = len(layer.get_output_at(i))\n",
    "            for j in range(list_length):\n",
    "                name = str(layer.get_output_at(i)[j]).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "                temp_list.append(name)\n",
    "            outputs.insert(i,temp_list)\n",
    "        else:\n",
    "            name = str(layer.get_output_at(i)).split()[0].split('\"')[1].split('/')[0].split(':')[0]\n",
    "            outputs.insert(i,name)\n",
    "\n",
    "    return (inputs, outputs)\n",
    "\n",
    "def is_valid_c_name(name):\n",
    "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_123456789'\n",
    "    allowed_starting_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_'\n",
    "    if not set(name).issubset(allowed_chars):\n",
    "        return False\n",
    "    if not set(name[0]).issubset(allowed_starting_chars):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def name_check(model):\n",
    "    for layer in model.layers:\n",
    "        assert (is_valid_c_name(layer.name)), \"layer name '\" + layer.name + \"' is not a valid C name\"\n",
    "\n",
    "def layer_type(layer):\n",
    "    return str(layer.__class__).split('.')[-1][0:-2]\n",
    "def layers_supported_check(model):\n",
    "    supported_layers = ['Dense','LSTM','Conv1D','InputLayer','MaxPooling1D','AveragePooling1D',\\\n",
    "                        'GlobalMaxPooling1D','GlobalAveragePooling1D','Add','Multiply','Average',\\\n",
    "                        'Maximum','Minimum','LeakyReLU','ELU','ThresholdedReLU','ReLU']\n",
    "    for layer in model.layers:\n",
    "        assert(layer_type(layer) in supported_layers), \"layer type '\" + \\\n",
    "        layer_type(layer) + \"' is not supported at this time\"\n",
    "        \n",
    "def activation_supported_check(model):\n",
    "    supported_activations = ['linear', 'relu','softmax','softplus','softsign','relu','tanh',\\\n",
    "                             'sigmoid','hard_sigmoid','exponential' ]\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if 'activation' in layer.get_config():\n",
    "            assert(layer.get_config()['activation'] in supported_activations), \\\n",
    "            \"activation type '\" + layer.get_config()['activation'] + \"' is not supported at this time\"\n",
    "        if 'recurrent_activation' in layer.get_config():\n",
    "            assert(layer.get_config()['recurrent_activation'] in supported_activations), \\\n",
    "            \"recurrent activation type '\" + layer.get_config()['recurrent_activation'] + \"' is not supported at this time\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### model testing\n",
    "\n",
    "inshape = (10,10)\n",
    "pool_size=3\n",
    "stride=1\n",
    "dilation=1\n",
    "num_filters=10\n",
    "kernel_size=3\n",
    "pad = 'valid'\n",
    "a = keras.layers.Input(inshape)\n",
    "b = keras.layers.Dense(10)(a)\n",
    "c = keras.layers.AveragePooling1D(pool_size=pool_size, strides=stride, padding=pad)(b)\n",
    "# d = keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, padding=pad, dilation_rate=dilation)(c)\n",
    "# e = keras.layers.Input((10,10))\n",
    "# f = keras.layers.Dense(10)(e)\n",
    "# g = keras.layers.LSTM(10)(f)\n",
    "# h = keras.layers.add([g,d,e])\n",
    "model = keras.models.Model(inputs=[a], outputs=[c])\n",
    "\n",
    "# a = keras.layers.Input(inshape)\n",
    "# b = keras.layers.Input(inshape)\n",
    "# c = keras.layers.LSTM(20)\n",
    "# d = c(a)\n",
    "# e = c(b)\n",
    "# model = keras.models.Model(inputs=[a,b], outputs=[d,e])\n",
    "\n",
    "#print(model.layers[1].input_shape)\n",
    "#print(model.layers[1].output_shape)\n",
    "#print(model.layers[1].get_weights()[0].shape)\n",
    "#model.layers[2].get_config()\n",
    "print(model.layers[0].name)\n",
    "str(model.layers[0].get_input_at(0)).split()[0][8:-4]\n",
    "dir(model)\n",
    "print(model.output[0].name)\n",
    "len(model.layers[-1].input_shape)\n",
    "#print(model.layers[5].name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ktf2cpp] *",
   "language": "python",
   "name": "conda-env-ktf2cpp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
