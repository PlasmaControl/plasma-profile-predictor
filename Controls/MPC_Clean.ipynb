{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Clean Version of the MPC Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import helpers\n",
    "from helpers.data_generator import process_data, AutoEncoderDataGenerator, DataGenerator\n",
    "from helpers.custom_losses import normed_mse, mean_diff_sum_2, max_diff_sum_2, mean_diff2_sum2, max_diff2_sum2, denorm_loss, hinge_mse_loss, percent_correct_sign, baseline_MAE\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import strftime, localtime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import copy\n",
    "from tqdm import tqdm_notebook\n",
    "from helpers.normalization import normalize, denormalize, renormalize\n",
    "import scipy\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import Image, display\n",
    "from helpers.custom_init import downsample\n",
    "from helpers.custom_reg import groupLasso\n",
    "import helpers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_17Nov20-09-22_Scenario-1_params.pkl',\n",
       " 'model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_17Nov20-09-26_Scenario-1_params.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.expanduser('/home/aiqtidar/test_run/'))\n",
    "files = [foo for foo in os.listdir() if '.pkl' in foo]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0317 20:51:32.208167 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0317 20:51:32.234373 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0317 20:51:32.476482 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/engine/saving.py:348: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "W0317 20:51:33.139197 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0317 20:51:33.140389 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:200: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0317 20:51:33.140880 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0317 20:51:34.598798 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0317 20:51:34.603625 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0317 20:51:35.498975 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: (20, 20)\n",
      "B: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "def get_AB(model):\n",
    "    A = model.get_layer('AB_matrices').get_weights()[1].T\n",
    "    B = model.get_layer('AB_matrices').get_weights()[0].T\n",
    "    return A,B\n",
    "\n",
    "model = keras.models.load_model('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0.h5', compile=False)\n",
    "with open('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0_params.pkl', 'rb') as f:\n",
    "    scenario = pickle.load(f, encoding='latin1')\n",
    "        \n",
    "A,B = get_AB(model)\n",
    "print(\"A: \" + str(A.shape))\n",
    "print(\"B: \" + str(B.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals: curr, dens, ffprime_EFIT02, gasA, pinj, press_EFIT02, q_EFIT02, temp, tinj\n",
      "Number of useable shots:  5531\n",
      "Number of shots used:  5531\n",
      "Total number of timesteps:  586968\n",
      "Shots with Complete NaN: \n",
      "125691 samples total\n",
      "Removing weird I-coils\n",
      "Removed 24703 samples\n",
      "100988 samples remaining\n",
      "Removing NaN\n",
      "Removed 0 samples\n",
      "100988 samples remaining\n",
      "Removing dudtrip\n",
      "Removed 7074 samples\n",
      "93914 samples remaining\n",
      "93914 samples remaining after pruning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denormalizing: 100%|##########| 15/15 [00:00<00:00, 475.22it/s]\n",
      "Normalizing: 100%|##########| 15/15 [00:00<00:00, 162.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  93914\n",
      "Number of training samples:  84213\n",
      "Number of validation samples:  9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CPU Only. \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "num_cores = 1\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4*num_cores,\n",
    "                        inter_op_parallelism_threads=4*num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 0})\n",
    "                        \n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "%matplotlib inline\n",
    "font={'family': 'DejaVu Serif',\n",
    "      'size': 18}\n",
    "plt.rc('font', **font)\n",
    "matplotlib.rcParams['figure.facecolor'] = (1,1,1,1)\n",
    "\n",
    "matplotlib_colors = [(0.1215, 0.4667, 0.7058), # blue\n",
    "                     (1.0000, 0.4980, 0.0549), # orange\n",
    "                     (0.1725, 0.6275, 0.1725), # green\n",
    "                     (0.8392, 0.1529, 0.1568), # red\n",
    "                     (0.5804, 0.4039, 0.7412), # violet\n",
    "                     (0.4980, 0.4980, 0.4980), # grey\n",
    "                     (0.0902, 0.7450, 0.8117)] # cyan\n",
    "\n",
    "matlab_colors=[(0.0000, 0.4470, 0.7410), # blue\n",
    "               (0.8500, 0.3250, 0.0980), # reddish orange\n",
    "               (0.9290, 0.6940, 0.1250), # yellow\n",
    "               (0.4940, 0.1840, 0.5560), # purple\n",
    "               (0.4660, 0.6740, 0.1880), # light green\n",
    "               (0.3010, 0.7450, 0.9330), # cyan\n",
    "               (0.6350, 0.0780, 0.1840)] # dark red\n",
    "\n",
    "colorblind_colors = [(0.0000, 0.4500, 0.7000), # blue\n",
    "                     (0.8359, 0.3682, 0.0000), # vermillion\n",
    "                     (0.0000, 0.6000, 0.5000), # bluish green\n",
    "                     (0.9500, 0.9000, 0.2500), # yellow\n",
    "                     (0.3500, 0.7000, 0.9000), # sky blue\n",
    "                     (0.8000, 0.6000, 0.7000), # reddish purple\n",
    "                     (0.9000, 0.6000, 0.0000)] # orange\n",
    "\n",
    "dashes = [(1.0, 0.0, 0.0, 0.0, 0.0, 0.0), # solid\n",
    "          (3.7, 1.6, 0.0, 0.0, 0.0, 0.0), # dashed\n",
    "          (1.0, 1.6, 0.0, 0.0, 0.0, 0.0), # dotted\n",
    "          (6.4, 1.6, 1.0, 1.6, 0.0, 0.0), # dot dash\n",
    "          (3.0, 1.6, 1.0, 1.6, 1.0, 1.6), # dot dot dash\n",
    "          (6.0, 4.0, 0.0, 0.0, 0.0, 0.0), # long dash\n",
    "          (1.0, 1.6, 3.0, 1.6, 3.0, 1.6)] # dash dash dot\n",
    "\n",
    "from matplotlib import rcParams, cycler\n",
    "matplotlib.rcdefaults()\n",
    "rcParams['font.family'] = 'DejaVu Serif'\n",
    "rcParams['mathtext.fontset'] = 'cm'\n",
    "rcParams['font.size'] = 12\n",
    "rcParams['figure.facecolor'] = (1,1,1,1)\n",
    "rcParams['figure.figsize'] = (16,8)\n",
    "rcParams['figure.dpi'] = 141\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.labelsize'] =  'large'\n",
    "rcParams['axes.titlesize'] = 'x-large'\n",
    "rcParams['lines.linewidth'] = 2.5\n",
    "rcParams['lines.solid_capstyle'] = 'round'\n",
    "rcParams['lines.dash_capstyle'] = 'round'\n",
    "rcParams['lines.dash_joinstyle'] = 'round'\n",
    "rcParams['xtick.labelsize'] = 'large'\n",
    "rcParams['ytick.labelsize'] = 'large'\n",
    "# rcParams['text.usetex']=True\n",
    "color_cycle = cycler(color=colorblind_colors)\n",
    "dash_cycle = cycler(dashes=dashes)\n",
    "rcParams['axes.prop_cycle'] =  color_cycle\n",
    "\n",
    "labelsize=10\n",
    "ticksize=8\n",
    "# for i,c in enumerate(colorblind_colors):\n",
    "#     plt.plot((i)*np.ones(5),c=c)\n",
    "\n",
    "eq_sigs = {'temp':'etemp',\n",
    "         'thomson_temp_EFITRT1':'etemp',\n",
    "         'thomson_temp_EFITRT2':'etemp',\n",
    "         'dens':'edens',\n",
    "         'thomson_dens_EFITRT1':'edens',\n",
    "         'thomson_dens_EFITRT2':'edens',\n",
    "         'itemp':'itemp',\n",
    "         'cerquick_temp_EFITRT1':'itemp',\n",
    "         'cerquick_temp_EFITRT2':'itemp',\n",
    "         'rotation':'rotation',\n",
    "         'cerquick_rotation_EFITRT1':'rotation',\n",
    "         'cerquick_rotation_EFITRT2':'rotation',\n",
    "         'press_EFITRT1':'press',\n",
    "         'press_EFITRT2':'press',\n",
    "         'press_EFIT01':'press',\n",
    "         'press_EFIT02':'press',\n",
    "         'ffprime_EFITRT1':'ffprime',\n",
    "         'ffprime_EFITRT2':'ffprime',\n",
    "         'ffprime_EFIT01':'ffprime',\n",
    "         'ffprime_EFIT02':'ffprime',\n",
    "         'q':'q',\n",
    "         'q_EFITRT1':'q',\n",
    "         'q_EFITRT2':'q',\n",
    "         'q_EFIT01':'q',\n",
    "         'q_EFIT02':'q'}\n",
    "\n",
    "labels = {'edens': '$n_e$ ($10^{19}/m^3$)',\n",
    "          'etemp': '$T_e$ (keV)',\n",
    "          'itemp': '$T_i$ (keV)',\n",
    "          'rotation':'$\\Omega$ (kHz)',\n",
    "          'q':'$\\iota$',\n",
    "          'press':'$P$ (Pa)',\n",
    "         'ffprime':\"$FF'$\"}\n",
    "\n",
    "labels = {key:labels[val] for key, val in eq_sigs.items()}\n",
    "\n",
    "scatter_titles = {'mean':'Mean',\n",
    "                  'std':'Std Dev.',\n",
    "                  'pca_1':'PCA Mode 1',\n",
    "                  'pca_2':'PCA Mode 2',\n",
    "                  'pca_3':'PCA Mode 3',\n",
    "                  'pca_4':'PCA Mode 4',\n",
    "                  'pca_5':'PCA Mode 5',\n",
    "                  'pca_6':'PCA Mode 6',\n",
    "                  'pca_2':'PCA Mode 2'}\n",
    "\n",
    "\n",
    "datapath = '/scratch/gpfs/jabbate/full_data_with_error/train_data.pkl'\n",
    "with open(datapath,'rb') as f:\n",
    "    rawdata = pickle.load(f,encoding='latin1')\n",
    "    \n",
    "traindata, valdata, normalization_dict = process_data(rawdata,\n",
    "                                                              scenario['sig_names'],\n",
    "                                                              scenario['normalization_method'],\n",
    "                                                              scenario['window_length'],\n",
    "                                                              scenario['window_overlap'],\n",
    "                                                              scenario['lookback'],\n",
    "                                                              scenario['lookahead'],\n",
    "                                                              scenario['sample_step'],\n",
    "                                                              scenario['uniform_normalization'],\n",
    "                                                              1,\n",
    "                                                              0,\n",
    "                                                              scenario['nshots'],\n",
    "                                                              2,\n",
    "                                                              scenario['flattop_only'],\n",
    "                                                              pruning_functions=scenario['pruning_functions'],\n",
    "                                                              invert_q = None, #scenario['invert_q'],\n",
    "                                                              val_idx = 0,\n",
    "                                                              excluded_shots=scenario['excluded_shots'],\n",
    "                                                            randomize=False)\n",
    "valdata = denormalize(valdata, normalization_dict)\n",
    "valdata = renormalize(valdata, scenario['normalization_dict'])\n",
    "generator = AutoEncoderDataGenerator(valdata,\n",
    "                                               1,  \n",
    "                                               scenario['profile_names'],\n",
    "                                               scenario['actuator_names'],\n",
    "                                               scenario['scalar_names'],\n",
    "                                               scenario['lookback'],\n",
    "                                               scenario['lookahead'],\n",
    "                                               scenario['profile_downsample'],\n",
    "                                               scenario['state_latent_dim'],\n",
    "                                               scenario['discount_factor'],\n",
    "                                               scenario['x_weight'],\n",
    "                                               scenario['u_weight'],                                            \n",
    "                                               scenario['shuffle_generators'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoders and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/engine/saving.py:348: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "def get_submodels(model):\n",
    "    from keras.models import Model\n",
    "    state_encoder = model.get_layer('state_encoder_time_dist').layer.layers[-1]\n",
    "    control_encoder = model.get_layer('ctrl_encoder_time_dist').layer.layers[-1]\n",
    "    state_decoder = model.get_layer('state_decoder_time_dist').layer\n",
    "    return state_encoder, state_decoder, control_encoder\n",
    "        \n",
    "def get_state_and_inputs(scenario,inputs,**kwargs):\n",
    "    state_inputs = {}\n",
    "    x0 = {}\n",
    "    for sig in scenario['profile_names']+scenario['scalar_names']:\n",
    "        state_inputs[sig] = np.squeeze(inputs[0]['input_'+sig])\n",
    "        if sig in scenario['profile_names']:\n",
    "            x0['input_'+sig] = inputs[0]['input_'+sig][0][0].reshape((1,1,scenario['profile_length']))\n",
    "        else:\n",
    "            x0['input_'+sig] = inputs[0]['input_'+sig][0][0].reshape((1,1,1))\n",
    "    \n",
    "    control_inputs = {}\n",
    "    for sig in scenario['actuator_names']:\n",
    "        control_inputs['input_'+sig] = inputs[0]['input_'+sig]\n",
    "    return x0, control_inputs\n",
    "\n",
    "def encode_state_and_inputs(state_encoder,control_encoder,scenario,x0,control_inputs,**kwargs):\n",
    "    # encode control\n",
    "    T = scenario['lookback'] + scenario['lookahead']\n",
    "    u = []\n",
    "    for i in range(T):\n",
    "        temp_input = {k:v[:,i].reshape((1,1,1)) for k,v in control_inputs.items()}\n",
    "        u.append(np.squeeze(control_encoder.predict(temp_input)))\n",
    "        \n",
    "    # encode state and propogate\n",
    "    x0 = np.squeeze(state_encoder.predict(x0))\n",
    "    return x0, u\n",
    "    \n",
    "def decode_state(state_decoder,scenario,x,shot,timestep,**kwargs):\n",
    "    # decode state and organize\n",
    "    x_decoded = []\n",
    "    for elem in x:\n",
    "        x_decoded.append(state_decoder.predict(elem[np.newaxis,:]))\n",
    "    state_predictions = {}\n",
    "    residuals = {}\n",
    "    for i, sig in enumerate(scenario['profile_names']):\n",
    "        state_predictions[sig] = np.squeeze(np.array([x_decoded[j][i] for j in range(len(x_decoded))]))\n",
    "        residuals[sig] = state_inputs[sig] - state_predictions[sig]\n",
    "    return state_inputs, state_predictions, residuals\n",
    "\n",
    "def get_final_state(state_encoder,scenario,inputs,**kwargs):\n",
    "    state_inputs = {}\n",
    "    xf = {}\n",
    "    for sig in scenario['profile_names']+scenario['scalar_names']:\n",
    "        state_inputs[sig] = np.squeeze(inputs[0]['input_'+sig])\n",
    "        if sig in scenario['profile_names']:\n",
    "            xf['input_'+sig] = inputs[0]['input_'+sig][0][3].reshape((1,1,scenario['profile_length']))\n",
    "        else:\n",
    "            xf['input_'+sig] = inputs[0]['input_'+sig][0][3].reshape((1,1,1))\n",
    "    \n",
    "    xf_enc = np.squeeze(state_encoder.predict(xf))\n",
    "    return xf, xf_enc\n",
    "\n",
    "model = keras.models.load_model('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0.h5', compile=False)\n",
    "with open('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0_params.pkl', 'rb') as f:\n",
    "    scenario = pickle.load(f, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Input: (9701, 3, 5)701\n",
      "Enc_x: (9701, 20)\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "#######################################################################################\n",
    "state_encoder, state_decoder, control_encoder = get_submodels(model)\n",
    "x = []\n",
    "XF = []\n",
    "enc_x = []\n",
    "enc_XF = []\n",
    "\n",
    "inputs = []\n",
    "enc_inputs = []\n",
    "\n",
    "for i in range(len(generator)):\n",
    "    print(\"Completed {} out of {}\".format(i+1,len(generator)),end='\\r')\n",
    "    \n",
    "    # Get state and input from generators\n",
    "    temp_x, temp_con_inputs = get_state_and_inputs(scenario,generator[i])\n",
    "    x.append(temp_x)\n",
    "    \n",
    "    \n",
    "    # Append control inputs\n",
    "    inputs.append(temp_con_inputs)\n",
    "    \n",
    "    # Encode state and inputs\n",
    "    temp_x, temp_con_inputs = encode_state_and_inputs(state_encoder,control_encoder,scenario,temp_x,temp_con_inputs)\n",
    "    enc_x.append(temp_x)\n",
    "    enc_inputs.append(temp_con_inputs)\n",
    "    \n",
    "    # Get final encoded state for MPC\n",
    "    exf, exf_enc = get_final_state(state_encoder,scenario,generator[i])\n",
    "    XF.append(exf)\n",
    "    enc_XF.append(exf_enc)\n",
    "\n",
    "enc_inputs = np.array(enc_inputs)\n",
    "enc_x = np.array(enc_x)\n",
    "print(\"Enc Input: {}\".format(enc_inputs.shape))\n",
    "print(\"Enc_x: {}\".format(enc_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical MPC Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Classical_MPC_system(Q,R,A,B,x0,n):\n",
    "\n",
    "    import numpy\n",
    "    from cvxopt import matrix\n",
    "    from cvxopt import solvers\n",
    "\n",
    "\n",
    "    # Define parameters\n",
    "    N = A.shape[0]\n",
    "    M = B.shape[1]\n",
    "\n",
    "    ############################### Generate Matrices ####################################\n",
    "\n",
    "    # Generate Matrix M\n",
    "    M_bar = np.zeros((N * n, N))\n",
    "    rsl = slice(0, N)\n",
    "    M_bar[rsl, :N] = A\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        M_bar[rsl, :N] = A @ M_bar[rsl_p, :N]\n",
    "\n",
    "    # Generate Q_bar\n",
    "    Q_bar = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    Q_bar[rsl, :N] = Q\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        Q_bar[rsl, N : (i + 1) * N] = Q_bar[rsl_p, : i * N]\n",
    "\n",
    "    # Generate R_bar\n",
    "    R = np.diag(np.ones((M)))\n",
    "    R_bar = np.kron(np.eye(n),R)\n",
    "\n",
    "    # Generate V\n",
    "    V = np.zeros((N * n, n * M))\n",
    "    rsl = slice(0, N)\n",
    "    V[rsl, :M] = B #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        V[rsl, :M] = A @ V[rsl_p, :M] # A^(N-1)*B\n",
    "        V[rsl, M : (i + 1) * M] = V[rsl_p, : i * M]\n",
    "\n",
    "    # Generate D_bar, d\n",
    "    D_bar = np.zeros((2*M*n,M*n))\n",
    "    rsl = slice(0,M*n)\n",
    "    D_bar[rsl, rsl] = np.eye(M*n)\n",
    "    D_bar[slice(M*n,2*M*n), rsl] = -np.eye(M*n)\n",
    "\n",
    "    d = np.zeros((2*M*n,1))\n",
    "    \n",
    "    # Limits on u\n",
    "    d[rsl,:] = np.ones((M*n,1))*10\n",
    "    d[slice(M*n,2*M*n),:] = -np.ones((M*n,1))*10\n",
    "\n",
    "    # Generate F and H matrices\n",
    "    temp = np.transpose(V).dot(Q_bar)\n",
    "    F = temp.dot(M_bar)\n",
    "\n",
    "    temp = np.transpose(V).dot(Q_bar)\n",
    "    H = temp.dot(V) + R_bar\n",
    "\n",
    "    ########################################### Do computations #############################\n",
    "\n",
    "    # Define QP parameters (with NumPy)\n",
    "\n",
    "\n",
    "    P = matrix(H, tc='d')\n",
    "    q = matrix(F.dot(x0), tc='d')\n",
    "    G = matrix(D_bar, tc='d')\n",
    "    h = matrix(d, tc='d')\n",
    "\n",
    "\n",
    "    ######################################### Print Solution ###############################\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P,q,G,h)\n",
    "    # Extract optimal value and solution\n",
    "    sol['x'] # [7.13e-07, 5.00e+00]\n",
    "    sol['primal objective'] # 20.0000061731\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: [[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 10.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0. 10.]]\n",
      "R: [[10.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0. 10.]]\n"
     ]
    }
   ],
   "source": [
    "x0 = - enc_x[0] + enc_XF[0]\n",
    "\n",
    "N = x0.shape[0]\n",
    "M = enc_inputs.shape[2]\n",
    "\n",
    "# Generate Q,R\n",
    "Q = np.eye(N)*1e1\n",
    "R = np.eye(M)*1e1\n",
    "\n",
    "n = scenario['lookback'] + scenario['lookahead']\n",
    "print(\"Q: {}\".format(np.matrix.view(Q)))\n",
    "print(\"R: {}\".format(np.matrix.view(R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.2909e+02  2.0813e+03  2e+03  1e+00  2e-14\n",
      " 1:  1.5590e+03  6.0337e+03  3e+03  8e-01  9e-14\n",
      " 2:  5.6905e+03  9.4328e+03  3e+03  4e-01  4e-13\n",
      " 3:  7.5343e+03  1.0554e+04  3e+03  3e-01  4e-13\n",
      " 4:  9.2543e+03  1.1093e+04  2e+03  1e-01  2e-13\n",
      " 5:  1.1162e+04  1.1236e+04  7e+01  4e-03  1e-12\n",
      " 6:  1.1235e+04  1.1236e+04  8e-01  4e-05  4e-13\n",
      " 7:  1.1236e+04  1.1236e+04  8e-03  4e-07  2e-13\n",
      " 8:  1.1236e+04  1.1236e+04  8e-05  4e-09  3e-13\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999998,  9.99999998,  9.99999997, 10.00000002,  9.99999997],\n",
       "       [ 9.99999998,  9.99999998,  9.99999998, 10.00000004,  9.99999998],\n",
       "       [ 9.99999998,  9.99999998,  9.99999998, 10.00000003,  9.99999998]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_mpc = solve_Classical_MPC_system(Q,R,A,B,x0,n)\n",
    "sol_mpc = np.array(sol_mpc['x'])\n",
    "u_mpc = sol_mpc.reshape(3, 5)\n",
    "u_mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo MPC System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(A: np.ndarray, B: np.ndarray, Q: np.ndarray, R: np.ndarray) -> np.ndarray:\n",
    "    from scipy.linalg import solve_discrete_are\n",
    "    return solve_discrete_are(A, B, Q, R) \n",
    "\n",
    "def solve_Neo_MPC_system(Q,R,A,B,x0,xf,n):\n",
    "    \n",
    "    # Imports\n",
    "    import numpy\n",
    "    from cvxopt import matrix\n",
    "    from cvxopt import solvers\n",
    "    \n",
    "    # Define parameters\n",
    "    N = A.shape[0]\n",
    "    M = B.shape[1]\n",
    "    print(\"N: {}\".format(N))\n",
    "    print(\"M: {}\".format(M))\n",
    "    \n",
    "    # Reshape to avoid complications\n",
    "    x0 = x0.reshape((N,1))\n",
    "    xf = xf.reshape((N,1))\n",
    "\n",
    "    ############################### Generate Matrices ####################################\n",
    "\n",
    "    # Generate Matrix M\n",
    "    M_bar = np.zeros((N * n, N))\n",
    "    rsl = slice(0, N)\n",
    "    M_bar[rsl, :N] = A\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        M_bar[rsl, :N] = A @ M_bar[rsl_p, :N]\n",
    "    \n",
    "#     print(\"M_bar: {}\".format(M_bar))\n",
    "    \n",
    "    # Generate Q_bar\n",
    "    Q_bar = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    Q_bar[rsl, :N] = Q\n",
    "\n",
    "    for i in range(1, n-1):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        Q_bar[rsl, N : (i + 1) * N] = Q_bar[rsl_p, : i * N]\n",
    "    \n",
    "    Q_N = lqr(A,B,Q,R)\n",
    "    rsl = slice((n-1) * N, n * N)\n",
    "    Q_bar[rsl, rsl] = Q_N\n",
    "    \n",
    "#     print(\"Q_bar: {}\".format(Q_bar))\n",
    "\n",
    "    # Generate R_bar\n",
    "    R_bar = np.kron(np.eye(n),R)\n",
    "    \n",
    "#     print(\"R_bar: {}\".format(R_bar))\n",
    "\n",
    "    # Generate V\n",
    "    V = np.zeros((N * n, n * M))\n",
    "    rsl = slice(0, N)\n",
    "    V[rsl, :M] = B #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        V[rsl, :M] = A @ V[rsl_p, :M] # A^(N-1)*B\n",
    "        V[rsl, M : (i + 1) * M] = V[rsl_p, : i * M]\n",
    "    \n",
    "#     print(\"V: {}\".format(V))\n",
    "        \n",
    "    # Generate L\n",
    "    L = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    L[rsl, :N] = A #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        L[rsl, :N] = L[rsl_p, :N]\n",
    "        L[rsl, N : (i + 1) * N] = A @ L[rsl_p, : i * N]\n",
    "    \n",
    "#     print(\"L: {}\".format(np.matrix.view(L)))\n",
    "    \n",
    "    #Generate X_F from x_f\n",
    "    X_F = np.zeros((N*n,1))\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        rsl = slice(i * N, (i + 1)*N)\n",
    "        X_F[rsl] = xf\n",
    "    \n",
    "#     print(\"XF: {}\".format(X_F))\n",
    "    \n",
    "    # Generate D_bar, d\n",
    "    D_bar = np.zeros((2*M*n,M*n))\n",
    "    rsl = slice(0,M*n)\n",
    "    D_bar[rsl, rsl] = np.eye(M*n)\n",
    "    D_bar[slice(M*n,2*M*n), rsl] = -np.eye(M*n)\n",
    "\n",
    "    d = np.zeros((2*M*n,1))\n",
    "    \n",
    "    # Limits on U\n",
    "    lim = 1\n",
    "    \n",
    "    d[rsl,:] = np.ones((M*n,1))*lim\n",
    "    d[slice(M*n,2*M*n),:] = np.ones((M*n,1))*lim\n",
    "\n",
    "#     print(\"D_bar: {}\".format(D_bar))\n",
    "#     print(\"D: {}\".format(d))\n",
    "    \n",
    "    # Generate F and H matrices   \n",
    "    temp = np.transpose(V) @ (Q_bar)\n",
    "    F = temp @ (M_bar.dot(x0)  + L @ (X_F)) # + L @ (X_F)\n",
    "    \n",
    "    temp = np.transpose(V) @ (Q_bar)\n",
    "    H = temp @ (V) + R_bar\n",
    "    \n",
    "#     print(\"H: {}\".format(H))\n",
    "#     print(\"F: {}\".format(F))\n",
    "\n",
    "    ########################################### Do computations #############################\n",
    "\n",
    "    # Define QP parameters (with NumPy)\n",
    "\n",
    "    P = matrix(H, tc='d')\n",
    "    q = matrix(F, tc='d')\n",
    "    G = matrix(D_bar, tc='d')\n",
    "    h = matrix(d, tc='d')\n",
    "\n",
    "    ######################################### Print Solution ###############################\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P,q, G, h)\n",
    "\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 20\n",
      "M: 5\n",
      "n: 3\n",
      "Q: [[1000.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0. 1000.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0. 1000.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0. 1000.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0. 1000.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0. 1000.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0. 1000.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0. 1000.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0. 1000.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0. 1000.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0. 1000.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. 1000.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  1000.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0. 1000.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0. 1000.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0. 1000.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0. 1000.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0. 1000.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0. 1000.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0. 1000.]]\n",
      "R: [[1.e+10 0.e+00 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 1.e+10 0.e+00 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 1.e+10 0.e+00 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 1.e+10 0.e+00]\n",
      " [0.e+00 0.e+00 0.e+00 0.e+00 1.e+10]]\n"
     ]
    }
   ],
   "source": [
    "# 0 <= Sample < 9701\n",
    "sample = 1000\n",
    "\n",
    "x0 = enc_x[sample] \n",
    "xf = enc_XF[sample]\n",
    "x_tilde0 = x0 - xf\n",
    "\n",
    "N = x0.shape[0]\n",
    "M = enc_inputs.shape[2]\n",
    "\n",
    "# Generate Q,R\n",
    "Q = np.eye(N)*1e3\n",
    "R = np.eye(M)*1e10\n",
    "\n",
    "# Replenish A,B\n",
    "A,B = get_AB(model)\n",
    "\n",
    "n = scenario['lookback'] + scenario['lookahead']\n",
    "print(\"N: {}\".format(N))\n",
    "print(\"M: {}\".format(M))\n",
    "print(\"n: {}\".format(n))\n",
    "print(\"Q: {}\".format(np.matrix.view(Q)))\n",
    "print(\"R: {}\".format(np.matrix.view(R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 20\n",
      "M: 5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.1625e+02  2.2601e+03  1e+03  1e+00  3e-16\n",
      " 1: -2.5496e+02  2.2001e+04  2e+03  1e+00  7e-16\n",
      " 2:  1.8521e+04  2.0685e+05  4e+04  1e+00  2e-15\n",
      " 3:  3.8635e+04  3.2881e+05  6e+04  1e+00  6e-15\n",
      " 4:  2.4158e+05  6.9866e+05  2e+05  7e-01  2e-14\n",
      " 5:  4.6604e+05  8.4139e+05  2e+05  4e-01  1e-14\n",
      " 6:  5.0047e+05  9.1679e+05  3e+05  4e-01  1e-14\n",
      " 7:  5.8728e+05  9.2208e+05  3e+05  3e-01  2e-14\n",
      " 8:  8.5357e+05  1.0556e+06  3e+05  1e-01  1e-13\n",
      " 9:  1.0638e+06  1.0728e+06  1e+04  5e-03  2e-14\n",
      "10:  1.0727e+06  1.0728e+06  1e+02  5e-05  5e-14\n",
      "11:  1.0728e+06  1.0728e+06  1e+00  5e-07  4e-14\n",
      "12:  1.0728e+06  1.0728e+06  1e-02  5e-09  5e-14\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999996,  9.99999998,  9.99999996,  9.99999999,  9.99999996],\n",
       "       [ 9.99999996,  9.99999997,  9.99999998, 10.00000005,  9.99999998],\n",
       "       [ 9.99999997,  9.99999997,  9.99999997, 10.00000004,  9.99999997]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_mpc = solve_Neo_MPC_system(Q,R,A,B,x_tilde0,xf,n)\n",
    "sol_mpc = np.array(sol_mpc['x'])\n",
    "u_mpc = sol_mpc.reshape(3, 5)\n",
    "u_mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs[sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot u vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sol_mpc)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.ylabel(\"u\")\n",
    "plt.xlabel(\"# Timestep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot how state changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "abs_diff = []\n",
    "abs_fin_diff = []\n",
    "x_prev = x_0\n",
    "\n",
    "for i in range(0,n):\n",
    "    x_new = (A @ x_prev) + np.transpose(B.dot(sol_mpc[i])[np.newaxis])\n",
    "    print(\"x[{}]: {} \\n\".format(i+1,x_new))\n",
    "\n",
    "    states.append(x_prev)\n",
    "    abs_diff.append(np.linalg.norm(x_new - x_prev))\n",
    "    abs_fin_diff.append(np.linalg.norm(x_new - x_f))\n",
    "    x_prev = x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
