{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Clean Version of the MPC Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the trial and error code. A lot of the code is error prone. Look at MPC_clean_autoencoder-model2.ipynb for the cleaner version of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n",
      "435\n",
      "Total: 11061\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "from keras.models import Model\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import helpers\n",
    "from helpers.data_generator import process_data, AutoEncoderDataGenerator, DataGenerator\n",
    "from helpers.custom_losses import normed_mse, mean_diff_sum_2, max_diff_sum_2, mean_diff2_sum2, max_diff2_sum2, denorm_loss, hinge_mse_loss, percent_correct_sign, baseline_MAE\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from time import strftime, localtime\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import copy\n",
    "from tqdm import tqdm_notebook\n",
    "from helpers.normalization import normalize, denormalize, renormalize\n",
    "import scipy\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import Image, display\n",
    "from helpers.custom_init import downsample\n",
    "from helpers.custom_reg import groupLasso\n",
    "import helpers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('/home/aaronwu/run_results_06_30/'))\n",
    "files = [foo for foo in os.listdir() if '.pkl' in foo]\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'model-conv2d_profiles-dens-temp-q_EFIT01-rotation-press_EFIT01_act-target_density-pinj-tinj-curr_target_15Mar20-03-48_Scenario-265_params.pkl'\n",
    "# os.chdir(os.path.expanduser('/projects/EKOLEMEN/profile_predictor/run_results_03_10/'))\n",
    "# files = [foo for foo in os.listdir() if 'Scenario-265.h5' in foo]\n",
    "# print(\"Matching files at {} are : {}\".format(os.getcwd(),files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 14:49:01.900738 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0422 14:49:01.927160 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0422 14:49:02.212109 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/engine/saving.py:348: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "W0422 14:49:02.591621 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0422 14:49:02.592930 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:200: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0422 14:49:02.594038 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0422 14:49:02.653248 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0422 14:49:02.654499 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0422 14:49:02.747741 35184372369072 module_wrapper.py:139] From /scratch/gpfs/aiqtidar/.conda/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: (100, 100)\n",
      "B: (100, 15)\n"
     ]
    }
   ],
   "source": [
    "def get_AB(model):\n",
    "    A = model.get_layer('AB_matrices').get_weights()[1].T\n",
    "    B = model.get_layer('AB_matrices').get_weights()[0].T\n",
    "    return A,B\n",
    "\n",
    "# Some Model\n",
    "# model = keras.models.load_model('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0.h5', compile=False)\n",
    "# with open('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0_params.pkl', 'rb') as f:\n",
    "#     scenario = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Aaron's Ideal Model\n",
    "model = keras.models.load_model('/home/aaronwu/run_results_06_30/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_30Jun20-17-10.h5', compile=False)\n",
    "with open('/home/aaronwu/run_results_06_30/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_30Jun20-17-10_params.pkl', 'rb') as f:\n",
    "    scenario = pickle.load(f, encoding='latin1')\n",
    "\n",
    "\n",
    "    \n",
    "A,B = get_AB(model)\n",
    "print(\"A: \" + str(A.shape))\n",
    "print(\"B: \" + str(B.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4212769450dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scratch/gpfs/jabbate/full_data_with_error/train_data.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m traindata, valdata, normalization_dict = process_data(rawdata,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CPU Only. \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "num_cores = 1\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4*num_cores,\n",
    "                        inter_op_parallelism_threads=4*num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 0})\n",
    "                        \n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "%matplotlib inline\n",
    "font={'family': 'DejaVu Serif',\n",
    "      'size': 18}\n",
    "plt.rc('font', **font)\n",
    "matplotlib.rcParams['figure.facecolor'] = (1,1,1,1)\n",
    "\n",
    "matplotlib_colors = [(0.1215, 0.4667, 0.7058), # blue\n",
    "                     (1.0000, 0.4980, 0.0549), # orange\n",
    "                     (0.1725, 0.6275, 0.1725), # green\n",
    "                     (0.8392, 0.1529, 0.1568), # red\n",
    "                     (0.5804, 0.4039, 0.7412), # violet\n",
    "                     (0.4980, 0.4980, 0.4980), # grey\n",
    "                     (0.0902, 0.7450, 0.8117)] # cyan\n",
    "\n",
    "matlab_colors=[(0.0000, 0.4470, 0.7410), # blue\n",
    "               (0.8500, 0.3250, 0.0980), # reddish orange\n",
    "               (0.9290, 0.6940, 0.1250), # yellow\n",
    "               (0.4940, 0.1840, 0.5560), # purple\n",
    "               (0.4660, 0.6740, 0.1880), # light green\n",
    "               (0.3010, 0.7450, 0.9330), # cyan\n",
    "               (0.6350, 0.0780, 0.1840)] # dark red\n",
    "\n",
    "colorblind_colors = [(0.0000, 0.4500, 0.7000), # blue\n",
    "                     (0.8359, 0.3682, 0.0000), # vermillion\n",
    "                     (0.0000, 0.6000, 0.5000), # bluish green\n",
    "                     (0.9500, 0.9000, 0.2500), # yellow\n",
    "                     (0.3500, 0.7000, 0.9000), # sky blue\n",
    "                     (0.8000, 0.6000, 0.7000), # reddish purple\n",
    "                     (0.9000, 0.6000, 0.0000)] # orange\n",
    "\n",
    "dashes = [(1.0, 0.0, 0.0, 0.0, 0.0, 0.0), # solid\n",
    "          (3.7, 1.6, 0.0, 0.0, 0.0, 0.0), # dashed\n",
    "          (1.0, 1.6, 0.0, 0.0, 0.0, 0.0), # dotted\n",
    "          (6.4, 1.6, 1.0, 1.6, 0.0, 0.0), # dot dash\n",
    "          (3.0, 1.6, 1.0, 1.6, 1.0, 1.6), # dot dot dash\n",
    "          (6.0, 4.0, 0.0, 0.0, 0.0, 0.0), # long dash\n",
    "          (1.0, 1.6, 3.0, 1.6, 3.0, 1.6)] # dash dash dot\n",
    "\n",
    "from matplotlib import rcParams, cycler\n",
    "matplotlib.rcdefaults()\n",
    "rcParams['font.family'] = 'DejaVu Serif'\n",
    "rcParams['mathtext.fontset'] = 'cm'\n",
    "rcParams['font.size'] = 12\n",
    "rcParams['figure.facecolor'] = (1,1,1,1)\n",
    "rcParams['figure.figsize'] = (16,8)\n",
    "rcParams['figure.dpi'] = 141\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.labelsize'] =  'large'\n",
    "rcParams['axes.titlesize'] = 'x-large'\n",
    "rcParams['lines.linewidth'] = 2.5\n",
    "rcParams['lines.solid_capstyle'] = 'round'\n",
    "rcParams['lines.dash_capstyle'] = 'round'\n",
    "rcParams['lines.dash_joinstyle'] = 'round'\n",
    "rcParams['xtick.labelsize'] = 'large'\n",
    "rcParams['ytick.labelsize'] = 'large'\n",
    "# rcParams['text.usetex']=True\n",
    "color_cycle = cycler(color=colorblind_colors)\n",
    "dash_cycle = cycler(dashes=dashes)\n",
    "rcParams['axes.prop_cycle'] =  color_cycle\n",
    "\n",
    "labelsize=10\n",
    "ticksize=8\n",
    "# for i,c in enumerate(colorblind_colors):\n",
    "#     plt.plot((i)*np.ones(5),c=c)\n",
    "\n",
    "eq_sigs = {'temp':'etemp',\n",
    "         'thomson_temp_EFITRT1':'etemp',\n",
    "         'thomson_temp_EFITRT2':'etemp',\n",
    "         'dens':'edens',\n",
    "         'thomson_dens_EFITRT1':'edens',\n",
    "         'thomson_dens_EFITRT2':'edens',\n",
    "         'itemp':'itemp',\n",
    "         'cerquick_temp_EFITRT1':'itemp',\n",
    "         'cerquick_temp_EFITRT2':'itemp',\n",
    "         'rotation':'rotation',\n",
    "         'cerquick_rotation_EFITRT1':'rotation',\n",
    "         'cerquick_rotation_EFITRT2':'rotation',\n",
    "         'press_EFITRT1':'press',\n",
    "         'press_EFITRT2':'press',\n",
    "         'press_EFIT01':'press',\n",
    "         'press_EFIT02':'press',\n",
    "         'ffprime_EFITRT1':'ffprime',\n",
    "         'ffprime_EFITRT2':'ffprime',\n",
    "         'ffprime_EFIT01':'ffprime',\n",
    "         'ffprime_EFIT02':'ffprime',\n",
    "         'q':'q',\n",
    "         'q_EFITRT1':'q',\n",
    "         'q_EFITRT2':'q',\n",
    "         'q_EFIT01':'q',\n",
    "         'q_EFIT02':'q'}\n",
    "\n",
    "labels = {'edens': '$n_e$ ($10^{19}/m^3$)',\n",
    "          'etemp': '$T_e$ (keV)',\n",
    "          'itemp': '$T_i$ (keV)',\n",
    "          'rotation':'$\\Omega$ (kHz)',\n",
    "          'q':'$\\iota$',\n",
    "          'press':'$P$ (Pa)',\n",
    "         'ffprime':\"$FF'$\"}\n",
    "\n",
    "labels = {key:labels[val] for key, val in eq_sigs.items()}\n",
    "\n",
    "scatter_titles = {'mean':'Mean',\n",
    "                  'std':'Std Dev.',\n",
    "                  'pca_1':'PCA Mode 1',\n",
    "                  'pca_2':'PCA Mode 2',\n",
    "                  'pca_3':'PCA Mode 3',\n",
    "                  'pca_4':'PCA Mode 4',\n",
    "                  'pca_5':'PCA Mode 5',\n",
    "                  'pca_6':'PCA Mode 6',\n",
    "                  'pca_2':'PCA Mode 2'}\n",
    "\n",
    "\n",
    "datapath = '/scratch/gpfs/jabbate/full_data_with_error/train_data.pkl'\n",
    "with open(datapath,'rb') as f:\n",
    "    rawdata = pickle.load(f,encoding='latin1')\n",
    "    \n",
    "traindata, valdata, normalization_dict = process_data(rawdata,\n",
    "                                                              scenario['sig_names'],\n",
    "                                                              scenario['normalization_method'],\n",
    "                                                              scenario['window_length'],\n",
    "                                                              scenario['window_overlap'],\n",
    "                                                              scenario['lookback'],\n",
    "                                                              scenario['lookahead'],\n",
    "                                                              scenario['sample_step'],\n",
    "                                                              scenario['uniform_normalization'],\n",
    "                                                              1,\n",
    "                                                              0,\n",
    "                                                              scenario['nshots'],\n",
    "                                                              2,\n",
    "                                                              scenario['flattop_only'],\n",
    "                                                              pruning_functions=scenario['pruning_functions'],\n",
    "                                                              invert_q = None, #scenario['invert_q'],\n",
    "                                                              val_idx = 0,\n",
    "                                                              excluded_shots=scenario['excluded_shots'],\n",
    "                                                            randomize=False)\n",
    "valdata = denormalize(valdata, normalization_dict)\n",
    "valdata = renormalize(valdata, scenario['normalization_dict'])\n",
    "generator = AutoEncoderDataGenerator(valdata,\n",
    "                                               1,  \n",
    "                                               scenario['profile_names'],\n",
    "                                               scenario['actuator_names'],\n",
    "                                               scenario['scalar_names'],\n",
    "                                               scenario['lookback'],\n",
    "                                               scenario['lookahead'],\n",
    "                                               scenario['profile_downsample'],\n",
    "                                               scenario['state_latent_dim'],\n",
    "                                               scenario['discount_factor'],\n",
    "                                               scenario['x_weight'],\n",
    "                                               scenario['u_weight'],                                            \n",
    "                                               scenario['shuffle_generators'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoders and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submodels(model):\n",
    "    from keras.models import Model\n",
    "    state_encoder = model.get_layer('state_encoder_time_dist').layer.layers[-1]\n",
    "    control_encoder = model.get_layer('ctrl_encoder_time_dist').layer.layers[-1]\n",
    "    state_decoder = model.get_layer('state_decoder_time_dist').layer\n",
    "    control_decoder = model.get_layer('ctrl_decoder_time_dist').layer\n",
    "    return state_encoder, state_decoder, control_encoder, control_decoder\n",
    "        \n",
    "def get_state_and_inputs(scenario,inputs,**kwargs):\n",
    "    state_inputs = {}\n",
    "    x0 = {}\n",
    "    for sig in scenario['profile_names']+scenario['scalar_names']:\n",
    "        state_inputs[sig] = np.squeeze(inputs[0]['input_'+sig])\n",
    "        if sig in scenario['profile_names']:\n",
    "            x0['input_'+sig] = inputs[0]['input_'+sig][0][0].reshape((1,1,scenario['profile_length']))\n",
    "        else:\n",
    "            x0['input_'+sig] = inputs[0]['input_'+sig][0][0].reshape((1,1,1))\n",
    "    \n",
    "    control_inputs = {}\n",
    "    for sig in scenario['actuator_names']:\n",
    "        control_inputs['input_'+sig] = inputs[0]['input_'+sig]\n",
    "    return x0, control_inputs\n",
    "\n",
    "def encode_state_and_inputs(state_encoder,control_encoder,scenario,x0,control_inputs,**kwargs):\n",
    "    # encode control\n",
    "    T = scenario['lookback'] + scenario['lookahead']\n",
    "    u = []\n",
    "    for i in range(T):\n",
    "        temp_input = {k:v[:,i].reshape((1,1,1)) for k,v in control_inputs.items()}\n",
    "        u.append(np.squeeze(control_encoder.predict(temp_input)))\n",
    "        \n",
    "    # encode state and propogate\n",
    "    x0 = np.squeeze(state_encoder.predict(x0))\n",
    "    return x0, u\n",
    "    \n",
    "def decode_state(state_decoder,x):\n",
    "    return state_decoder.predict(x[np.newaxis,:])\n",
    "\n",
    "\n",
    "def decode_inputs(control_decoder, inputs):\n",
    "    return control_decoder.predict(inputs)\n",
    "\n",
    "def get_final_state(state_encoder,scenario,inputs,**kwargs):\n",
    "    state_inputs = {}\n",
    "    xf = {}\n",
    "    for sig in scenario['profile_names']+scenario['scalar_names']:\n",
    "        state_inputs[sig] = np.squeeze(inputs[0]['input_'+sig])\n",
    "        if sig in scenario['profile_names']:\n",
    "            xf['input_'+sig] = inputs[0]['input_'+sig][0][3].reshape((1,1,scenario['profile_length']))\n",
    "        else:\n",
    "            xf['input_'+sig] = inputs[0]['input_'+sig][0][3].reshape((1,1,1))\n",
    "    \n",
    "    xf_enc = np.squeeze(state_encoder.predict(xf))\n",
    "    return xf, xf_enc\n",
    "\n",
    "# Some Model\n",
    "model = keras.models.load_model('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0.h5', compile=False)\n",
    "with open('/home/aiqtidar/run_results_11_15/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_16Nov20-16-52_Scenario-0_params.pkl', 'rb') as f:\n",
    "    scenario = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Aaron's Ideal Model\n",
    "# model = keras.models.load_model('/home/aaronwu/run_results_06_30/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_30Jun20-17-10.h5', compile=False)\n",
    "# with open('/home/aaronwu/run_results_06_30/model-autoencoder_SET-dense_SDT-dense_CET-dense_CDT-dense_profiles-temp-dens-ffprime_EFIT02-press_EFIT02-q_EFIT02_act-pinj-curr-tinj-gasA_LB-0_LA-3_30Jun20-17-10_params.pkl', 'rb') as f:\n",
    "#     scenario = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#######################################################################################\n",
    "state_encoder, state_decoder, control_encoder, control_decoder = get_submodels(model)\n",
    "x = []\n",
    "XF = []\n",
    "enc_x = []\n",
    "enc_XF = []\n",
    "\n",
    "inputs = []\n",
    "enc_inputs = []\n",
    "\n",
    "for i in range(len(generator)):\n",
    "    print(\"Completed {} out of {}\".format(i+1,len(generator)),end='\\r')\n",
    "    \n",
    "    # Get state and input from generators\n",
    "    temp_x, temp_con_inputs = get_state_and_inputs(scenario,generator[i])\n",
    "    x.append(temp_x)\n",
    "    \n",
    "    \n",
    "    # Append control inputs\n",
    "    inputs.append(temp_con_inputs)\n",
    "    \n",
    "    # Encode state and inputs\n",
    "    temp_x, temp_con_inputs = encode_state_and_inputs(state_encoder,control_encoder,scenario,temp_x,temp_con_inputs)\n",
    "    enc_x.append(temp_x)\n",
    "    enc_inputs.append(temp_con_inputs)\n",
    "    \n",
    "    # Get final encoded state for MPC\n",
    "    exf, exf_enc = get_final_state(state_encoder,scenario,generator[i])\n",
    "    XF.append(exf)\n",
    "    enc_XF.append(exf_enc)\n",
    "\n",
    "enc_inputs = np.array(enc_inputs)\n",
    "enc_x = np.array(enc_x)\n",
    "print(\"Enc Input: {}\".format(enc_inputs.shape))\n",
    "print(\"Enc_x: {}\".format(enc_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filtfilt(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "cutoff = 1500\n",
    "fs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple experiment to obtain error percentages in encoding and decoding of states\n",
    "\n",
    "# n_sample goes from 0 to 9701 and only accepts even integers\n",
    "n_sample = 8\n",
    "sample = []\n",
    "\n",
    "# pick n_samples at random\n",
    "for i in range(0, n_sample):\n",
    "    sample.append(np.random.randint(9700))\n",
    "\n",
    "print(sample)\n",
    "    \n",
    "percent_err_tot = []\n",
    "temp_x_tot = []\n",
    "tempor_tot = []\n",
    "temp_x_filtered = []\n",
    "percent_err_mean = []\n",
    "\n",
    "for samp in sample:\n",
    "    temp_x = x[samp]\n",
    "    \n",
    "    # Encode and decode state\n",
    "    temp_x_prime = state_decoder.predict(np.squeeze(state_encoder.predict(x[samp]))[np.newaxis,:])\n",
    "    \n",
    "    tempor = np.array([])\n",
    "    for keys in x[samp]:\n",
    "        tempor = np.concatenate([tempor,x[samp][keys][0][0]])\n",
    "    \n",
    "    percent_err = abs(100*((tempor - temp_x_prime))/(tempor))\n",
    "    percent_err_tot.append(percent_err)\n",
    "    percent_err_mean.append(np.mean(percent_err))\n",
    "    temp_x_tot.append(temp_x_prime)\n",
    "    tempor_tot.append(tempor)\n",
    "    \n",
    "    temp_x_fil = []\n",
    "    for i in range(0, int(len(temp_x_prime[0])/33)):\n",
    "        temp_x_fil.append(butter_lowpass_filtfilt(temp_x_prime[0][i*33:(i+1)*33].squeeze(), cutoff, fs))    \n",
    "    temp_x_filtered.append(np.concatenate(temp_x_fil))\n",
    "    \n",
    "    \n",
    "print(\"Mean Sample Error of States: {} %\".format(np.mean(percent_err_mean)))\n",
    "\n",
    "\n",
    "# plt.plot(temp_x_prime.flatten())\n",
    "# plt.plot(tempor)\n",
    "# plt.show()\n",
    "\n",
    "n_fig = 2\n",
    "figures, axes = plt.subplots(nrows = int(len(sample) /2), ncols = n_fig)\n",
    "\n",
    "for i in range(0, n_fig):\n",
    "    for j in range(0, int(len(sample) /2)):\n",
    "        axes[j,i].plot(temp_x_tot[j*(n_fig)+i].flatten())\n",
    "        axes[j,i].plot(tempor_tot[j*(n_fig)+i])\n",
    "        axes[j,i].plot(temp_x_filtered[j*(n_fig)+i], color = 'red')\n",
    "        axes[j,i].set_ylabel(\"Profile Value\")\n",
    "        axes[j,i].set_xlabel(\"Spatial Array\")\n",
    "#     figures.tight_layout()\n",
    "figures.legend([\"Encoded Profile\", \"Original Profile\", \"Filtered Encoded Profile\"])\n",
    "plt.show()\n",
    "figures.clear()\n",
    "\n",
    "# np.concatenate(temp_x_filtered[0])\n",
    "# butter_lowpass_filtfilt(temp_x_prime[0][i*33:(i+1)*33].squeeze(),cutoff,fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A similar experiment to obtain error percentages in encoding and decoding of inputs\n",
    "\n",
    "# Sample goes from 0 to 9701\n",
    "n_sample = 6\n",
    "sample = []\n",
    "\n",
    "# pick n_samples at random\n",
    "for i in range(0, n_sample):\n",
    "    sample.append(np.random.randint(100))\n",
    "\n",
    "percent_err_tot = []\n",
    "tempor_tot = []\n",
    "temp_u_prime_tot = []\n",
    "percent_err_mean = []\n",
    "\n",
    "for samp in sample:\n",
    "    temp_inp = inputs[samp]\n",
    "    \n",
    "    # encode control\n",
    "    T = scenario['lookback'] + scenario['lookahead']\n",
    "    temp_u = []\n",
    "    for i in range(T):\n",
    "        temp_input = {k:v[:,i].reshape((1,1,1)) for k,v in temp_inp.items()}\n",
    "#         print(temp_input)\n",
    "        temp_u.append(np.squeeze(control_encoder.predict(temp_input)))\n",
    "    \n",
    "    # Decode control\n",
    "    temp_u_prime = np.concatenate(decode_inputs(control_decoder, np.array(temp_u)))\n",
    "    \n",
    "    tempor = np.array([])\n",
    "    tempor2 = []\n",
    "    for keys in inputs[samp]:\n",
    "        tempor2.append(np.transpose(inputs[samp][keys][0])[0])\n",
    "    \n",
    "    for i in range(0,len(tempor2[0])):\n",
    "        tempor = np.concatenate([tempor,np.squeeze(np.array([tempor2[j][i] for j in range(len(tempor2))]))])\n",
    "\n",
    "    percent_err = abs(100*((tempor - temp_u_prime))/(tempor))\n",
    "    percent_err_tot.append(percent_err)\n",
    "    temp_u_prime_tot.append(temp_u_prime)\n",
    "    tempor_tot.append(tempor)\n",
    "    percent_err_mean.append(np.mean(percent_err))\n",
    "    \n",
    "print(\"Mean Sample Error of Control Inputs: {} %\".format(np.mean(percent_err_mean)))\n",
    "# plt.plot(tempor)\n",
    "# plt.plot(temp_u_prime)\n",
    "\n",
    "n_fig = 2\n",
    "figures, axes = plt.subplots(nrows = int(len(sample) /2), ncols = n_fig)\n",
    "\n",
    "for i in range(0, n_fig):\n",
    "    for j in range(0, int(len(sample) /2)):\n",
    "        axes[j,i].plot(temp_u_prime_tot[j*(n_fig)+i].flatten())\n",
    "        axes[j,i].plot(tempor_tot[j*(n_fig)+i])\n",
    "        axes[j,i].set_ylabel(\"Control Input\")\n",
    "        axes[j,i].set_xlabel(\"Discrete Time\")\n",
    "#     figures.tight_layout()\n",
    "figures.legend([\"Encoded Profile\", \"Original Profile\"])\n",
    "plt.show()\n",
    "figures.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_state(state_decoder,enc_x[0])\n",
    "# enc_x[0][np.newaxis,:].shape\n",
    "# state_decoder.predict(enc_x[0][np.newaxis,:])\n",
    "tempor = np.array([])\n",
    "for keys in x[0]:\n",
    "    tempor = np.concatenate([tempor,x[0][keys][0][0]])\n",
    "# x[0]['input_temp'][0][0]\n",
    "tempor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control_decoder.predict(enc_inputs[0])\n",
    "# decode_inputs(control_decoder,enc_inputs[0])\n",
    "# inputs[0]\n",
    "# np.concatenate(enc_inputs[0])\n",
    "np.transpose(inputs[0]['input_pinj'][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[samp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical MPC Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Classical_MPC_system(Q,R,A,B,x0,n):\n",
    "\n",
    "    import numpy\n",
    "    from cvxopt import matrix\n",
    "    from cvxopt import solvers\n",
    "\n",
    "\n",
    "    # Define parameters\n",
    "    N = A.shape[0]\n",
    "    M = B.shape[1]\n",
    "\n",
    "    ############################### Generate Matrices ####################################\n",
    "\n",
    "    # Generate Matrix M\n",
    "    M_bar = np.zeros((N * n, N))\n",
    "    rsl = slice(0, N)\n",
    "    M_bar[rsl, :N] = A\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        M_bar[rsl, :N] = A @ M_bar[rsl_p, :N]\n",
    "\n",
    "    # Generate Q_bar\n",
    "    Q_bar = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    Q_bar[rsl, :N] = Q\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        Q_bar[rsl, N : (i + 1) * N] = Q_bar[rsl_p, : i * N]\n",
    "\n",
    "    # Generate R_bar\n",
    "    R = np.diag(np.ones((M)))\n",
    "    R_bar = np.kron(np.eye(n),R)\n",
    "\n",
    "    # Generate V\n",
    "    V = np.zeros((N * n, n * M))\n",
    "    rsl = slice(0, N)\n",
    "    V[rsl, :M] = B #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        V[rsl, :M] = A @ V[rsl_p, :M] # A^(N-1)*B\n",
    "        V[rsl, M : (i + 1) * M] = V[rsl_p, : i * M]\n",
    "\n",
    "    # Generate D_bar, d\n",
    "    D_bar = np.zeros((2*M*n,M*n))\n",
    "    rsl = slice(0,M*n)\n",
    "    D_bar[rsl, rsl] = np.eye(M*n)\n",
    "    D_bar[slice(M*n,2*M*n), rsl] = -np.eye(M*n)\n",
    "\n",
    "    d = np.zeros((2*M*n,1))\n",
    "    \n",
    "    # Limits on u\n",
    "    d[rsl,:] = np.ones((M*n,1))*10\n",
    "    d[slice(M*n,2*M*n),:] = -np.ones((M*n,1))*10\n",
    "\n",
    "    # Generate F and H matrices\n",
    "    temp = np.transpose(V).dot(Q_bar)\n",
    "    F = temp.dot(M_bar)\n",
    "\n",
    "    temp = np.transpose(V).dot(Q_bar)\n",
    "    H = temp.dot(V) + R_bar\n",
    "\n",
    "    ########################################### Do computations #############################\n",
    "\n",
    "    # Define QP parameters (with NumPy)\n",
    "\n",
    "\n",
    "    P = matrix(H, tc='d')\n",
    "    q = matrix(F.dot(x0), tc='d')\n",
    "    G = matrix(D_bar, tc='d')\n",
    "    h = matrix(d, tc='d')\n",
    "\n",
    "\n",
    "    ######################################### Print Solution ###############################\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P,q,G,h)\n",
    "    # Extract optimal value and solution\n",
    "    sol['x'] # [7.13e-07, 5.00e+00]\n",
    "    sol['primal objective'] # 20.0000061731\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = - enc_x[0] + enc_XF[0]\n",
    "\n",
    "N = x0.shape[0]\n",
    "M = enc_inputs.shape[2]\n",
    "\n",
    "# Generate Q,R\n",
    "Q = np.eye(N)*1e1\n",
    "R = np.eye(M)*1e1\n",
    "\n",
    "n = scenario['lookback'] + scenario['lookahead']\n",
    "print(\"Q: {}\".format(np.matrix.view(Q)))\n",
    "print(\"R: {}\".format(np.matrix.view(R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_mpc = solve_Classical_MPC_system(Q,R,A,B,x0,n)\n",
    "sol_mpc = np.array(sol_mpc['x'])\n",
    "u_mpc = sol_mpc.reshape(3, 5)\n",
    "u_mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo MPC System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(A: np.ndarray, B: np.ndarray, Q: np.ndarray, R: np.ndarray) -> np.ndarray:\n",
    "    from scipy.linalg import solve_discrete_are\n",
    "    return solve_discrete_are(A, B, Q, R) \n",
    "\n",
    "def solve_Neo_MPC_system(Q,R,A,B,x0,xf,n):\n",
    "    \n",
    "    # Imports\n",
    "    import numpy\n",
    "    from cvxopt import matrix\n",
    "    from cvxopt import solvers\n",
    "    \n",
    "    # Define parameters\n",
    "    N = A.shape[0]\n",
    "    M = B.shape[1]\n",
    "    print(\"N: {}\".format(N))\n",
    "    print(\"M: {}\".format(M))\n",
    "    \n",
    "    # Reshape to avoid complications\n",
    "    x0 = x0.reshape((N,1))\n",
    "    xf = xf.reshape((N,1))\n",
    "\n",
    "    ############################### Generate Matrices ####################################\n",
    "\n",
    "    # Generate Matrix M\n",
    "    M_bar = np.zeros((N * n, N))\n",
    "    rsl = slice(0, N)\n",
    "    M_bar[rsl, :N] = A\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        M_bar[rsl, :N] = A @ M_bar[rsl_p, :N]\n",
    "    \n",
    "#     print(\"M_bar: {}\".format(M_bar))\n",
    "    \n",
    "    # Generate Q_bar\n",
    "    Q_bar = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    Q_bar[rsl, :N] = Q\n",
    "\n",
    "    for i in range(1, n-1):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        Q_bar[rsl, N : (i + 1) * N] = Q_bar[rsl_p, : i * N]\n",
    "    \n",
    "    Q_N = lqr(A,B,Q,R)\n",
    "    rsl = slice((n-1) * N, n * N)\n",
    "    Q_bar[rsl, rsl] = Q_N\n",
    "    \n",
    "#     print(\"Q_bar: {}\".format(Q_bar))\n",
    "\n",
    "    # Generate R_bar\n",
    "    R_bar = np.kron(np.eye(n),R)\n",
    "    \n",
    "#     print(\"R_bar: {}\".format(R_bar))\n",
    "\n",
    "    # Generate V\n",
    "    V = np.zeros((N * n, n * M))\n",
    "    rsl = slice(0, N)\n",
    "    V[rsl, :M] = B #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        V[rsl, :M] = A @ V[rsl_p, :M] # A^(N-1)*B\n",
    "        V[rsl, M : (i + 1) * M] = V[rsl_p, : i * M]\n",
    "    \n",
    "#     print(\"V: {}\".format(V))\n",
    "        \n",
    "    # Generate L\n",
    "    L = np.zeros((N * n, N * n))\n",
    "    rsl = slice(0, N)\n",
    "    L[rsl, :N] = A #Make first line\n",
    "\n",
    "    for i in range(1, n):\n",
    "        rsl_p, rsl = rsl, slice(i * N, (i + 1) * N)\n",
    "        L[rsl, :N] = L[rsl_p, :N]\n",
    "        L[rsl, N : (i + 1) * N] = A @ L[rsl_p, : i * N]\n",
    "    \n",
    "#     print(\"L: {}\".format(np.matrix.view(L)))\n",
    "    \n",
    "    #Generate X_F from x_f\n",
    "    X_F = np.zeros((N*n,1))\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        rsl = slice(i * N, (i + 1)*N)\n",
    "        X_F[rsl] = xf\n",
    "    \n",
    "#     print(\"XF: {}\".format(X_F))\n",
    "    \n",
    "    # Generate D_bar, d\n",
    "    D_bar = np.zeros((2*M*n,M*n))\n",
    "    rsl = slice(0,M*n)\n",
    "    D_bar[rsl, rsl] = np.eye(M*n)\n",
    "    D_bar[slice(M*n,2*M*n), rsl] = -np.eye(M*n)\n",
    "\n",
    "    d = np.zeros((2*M*n,1))\n",
    "    \n",
    "    # Limits on U\n",
    "    lim = 1\n",
    "    \n",
    "    d[rsl,:] = np.ones((M*n,1))*lim\n",
    "    d[slice(M*n,2*M*n),:] = np.ones((M*n,1))*lim\n",
    "\n",
    "#     print(\"D_bar: {}\".format(D_bar))\n",
    "#     print(\"D: {}\".format(d))\n",
    "    \n",
    "    # Generate F and H matrices   \n",
    "    temp = np.transpose(V) @ (Q_bar)\n",
    "    F = temp @ (M_bar.dot(x0) - X_F) # + L @ (X_F)\n",
    "    \n",
    "    temp = np.transpose(V) @ (Q_bar)\n",
    "    H = temp @ (V) + R_bar\n",
    "    \n",
    "#     print(\"H: {}\".format(H))\n",
    "#     print(\"F: {}\".format(F))\n",
    "\n",
    "    ########################################### Do computations #############################\n",
    "\n",
    "    # Define QP parameters (with NumPy)\n",
    "\n",
    "    P = matrix(H, tc='d')\n",
    "    q = matrix(F, tc='d')\n",
    "    G = matrix(D_bar, tc='d')\n",
    "    h = matrix(d, tc='d')\n",
    "\n",
    "    ######################################### Print Solution ###############################\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P,q, G, h)\n",
    "\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve MPC Problem for one case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Q,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 <= Sample < 9701\n",
    "sample = 10\n",
    "\n",
    "x0 = enc_x[sample] \n",
    "xf = enc_XF[sample]\n",
    "\n",
    "N = x0.shape[0]\n",
    "M = enc_inputs.shape[2]\n",
    "\n",
    "# Generate Q,R\n",
    "Q = np.eye(N)*1e5\n",
    "R = np.eye(M)*1e-3\n",
    "\n",
    "# Replenish A,B\n",
    "A,B = get_AB(model)\n",
    "\n",
    "n = scenario['lookback'] + scenario['lookahead']\n",
    "print(\"N: {}\".format(N))\n",
    "print(\"M: {}\".format(M))\n",
    "print(\"n: {}\".format(n))\n",
    "print(\"Q: {}\".format(np.matrix.view(Q)))\n",
    "print(\"R: {}\".format(np.matrix.view(R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_mpc = solve_Neo_MPC_system(Q,R,A,B,x0,xf,n)\n",
    "sol_mpc = np.array(sol_mpc['x'])\n",
    "u_mpc = sol_mpc.reshape(n, M)\n",
    "u_mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs[sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot u vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sol_mpc)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.ylabel(\"u\")\n",
    "plt.xlabel(\"# Timestep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot how state changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "abs_diff = []\n",
    "abs_fin_diff = []\n",
    "abs_aut_diff = []\n",
    "x_prev = x0\n",
    "x_prev2 = x0\n",
    "\n",
    "for i in range(0,n):\n",
    "    x_new = (A @ x_prev) + np.transpose(B.dot(u_mpc[i]))\n",
    "    x_new2 = (A @ x_prev2) + np.transpose(B.dot(enc_inputs[sample][i]))    \n",
    "    \n",
    "    print(\"x[{}]: {} \\n\".format(i+1,x_new))\n",
    "\n",
    "    states.append(x_prev)\n",
    "    abs_diff.append(np.linalg.norm(x_new - x_prev))\n",
    "    abs_fin_diff.append(np.linalg.norm(x_new - xf))\n",
    "    abs_aut_diff.append(np.linalg.norm(x_new2 - xf))\n",
    "    x_prev = x_new\n",
    "    x_prev2 = x_new2\n",
    "\n",
    "print(\"Target: {} \\n\".format(xf))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(np.arange(1,n+1),abs_fin_diff)\n",
    "plt.plot(np.arange(1,n+1),abs_aut_diff)\n",
    "plt.legend([\"Abs Diff between x_i and x_f\", \"Abs Diff between x_i and x_f in Autoencoder\"])\n",
    "plt.ylabel(\"Norm of (x_i+1 - x_i) \")\n",
    "plt.xlabel(\"# Timestep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Larger results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Q,R\n",
    "Q = np.eye(N)*1e5\n",
    "R = np.eye(M)*1e-3\n",
    "\n",
    "# Replenish A,B\n",
    "A,B = get_AB(model)\n",
    "\n",
    "n = scenario['lookback'] + scenario['lookahead']\n",
    "\n",
    "#### Pick Sample and solve system\n",
    "\n",
    "# 0 <= Sample < 9701\n",
    "# Pick n_sample random samples and put them into an array called sample\n",
    "n_sample = 8\n",
    "sample = []\n",
    "\n",
    "for i in range(0, n_sample):\n",
    "    sample.append(np.random.randint(100))\n",
    "\n",
    "# Solve mpc system for the samples in sample array\n",
    "u_mpc = []\n",
    "for samp in sample:\n",
    "    x0 = enc_x[samp] \n",
    "    xf = enc_XF[samp]\n",
    "\n",
    "    N = x0.shape[0]\n",
    "    M = enc_inputs.shape[2]\n",
    "\n",
    "    sol_mpc = solve_Neo_MPC_system(Q,R,A,B,x0,xf,n)\n",
    "    sol_mpc = np.array(sol_mpc['x'])\n",
    "    u_mpc.append(sol_mpc.reshape(n, M))\n",
    "\n",
    "# Generate statistics for each sample\n",
    "abs_diff_tot = []\n",
    "abs_aut_diff_tot = []\n",
    "\n",
    "for j in range(0,len(sample)):\n",
    "    states = []\n",
    "    abs_diff = []\n",
    "    abs_aut_diff = []\n",
    "    x_prev = enc_x[sample[j]]\n",
    "    x_prev2 = enc_x[sample[j]]\n",
    "    xf = enc_XF[sample[j]]\n",
    "\n",
    "    for i in range(0,n):\n",
    "        x_new = (A @ x_prev) + np.transpose(B.dot(u_mpc[j][i]))\n",
    "        x_new2 = (A @ x_prev2) + np.transpose(B.dot(enc_inputs[sample[j]][i]))    \n",
    "\n",
    "        states.append(x_prev)\n",
    "        abs_diff.append(np.linalg.norm(x_new - xf))\n",
    "        abs_aut_diff.append(np.linalg.norm(x_new2 - xf))\n",
    "        x_prev = x_new\n",
    "        x_prev2 = x_new2\n",
    "    abs_diff_tot.append(abs_diff)\n",
    "    abs_aut_diff_tot.append(abs_aut_diff)\n",
    "\n",
    "\n",
    "n_fig = 2\n",
    "figures, axes = plt.subplots(nrows = int(len(sample) /2), ncols = n_fig, clear= True)\n",
    "\n",
    "for i in range(0, n_fig):\n",
    "    for j in range(0, int(len(sample) /2)):\n",
    "        axes[j,i].plot(abs_diff_tot[j*(n_fig)+i])\n",
    "        axes[j,i].plot(abs_aut_diff_tot[j*(n_fig)+i])\n",
    "        axes[j,i].set_ylim([0,np.max(np.concatenate([abs_aut_diff_tot[j*(n_fig)+i],abs_diff_tot[j*(n_fig)+i]]))])\n",
    "        axes[j,i].set_ylabel(\"||x_i+1 - x_f|| \")\n",
    "        axes[j,i].set_xlabel(\"# Timestep\")\n",
    "# figures.tight_layout()\n",
    "figures.legend([\"||x_i - x_f||\", \"||x_i - x_f|| in Autoencoder\"])\n",
    "plt.show()\n",
    "figures.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Encoded state MPC results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MPC is asked to find the set of control inputs $ U $ which take the state space system from some $x_i$ to some $x_f$, both of which are taken from real data. However, the state space model used by the MPC relies on the model used from the autoencoder system. \n",
    "\n",
    "The autoencoder model predicts some final state $x_f^a$ based on the actual set of inputs used during the experiment.\n",
    "\n",
    "The MPC's final state $x_f^m$ is in fact closer to the real state $x_f$ than $x_f^a$.\n",
    "\n",
    "There are numerous possibilities:\n",
    "\n",
    "1. There  are errors in the state space model from the autoencoder, which implies that the real set of inputs to reach $x_f$ are different from $U$.\n",
    "\n",
    "2. The autoencoder's prediction $x_f^a$ in incorrect, and that the real state reached should be closer to $x_f$.\n",
    "\n",
    "3. Both of the above?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding State and Control Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Todo:\n",
    "\n",
    "- Check if the encoders and decoders are linear...\n",
    "\n",
    "1. Take U, get x and decode to get actual x. And compare to actual profiles.\n",
    "2. Take U and plug into a different model that were trained in different data. Compare between models. Find one that has small error in predictions.\n",
    "- Based on the top two, decide on what next steps are...\n",
    "\n",
    "- Take inputs from MPC, plug into several models, compare predictions from MPC vs Target\n",
    "\n",
    "\n",
    "3. If its not good, retrain autoencoder model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
